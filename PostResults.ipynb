{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "import collections\n",
    "import pickle\n",
    "from statistics import mean, stdev\n",
    "from scipy import stats, spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information for NYUv2\n",
    "data = 'NYUv2'\n",
    "iters = 20000\n",
    "tasks = ('segment_semantic','normal','depth_zbuffer') # task 0, 1, 2\n",
    "metrics = {'segment_semantic': ['mIoU', 'Pixel Acc'],\n",
    "           'normal': ['Angle Mean', 'Angle Median', 'Angle 11.25', 'Angle 22.5', 'Angle 30'],\n",
    "           'depth_zbuffer': ['abs_err','rel_err','sigma_1.25','sigma_1.25^2','sigma_1.25^3']}\n",
    "metrics_prop = {'mIoU': False, 'Pixel Acc': False, \n",
    "                'Angle Mean': True, 'Angle Median': True, 'Angle 11.25': False, 'Angle 22.5': False, 'Angle 30': False,\n",
    "                'abs_err': True,'rel_err': True,'sigma_1.25': False,'sigma_1.25^2': False,'sigma_1.25^3': False} # True: the lower the better\n",
    "reduce_var_length = {'train_loss': 10, 'val_loss': 3, 'val_acc': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '1129'\n",
    "model = 'resnet'\n",
    "B = 5 # 17 - fined, 5 - coarse\n",
    "coarse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '0115'\n",
    "model = 'mobilenet'\n",
    "B = 6 # 9 - coarse v1, 6 - coarse v2\n",
    "coarse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_complete(lines, iters):\n",
    "    rev_lines = lines[::-1]\n",
    "    for line in rev_lines:\n",
    "        if 'Iter' in line:\n",
    "            it = int(line.split(' ')[1])\n",
    "            break\n",
    "    if it != iters:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def extract_loss_results(lines, tasks, reduce_var_length):\n",
    "    # Function: Extract train loss / val loss \n",
    "    train_loss = {}\n",
    "    val_loss = {}\n",
    "    for task in tasks:\n",
    "        train_loss[task] = collections.deque(reduce_var_length['train_loss']*[0], reduce_var_length['train_loss'])\n",
    "        val_loss[task] = collections.deque(reduce_var_length['val_loss']*[0], reduce_var_length['val_loss'])\n",
    "    \n",
    "    for line in lines:\n",
    "        for task in tasks:\n",
    "            if task[:4] in line and 'Train Loss' in line:\n",
    "                loss = float(line.split(': ')[1])\n",
    "                train_loss[task].append(loss)\n",
    "            elif task[:4] in line and 'Val Loss' in line:\n",
    "                loss = float(line.split(': ')[1])\n",
    "                val_loss[task].append(loss)\n",
    "                \n",
    "    avg_loss = {'train_loss': [], 'val_loss': []}\n",
    "    std_loss = {'train_loss': [], 'val_loss': []}\n",
    "    for task in tasks:\n",
    "        avg_loss['train_loss'].append(mean(train_loss[task]))\n",
    "        avg_loss['val_loss'].append(mean(val_loss[task]))\n",
    "        \n",
    "        std_loss['train_loss'].append(stdev(train_loss[task]))\n",
    "        std_loss['val_loss'].append(stdev(val_loss[task]))\n",
    "    return avg_loss, std_loss\n",
    "\n",
    "def extract_metric_results(lines, tasks, metrics, reduce_var_length):\n",
    "    # Function: Extract val metrics\n",
    "    metric_queue = {}\n",
    "    for task in tasks:\n",
    "        for metric in metrics[task]:\n",
    "            metric_queue[metric] = collections.deque(reduce_var_length['val_acc']*[0], reduce_var_length['val_acc'])\n",
    "    \n",
    "    for line in lines:\n",
    "        for task in tasks:\n",
    "            for metric in metrics[task]:\n",
    "                if metric in line:\n",
    "                    value = float(re.findall(\"\\d+\\.\\d+\", line.split(metric)[1])[0])\n",
    "                    metric_queue[metric].append(value)\n",
    "                \n",
    "    avg_metric = {}\n",
    "    for task in tasks:\n",
    "        for metric in metrics[task]:\n",
    "            avg_metric[metric] = (mean(metric_queue[metric]))\n",
    "    return avg_metric\n",
    "\n",
    "def rel_perf(results, lower=True):\n",
    "    # Function: Compute rel. perf.\n",
    "    if lower:\n",
    "        return (results[0,:] - results)/results[0,:]*100\n",
    "    else:\n",
    "        return (results - results[0,:])/results[0,:]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For 2-Task Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('segment_semantic', 'normal')\n",
      "train_loss\n",
      "task 0\n",
      "single 0.01249302902804501\n",
      "multiple 0.02677682831189021\n",
      "task 1\n",
      "single 0.0007691358238131854\n",
      "multiple 0.0009873696819777727\n",
      "================================================================================\n",
      "val_loss\n",
      "task 0\n",
      "single 0.01149084769583841\n",
      "multiple 0.01330411660045557\n",
      "task 1\n",
      "single 0.0009567405382894348\n",
      "multiple 0.0014403574659193551\n",
      "================================================================================\n",
      "('segment_semantic', 'depth_zbuffer')\n",
      "train_loss\n",
      "task 0\n",
      "single 0.012872436834668597\n",
      "multiple 0.019074019590357285\n",
      "task 1\n",
      "single 0.0080218243695754\n",
      "multiple 0.08187166477685263\n",
      "================================================================================\n",
      "val_loss\n",
      "task 0\n",
      "single 0.013864718082114343\n",
      "multiple 0.015062251073707645\n",
      "task 1\n",
      "single 0.016702541815673225\n",
      "multiple 0.049194100820683324\n",
      "================================================================================\n",
      "('normal', 'depth_zbuffer')\n",
      "train_loss\n",
      "task 0\n",
      "single 0.0007576104586850229\n",
      "multiple 0.0052310004354382865\n",
      "task 1\n",
      "single 0.010555536932761986\n",
      "multiple 0.0437425597990993\n",
      "================================================================================\n",
      "val_loss\n",
      "task 0\n",
      "single 0.00037900599330725326\n",
      "multiple 0.004815100988646469\n",
      "task 1\n",
      "single 0.014349063771378612\n",
      "multiple 0.03308221501981516\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "loss_df = {'train_loss': pd.DataFrame(), 'val_loss': pd.DataFrame()}\n",
    "\n",
    "# For all two tasks\n",
    "for two_task in set(itertools.combinations(tasks, 2)):\n",
    "    print(two_task)\n",
    "    \n",
    "    # For all branching points\n",
    "    loss_results = {'train_loss': [], 'val_loss': []}\n",
    "    loss_std  = {'train_loss': [], 'val_loss': []}\n",
    "    block = B\n",
    "    for i in range(block+1):\n",
    "        log = '_'.join(two_task) + '_b' + str(i) + '.stdout'\n",
    "        if coarse:\n",
    "            log = '2task_coarse_'+data+'_'+model+'/'+log\n",
    "        else:\n",
    "            log = '2task_fined_'+data+'_'+model+'/'+log\n",
    "        # Read in content\n",
    "        with open('./log/'+log) as f:\n",
    "            lines = f.readlines()\n",
    "            lines = [line.rstrip() for line in lines]\n",
    "            if not confirm_complete(lines,iters):\n",
    "                print(str(i) + ' not complete')\n",
    "                continue\n",
    "            avg_loss, std_loss = extract_loss_results(lines, two_task, reduce_var_length)\n",
    "            for mode in loss_results:\n",
    "                loss_results[mode].append(avg_loss[mode])\n",
    "                loss_std[mode].append(std_loss[mode])\n",
    "    \n",
    "    # Compute loss std \n",
    "    # 1. avg of std of loss in one 2-task model\n",
    "    # 2. std of loss in multiple 2-task models with different b:\n",
    "    for mode in loss_results:\n",
    "        print(mode)\n",
    "        single_temp = np.array(loss_std[mode])\n",
    "        multiple_temp = np.array(loss_results[mode])\n",
    "        for i in range(single_temp.shape[1]):\n",
    "            print('task '+str(i))\n",
    "            print('single '+str(mean(single_temp[:,i])))\n",
    "            print('multiple '+str(stdev(multiple_temp[:,i])))\n",
    "        print('='*80)\n",
    "           \n",
    "    # Add results to dataframe\n",
    "    task0_idx = tasks.index(two_task[0])\n",
    "    task1_idx = tasks.index(two_task[1])\n",
    "    col_name = '(' + str(task0_idx) + ', '+ str(task1_idx) + ')' + '-'\n",
    "    for mode in loss_df:\n",
    "        rel_mode_loss = rel_perf(np.array(loss_results[mode]))\n",
    "        for idx in range(2):\n",
    "            loss_df[mode][col_name+str(idx)] = rel_mode_loss[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Excel\n",
    "for mode in loss_df:\n",
    "    loss_df[mode].to_excel(\"./2task/\"+ data + \"_2task_metrics_\" + model + \"_\" + date + \"_\" + mode + \".xlsx\", index_label='branch')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss':    (0, 1)-0  (0, 1)-1  (0, 2)-0   (0, 2)-1   (1, 2)-0   (1, 2)-1\n",
       " 0  0.000000  0.000000  0.000000   0.000000   0.000000   0.000000\n",
       " 1 -9.487279 -0.088543  2.159702   3.396303 -23.115468  -9.666065\n",
       " 2 -4.097883  1.770852  1.606371  11.226751 -27.734205 -16.396805\n",
       " 3  1.607108  4.515672  1.542481  17.528132 -31.111111  -3.354657\n",
       " 4 -2.331763  2.532318 -0.589839  26.020349 -31.721133   4.967708\n",
       " 5 -0.803554 -0.832300 -0.192810  30.174625 -35.381264   4.308102\n",
       " 6 -0.871528  0.194794 -3.078117  28.138301 -38.387800   0.029078,\n",
       " 'val_loss':    (0, 1)-0  (0, 1)-1  (0, 2)-0   (0, 2)-1   (1, 2)-0  (1, 2)-1\n",
       " 0  0.000000  0.000000  0.000000   0.000000   0.000000  0.000000\n",
       " 1 -0.080954  0.052165  1.567627   1.018140 -31.550069 -2.048204\n",
       " 2  1.237750 -2.556077  1.176766   8.643073 -29.218107 -7.537573\n",
       " 3 -1.361312 -3.338550  2.267834   8.554153 -31.207133  0.109971\n",
       " 4  0.419685 -1.095462  0.518362  12.960164 -28.257888  7.707111\n",
       " 5 -0.187473  2.973396 -0.599879  13.493687 -28.189300  2.630132\n",
       " 6 -0.609288  0.886802  1.682587  19.762582 -34.362140  5.654326}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For 2-Task Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('segment_semantic', 'normal')\n",
      "('segment_semantic', 'depth_zbuffer')\n",
      "('normal', 'depth_zbuffer')\n"
     ]
    }
   ],
   "source": [
    "baselines_2task = {'mIoU': [], 'Pixel Acc': [], \n",
    "            'Angle Mean': [], 'Angle Median': [], 'Angle 11.25': [], 'Angle 22.5': [], 'Angle 30': [],\n",
    "            'abs_err': [],'rel_err': [],'sigma_1.25': [],'sigma_1.25^2': [],'sigma_1.25^3': []}\n",
    "\n",
    "metric_df = pd.DataFrame()\n",
    "\n",
    "# For all two tasks\n",
    "for two_task in set(itertools.combinations(tasks, 2)):\n",
    "    print(two_task)\n",
    "\n",
    "    metric_results = {}\n",
    "    for task in two_task:\n",
    "        for metric in metrics[task]:\n",
    "            metric_results[metric] = []\n",
    "            \n",
    "    # For all branching points, get metrics results\n",
    "    block = B\n",
    "    for i in range(block+1):\n",
    "        log = '_'.join(two_task) + '_b' + str(i) + '.stdout'\n",
    "        if coarse:\n",
    "            log = '2task_coarse_'+data+'_'+model+'/'+log\n",
    "        else:\n",
    "            log = '2task_fined_'+data+'_'+model+'/'+log\n",
    "        # Read in content\n",
    "        with open('./log/'+log) as f:\n",
    "            lines = f.readlines()\n",
    "            lines = [line.rstrip() for line in lines]\n",
    "            if not confirm_complete(lines,iters):\n",
    "                print(str(i) + ' not complete')\n",
    "                continue\n",
    "            avg_metric = extract_metric_results(lines, two_task, metrics, reduce_var_length)\n",
    "            for task in two_task:\n",
    "                for metric in metrics[task]:\n",
    "                    metric_results[metric].append(avg_metric[metric])\n",
    "    \n",
    "    # Take down baselines\n",
    "    for task in two_task:\n",
    "        for metric in metrics[task]:\n",
    "            baselines_2task[metric].append(metric_results[metric][0])\n",
    "    \n",
    "    # Compute relative performance for each task\n",
    "    task_rel_perf = {}\n",
    "    for task in two_task:\n",
    "        temp = np.zeros((block + 1, 1))\n",
    "        idx = 0\n",
    "        for metric in metrics[task]:\n",
    "            idx += 1\n",
    "            temp += rel_perf(np.expand_dims(np.array(metric_results[metric]), axis=1), metrics_prop[metric])\n",
    "        task_rel_perf[task] = temp/idx\n",
    "        \n",
    "    # Add results to dataframe\n",
    "    task0_idx = tasks.index(two_task[0])\n",
    "    task1_idx = tasks.index(two_task[1])\n",
    "    col_name = '(' + str(task0_idx) + ', '+ str(task1_idx) + ')' + '-'\n",
    "    idx = 0\n",
    "    for task in two_task:\n",
    "        metric_df[col_name+str(idx)] = np.squeeze(task_rel_perf[task])\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Excel\n",
    "metric_df.to_excel(\"./2task/\" + data + \"_2task_metrics_\" + model + \"_\" + date + \"_val_acc.xlsx\", index_label='branch')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0, 1)-0</th>\n",
       "      <th>(0, 1)-1</th>\n",
       "      <th>(0, 2)-0</th>\n",
       "      <th>(0, 2)-1</th>\n",
       "      <th>(1, 2)-0</th>\n",
       "      <th>(1, 2)-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.756551</td>\n",
       "      <td>0.206613</td>\n",
       "      <td>1.101209</td>\n",
       "      <td>0.762078</td>\n",
       "      <td>-17.952050</td>\n",
       "      <td>-2.634157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.049282</td>\n",
       "      <td>-1.543906</td>\n",
       "      <td>2.578223</td>\n",
       "      <td>6.642063</td>\n",
       "      <td>-19.258973</td>\n",
       "      <td>-6.995612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.226608</td>\n",
       "      <td>-0.321529</td>\n",
       "      <td>2.155586</td>\n",
       "      <td>6.293724</td>\n",
       "      <td>-19.137206</td>\n",
       "      <td>-0.629648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.031691</td>\n",
       "      <td>0.910665</td>\n",
       "      <td>-0.233959</td>\n",
       "      <td>8.740496</td>\n",
       "      <td>-18.621772</td>\n",
       "      <td>3.480578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.002587</td>\n",
       "      <td>0.273969</td>\n",
       "      <td>-0.564342</td>\n",
       "      <td>8.774514</td>\n",
       "      <td>-19.128467</td>\n",
       "      <td>1.241206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.960275</td>\n",
       "      <td>2.428915</td>\n",
       "      <td>-1.746122</td>\n",
       "      <td>12.325905</td>\n",
       "      <td>-18.827467</td>\n",
       "      <td>1.628834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   (0, 1)-0  (0, 1)-1  (0, 2)-0   (0, 2)-1   (1, 2)-0  (1, 2)-1\n",
       "0  0.000000  0.000000  0.000000   0.000000   0.000000  0.000000\n",
       "1 -3.756551  0.206613  1.101209   0.762078 -17.952050 -2.634157\n",
       "2 -3.049282 -1.543906  2.578223   6.642063 -19.258973 -6.995612\n",
       "3 -3.226608 -0.321529  2.155586   6.293724 -19.137206 -0.629648\n",
       "4 -2.031691  0.910665 -0.233959   8.740496 -18.621772  3.480578\n",
       "5 -2.002587  0.273969 -0.564342   8.774514 -19.128467  1.241206\n",
       "6 -1.960275  2.428915 -1.746122  12.325905 -18.827467  1.628834"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Layout Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_perf_baselines(results, baselines, lower=True):\n",
    "    # Function: Compute rel. perf. for layouts\n",
    "    if lower:\n",
    "        return (baselines - results)/baselines*100\n",
    "    else:\n",
    "        return (results - baselines)/baselines*100\n",
    "    \n",
    "def save_obj(obj, name):\n",
    "    with open('./ntask/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('./ntask/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layout index for T=3, B=17/5, NYUv2\n",
    "# layout_idx = [383,342,415,344,278,251,231,161,65,484,329,481,268,374,79,55,368] # verify_1014 + verify_1012(xiao)\n",
    "# layout_idx = [0,55,72,86,103,200,227,239,349,376,485,493] # verify_1102 (coarse)\n",
    "# layout_idx = [484,492,487,495,379,397,267,486,490,387] # verify_1102 (flops)\n",
    "# layout_idx = [484,487] # verify_1116 (similar layouts)\n",
    "# layout_idx = [0,47,43,34,41,30,44,35,36,49,17,28,26,39,38,10,11,48,42,23,9,33,14,21,5,4,2] # verify_1118 (similar layouts, w/ coarse bps)\n",
    "layout_idx = [0,45,49,37,34] # top-5\n",
    "\n",
    "# Layout index for T=3, B=9/6, NYUv2\n",
    "# layout_idx = [11,18,20,25,24,131,137,111,113,106,110,101,115,125,68,42,66,67,96,100,46,61,91,35,72,88,86,77,84] # verify_1214\n",
    "# layout_idx = [8,12,14,19,16,62,65,59,61,67,58,53,27,28,45,38,1,48,25,3,23,37,32,22] # verify_0105\n",
    "base_2task = False # True: baseline from 2task baseline, False: baseline from policymtl\n",
    "base_2layout = False # True: baseline from layout 2 (the first layout idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_2task:\n",
    "    baselines = {'train_loss': [0.5333, 0.0603, 0.5743], 'val_loss': [1.609, 0.0636, 0.6785]}\n",
    "    # baselines from 2task b0 - only has metrics no loss now\n",
    "    for metric in baselines_2task:\n",
    "        baselines[metric] = mean(baselines_2task[metric])\n",
    "else:\n",
    "    # baselines are from policymtl\n",
    "    baselines = {'train_loss': [0.5333, 0.0603, 0.5743], 'val_loss': [1.609, 0.0636, 0.6785],\n",
    "                 'mIoU': 0.265, 'Pixel Acc': 0.582, \n",
    "                 'Angle Mean': 17.7, 'Angle Median': 16.3, 'Angle 11.25': 29.4, 'Angle 22.5': 72.3, 'Angle 30': 87.3,\n",
    "                 'abs_err': 0.62,'rel_err': 0.24,'sigma_1.25': 57.8,'sigma_1.25^2': 85.8,'sigma_1.25^3': 96} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_results = {'train_loss': [], 'val_loss': []}\n",
    "metric_results = {}\n",
    "for task in tasks:\n",
    "    for metric in metrics[task]:\n",
    "        metric_results[metric] = []\n",
    "        \n",
    "# For each layout\n",
    "for idx in layout_idx:\n",
    "    log = 'layout_' + str(idx) + '.stdout'\n",
    "    with open('./log/layout_'+data+'_'+model+'/'+log) as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "        if not confirm_complete(lines,iters):\n",
    "                print(str(idx) + ' not complete')\n",
    "                continue\n",
    "        avg_loss,_ = extract_loss_results(lines, tasks, reduce_var_length)\n",
    "        avg_metric = extract_metric_results(lines, tasks, metrics, reduce_var_length)\n",
    "        for mode in loss_results:\n",
    "                loss_results[mode].append(avg_loss[mode])\n",
    "        for task in tasks:\n",
    "            for metric in metrics[task]:\n",
    "                metric_results[metric].append(avg_metric[metric])\n",
    "                \n",
    "# Compute rel. perf.\n",
    "for mode in loss_results:\n",
    "    loss_results[mode] = rel_perf_baselines(np.array(loss_results[mode]), np.array(baselines[mode]))\n",
    "    \n",
    "task_rel_perf = {}\n",
    "for task in tasks:\n",
    "    temp = np.zeros(len(layout_idx))\n",
    "    idx = 0\n",
    "    for metric in metrics[task]:\n",
    "        idx += 1\n",
    "        if base_2layout:\n",
    "            temp += rel_perf_baselines(np.array(metric_results[metric]), metric_results[metric][-1], metrics_prop[metric])\n",
    "        else:\n",
    "            temp += rel_perf_baselines(np.array(metric_results[metric]), baselines[metric], metrics_prop[metric])\n",
    "    task_rel_perf[task] = temp/idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment_semantic\n",
      "-0.6232574726058531\n",
      "-3.111370464025586\n",
      "-4.416077719423376\n",
      "-0.800860187166347\n",
      "-3.4741187404093425\n",
      "normal\n",
      "6.371800935045249\n",
      "4.755908172256467\n",
      "2.2915749860420433\n",
      "4.91370000988694\n",
      "0.011035941535078031\n",
      "depth_zbuffer\n",
      "7.759144474720285\n",
      "5.926193747862684\n",
      "7.083578878365897\n",
      "2.9817553579413802\n",
      "6.868340550240836\n"
     ]
    }
   ],
   "source": [
    "for key in task_rel_perf:\n",
    "    print(key)\n",
    "    for value in task_rel_perf[key]:\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results to one dict\n",
    "real_results = {}\n",
    "real_results['layout'] = layout_idx\n",
    "\n",
    "for mode in loss_results:\n",
    "    real_results[mode] = loss_results[mode]\n",
    "    \n",
    "val_acc = None\n",
    "for task in task_rel_perf:\n",
    "    if val_acc is None:\n",
    "        val_acc = np.expand_dims(task_rel_perf[task], axis=1)\n",
    "    else:\n",
    "        val_acc = np.concatenate((val_acc, np.expand_dims(task_rel_perf[task], axis=1)), axis=1)\n",
    "real_results['val_acc'] = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layout': [11,\n",
       "  18,\n",
       "  20,\n",
       "  25,\n",
       "  24,\n",
       "  131,\n",
       "  137,\n",
       "  111,\n",
       "  113,\n",
       "  106,\n",
       "  110,\n",
       "  101,\n",
       "  115,\n",
       "  125,\n",
       "  68,\n",
       "  42,\n",
       "  66,\n",
       "  67,\n",
       "  96,\n",
       "  100,\n",
       "  46,\n",
       "  61,\n",
       "  91,\n",
       "  35,\n",
       "  72,\n",
       "  88,\n",
       "  86,\n",
       "  77,\n",
       "  84],\n",
       " 'train_loss': array([[-80.91693231,   7.89386401,  11.2171339 ],\n",
       "        [-61.92012001,   8.57379768,  17.09037089],\n",
       "        [-56.20101256,   4.84245439, -26.64809333],\n",
       "        [-53.68648041,  10.72968491, -29.10325614],\n",
       "        [-56.98481155,  10.89552239, -19.71269371],\n",
       "        [-59.6624789 ,   5.32338308,  14.52550932],\n",
       "        [-61.37258579,   7.47927032,  15.54588194],\n",
       "        [-62.44515282,  -1.6252073 ,   9.08236114],\n",
       "        [-57.73860866,   2.98507463,  13.35713042],\n",
       "        [-54.46277892,   6.00331675,   1.23280515],\n",
       "        [-60.65816614,   4.74295191,   1.49225144],\n",
       "        [-76.49728108,   7.72802653,  11.97806025],\n",
       "        [-63.19894993,  -0.86235489,  12.65366533],\n",
       "        [-60.39564973,   8.8225539 ,  15.37523942],\n",
       "        [-75.08531783,   7.81094527,  12.31586279],\n",
       "        [-72.76579786,   7.36318408,   5.98990075],\n",
       "        [-68.30864429,   4.90878939,  13.25091416],\n",
       "        [-70.96943559,   6.16915423,  14.21034303],\n",
       "        [-65.71723233,  10.97844113,   3.04718788],\n",
       "        [-61.200075  ,  -2.85240464,   4.55859307],\n",
       "        [-59.94374648,   5.43946932, -11.54797144],\n",
       "        [-68.54865929,  -5.97014925, -21.15444889],\n",
       "        [-57.35795987,  11.06135987,  -4.62127808],\n",
       "        [-77.92612038,  -2.93532338,  -7.81298973],\n",
       "        [-58.43990249,   8.8225539 , -10.10795751],\n",
       "        [-63.8496156 ,   8.34162521,  15.46230193],\n",
       "        [-61.62385149,   9.95024876,  15.08619189],\n",
       "        [-66.81230077,   7.79436153,  -4.71356434],\n",
       "        [-57.46859179,   9.68490879,   2.56834407]]),\n",
       " 'val_loss': array([[ -2.45701264,  -0.94339623,  12.31147138],\n",
       "        [  2.83198674,  -3.98322851,   8.42544829],\n",
       "        [  3.02050963,   1.10062893,  -9.33431589],\n",
       "        [  3.45556246,  -2.14884696, -11.49103414],\n",
       "        [  4.24694427,  -0.41928721,  -6.72562024],\n",
       "        [  0.39361923,   1.72955975,   4.11692459],\n",
       "        [  0.3749741 ,   2.30607966,  12.33603537],\n",
       "        [  1.5330433 ,   0.1572327 ,   6.8091378 ],\n",
       "        [  0.62150404,   3.19706499,   0.84991403],\n",
       "        [  1.91216076,   1.41509434,  -2.76099239],\n",
       "        [ -1.34452041,   2.56813417,  -0.2259887 ],\n",
       "        [ -0.42262275,  -3.35429769,   8.71039057],\n",
       "        [  3.41620054,   1.99161426,  -0.9088676 ],\n",
       "        [  1.87279884,  -0.89098532,   5.32547286],\n",
       "        [ -0.65257924,  -1.51991614,  11.40751658],\n",
       "        [ -0.56764036,   0.62893082,  -1.96511914],\n",
       "        [ -0.18645121,  -1.10062893,   7.80643577],\n",
       "        [  1.27615496,  -0.99580713,   5.4482928 ],\n",
       "        [  2.06132173,  -5.45073375,  -0.34389585],\n",
       "        [  1.05655687,   1.10062893,   0.32915746],\n",
       "        [  2.67039569,   0.73375262,  -6.63718988],\n",
       "        [  1.87901388,  -1.88679245,  -6.19503807],\n",
       "        [  2.20219598,  -3.77358491,  -4.57381479],\n",
       "        [  1.35902217,   0.99580713,  -3.76811594],\n",
       "        [  3.18831572,  -8.01886792,  -3.92041268],\n",
       "        [  2.24777294,  -1.10062893,   9.64382216],\n",
       "        [  0.64222084,  -2.46331237,   3.15892901],\n",
       "        [  1.57033354,  -1.51991614,  -5.27143208],\n",
       "        [  1.61176714,  -3.30188679,   3.76320314]]),\n",
       " 'val_acc': array([[ -5.51982984,  -9.44745798,  11.52859322],\n",
       "        [ -3.273836  , -11.97148825,   9.98752639],\n",
       "        [ -0.9491181 ,  -7.60824157,  -2.74271437],\n",
       "        [ -0.89843679,  -8.42919929,  -3.21973403],\n",
       "        [  1.66248734,  -9.11144755,   0.28482578],\n",
       "        [ -2.11115996,  -7.56638078,   7.64656156],\n",
       "        [ -3.31216163,  -9.16870255,  11.45069208],\n",
       "        [ -3.41936634,  -9.03678648,   8.85908134],\n",
       "        [ -1.00277722,  -9.4212835 ,   6.16879251],\n",
       "        [ -1.36792819,  -7.40449656,   4.95399544],\n",
       "        [ -5.03128267,  -7.57678426,   5.48488241],\n",
       "        [ -5.29077459, -11.21335491,  10.00097138],\n",
       "        [ -2.74987776,  -8.43225399,   5.52368738],\n",
       "        [ -1.75081632,  -8.39368815,   9.13596689],\n",
       "        [ -3.8847446 , -10.44014359,  11.04452167],\n",
       "        [ -5.74619759,  -8.95900343,   4.67282927],\n",
       "        [ -3.41078646,  -9.88472229,   9.75088278],\n",
       "        [ -2.20108814, -10.06259615,   7.8765075 ],\n",
       "        [ -3.31611097, -10.66925041,   5.31810485],\n",
       "        [ -2.36613164,  -9.32039815,   5.87956713],\n",
       "        [ -1.79635294,  -7.08378529,   1.56372542],\n",
       "        [ -3.87009879,  -9.61169299,   0.39400031],\n",
       "        [ -2.06665487,  -9.14923339,   2.63785941],\n",
       "        [ -3.63400609,  -9.86076111,   3.19448628],\n",
       "        [  2.33913015, -11.04336637,   2.33525099],\n",
       "        [ -3.56084031,  -9.84445724,  10.52670996],\n",
       "        [ -4.29074488,  -9.09187914,   7.43977761],\n",
       "        [ -3.12675348, -10.44328419,   2.47954371],\n",
       "        [ -1.74029015,  -9.10309561,   8.0104433 ]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle\n",
    "save_obj(real_results, 'real_results_'+data+'_'+model+'_'+date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layout': [0,\n",
       "  47,\n",
       "  43,\n",
       "  34,\n",
       "  41,\n",
       "  30,\n",
       "  44,\n",
       "  35,\n",
       "  36,\n",
       "  49,\n",
       "  17,\n",
       "  28,\n",
       "  26,\n",
       "  39,\n",
       "  38,\n",
       "  10,\n",
       "  11,\n",
       "  48,\n",
       "  42,\n",
       "  23,\n",
       "  9,\n",
       "  33,\n",
       "  14,\n",
       "  21,\n",
       "  5,\n",
       "  4,\n",
       "  2],\n",
       " 'train_loss': array([[44.09713107, 31.06135987, 50.74003134],\n",
       "        [37.25295331, 17.03150912, 46.20755703],\n",
       "        [43.63585224, 14.14593698, 50.33257879],\n",
       "        [32.79579974,  6.41791045, 46.49138081],\n",
       "        [38.29739359, 14.12935323, 40.55371757],\n",
       "        [43.82711419,  5.42288557, 27.44384468],\n",
       "        [43.46709169, 14.24543947, 48.05676476],\n",
       "        [40.65254078,  9.2039801 , 37.2366359 ],\n",
       "        [33.59647478, 10.96185738, 45.76527947],\n",
       "        [42.26701669, 19.75124378, 49.67612746],\n",
       "        [35.35720983,  3.30016584, 18.22566603],\n",
       "        [38.72867054, 18.3747927 , 22.98276162],\n",
       "        [38.51490718, 26.71641791, 19.13285739],\n",
       "        [27.98987437, 17.87728027, 23.33275292],\n",
       "        [41.08944309, 13.53233831, 24.52376807],\n",
       "        [41.43821489,  3.34991708, 38.92913112],\n",
       "        [36.66604163,  3.5986733 , 44.8058506 ],\n",
       "        [34.14213388, 17.77777778, 43.41459168],\n",
       "        [41.68010501, 14.11276949, 36.42347205],\n",
       "        [38.28239265,  6.69983416, 23.91955424],\n",
       "        [41.04256516,  3.94693201, 20.89500261],\n",
       "        [30.14063379,  5.85406302, 24.35486679],\n",
       "        [44.38214888, 14.66003317, 11.92408149],\n",
       "        [39.6624789 ,  3.58208955, 16.73863834],\n",
       "        [43.42208888,  2.43781095, 16.53665332],\n",
       "        [44.63716482,  4.09618574,  8.79853735],\n",
       "        [39.1055691 ,  2.75290216, 14.48720181]]),\n",
       " 'val_loss': array([[ -4.90781023,  -1.88679245,  18.44755588],\n",
       "        [ -8.19142324,   2.41090147,  16.30066323],\n",
       "        [ -5.17712865,   0.26205451,  19.27781872],\n",
       "        [-13.78081624,   3.19706499,  12.02652911],\n",
       "        [ -4.73171742,  -1.57232704,  16.64947187],\n",
       "        [ -5.40087011,   1.62473795,  10.56251535],\n",
       "        [ -5.29314274,  -2.62054507,  18.1871776 ],\n",
       "        [-10.3024653 ,   1.36268344,  13.03365267],\n",
       "        [ -8.35301429,  -2.14884696,  16.49717514],\n",
       "        [-32.63103377,  -5.50314465,  18.20682879],\n",
       "        [ -5.15434017,   2.51572327,   5.2321297 ],\n",
       "        [ -3.77045784,  -5.55555556,   6.98108573],\n",
       "        [ -5.19163041,  -2.46331237,   7.45762712],\n",
       "        [ -8.04847732,  -6.07966457,   5.84622943],\n",
       "        [ -7.82887922,  -1.31027254,  10.39548023],\n",
       "        [ -7.93246323,   0.1572327 ,  11.03905674],\n",
       "        [-10.12844417,  -1.25786164,  14.95946942],\n",
       "        [-10.67536772,  -5.18867925,  14.06042741],\n",
       "        [-10.9384711 ,  -4.14046122,  13.42667649],\n",
       "        [ -5.52102755,  -0.68134172,   7.5018423 ],\n",
       "        [ -6.93184172,   0.        ,  10.35617784],\n",
       "        [ -9.25833851,   0.1048218 ,   8.1847212 ],\n",
       "        [ -4.23658587,  -6.49895178,   3.59616802],\n",
       "        [ -5.01968096,   0.47169811,   7.92434291],\n",
       "        [ -3.72902424,   0.41928721,   4.25939573],\n",
       "        [ -5.03211104,  -1.04821803,   0.50110538],\n",
       "        [ -5.01968096,  -0.26205451,   4.66715795]]),\n",
       " 'val_acc': array([[ 2.30733033,  5.86486154, 12.15434338],\n",
       "        [-1.81197838,  5.44911757, 10.09920543],\n",
       "        [ 2.70887755,  2.25301358, 12.97445157],\n",
       "        [-8.73451371,  0.83847795,  6.9104237 ],\n",
       "        [ 1.68930033,  2.4194702 , 11.41894981],\n",
       "        [ 2.46415017,  1.38518699,  7.27380967],\n",
       "        [ 1.86525835,  1.31816166, 11.50194198],\n",
       "        [-1.32210982,  0.93747984,  8.16468996],\n",
       "        [-2.90882843,  0.38843893, 11.4417927 ],\n",
       "        [-1.62197221,  1.81388795, 11.5060726 ],\n",
       "        [ 0.91078127,  0.01594282,  4.26661924],\n",
       "        [ 3.00611323,  2.50743955,  5.2357945 ],\n",
       "        [ 2.18381934,  3.21686026,  5.0929786 ],\n",
       "        [-3.40249408,  1.3984871 ,  5.17458056],\n",
       "        [ 0.08187978,  2.56794558,  6.44901444],\n",
       "        [ 1.92487509, -0.02960559,  8.8981697 ],\n",
       "        [-3.71213245, -1.07821309, 10.5832039 ],\n",
       "        [-3.28177852,  1.84633478,  8.9554095 ],\n",
       "        [-2.26216046,  2.41173319,  8.81803399],\n",
       "        [ 0.61483852, -0.29091142,  5.70601974],\n",
       "        [ 1.23240853, -0.45512009,  7.84122717],\n",
       "        [-4.45192052,  0.95531093,  6.05744965],\n",
       "        [ 3.86826766, -0.23479557,  1.91849209],\n",
       "        [ 4.02942093, -1.7926678 ,  5.85542595],\n",
       "        [ 3.36915945, -0.14133083,  3.42675914],\n",
       "        [ 4.39770014, -1.16139567,  0.38258474],\n",
       "        [ 2.71146341, -0.65749766,  2.85396713]])}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_obj('real_results_'+data+'_'+model+'_'+date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
