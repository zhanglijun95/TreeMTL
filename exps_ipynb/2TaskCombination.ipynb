{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from main.head import ASPPHeadNode\n",
    "from data.nyuv2_dataloader_adashare import NYU_v2\n",
    "from data.pixel2pixel_loss import NYUCriterions\n",
    "from data.pixel2pixel_metrics import NYUMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(backbone='resnet34', branch=0, bz=64, ckpt_dir='checkpoint/', data='Taskonomy', dataroot='/mnt/nfs/work1/huiguan/lijunzhang/policymtl/data/', decay_lr_freq=10000, decay_lr_rate=0.3, exp_dir='exp', loss_lambda=[1, 1], lr=0.0001, print_iters=10, projectroot='/mnt/nfs/work1/huiguan/lijunzhang/multibranch/', reload_ckpt=None, save_iters=500, seed=10, total_iters=50000, two_task=['segment_semantic', 'normal'], val_iters=20)\n",
      "[Iter 10 Task segm] Train Loss: 1.7091\n",
      "[Iter 10 Task norm] Train Loss: 0.4213\n",
      "[Iter 10 Total] Train Loss: 2.1304\n",
      "======================================================================\n",
      "[Iter 20 Task segm] Train Loss: 1.6368\n",
      "[Iter 20 Task norm] Train Loss: 0.3136\n",
      "[Iter 20 Total] Train Loss: 1.9503\n",
      "======================================================================\n",
      "^C\n",
      "Error in loading mcdade/rgb/point_19_view_11_domain_rgb.png\n"
     ]
    }
   ],
   "source": [
    "!python two_task_exp.py --exp_dir='exp' --data='Taskonomy' --batch_size=64 --backbone='resnet34' --branch=0 --two_task 'segment_semantic' 'normal' --total_iters=50000 --lr=0.0001 --decay_lr_freq=10000 --decay_lr_rate=0.3 --print_iters=10 --save_iters=500 --val_iters=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplab Resnet with Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_par = True\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1, dilation=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "\n",
    "    kernel_size = np.asarray((3, 3))\n",
    "\n",
    "    # Compute the size of the upsampled filter with\n",
    "    # a specified dilation rate.\n",
    "    upsampled_kernel_size = (kernel_size - 1) * (dilation - 1) + kernel_size\n",
    "\n",
    "    # Determine the padding that is necessary for full padding,\n",
    "    # meaning the output spatial size is equal to input spatial size\n",
    "    full_padding = (upsampled_kernel_size - 1) // 2\n",
    "\n",
    "    # Conv2d doesn't accept numpy arrays as arguments\n",
    "    full_padding, kernel_size = tuple(full_padding), tuple(kernel_size)\n",
    "\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride,\n",
    "                      padding=full_padding, dilation=dilation, bias=False)\n",
    "\n",
    "# No projection: identity shortcut\n",
    "# conv -> bn -> relu -> conv -> bn\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1):\n",
    "        super(BasicBlock, self).__init__() \n",
    "        self.conv1 = conv3x3(inplanes, planes, stride, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, affine = affine_par)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, affine = affine_par)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        y = self.bn2(out)\n",
    "        return y\n",
    "    \n",
    "# Add residual projection\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, block, ds):\n",
    "        super(ResidualBlock, self).__init__() \n",
    "        self.block = block\n",
    "        self.ds = ds\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.ds(x) if self.ds is not None else x\n",
    "        x = F.relu(residual + self.block(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deeplab_ResNet_Backbone_Branch(nn.Module):\n",
    "    def __init__(self, block, layers, branch=None, task_num=2):\n",
    "        super(Deeplab_ResNet_Backbone_Branch, self).__init__()\n",
    "        \n",
    "        self.inplanes = 64\n",
    "        self.branch = branch\n",
    "        self.task_num = task_num\n",
    "\n",
    "        strides = [1, 2, 1, 1]\n",
    "        dilations = [1, 1, 2, 4]\n",
    "        filt_sizes = [64, 128, 256, 512]\n",
    "        self.shared_blocks, self.separate_blocks = [], []\n",
    "        self.layer_config = layers\n",
    "        \n",
    "        branch_cnt = 0\n",
    "        seed = self._make_seed()\n",
    "        self.__add_to_share_or_separate(branch_cnt, seed)\n",
    "        branch_cnt += 1\n",
    "        \n",
    "        for segment, num_blocks in enumerate(self.layer_config):\n",
    "            filt_size, num_blocks, stride, dilation = filt_sizes[segment],layers[segment],strides[segment],dilations[segment]\n",
    "            for b_idx in range(num_blocks):\n",
    "                blocklayer = self._make_blocklayer(b_idx, block, filt_size, stride=stride, dilation=dilation)\n",
    "                self.__add_to_share_or_separate(branch_cnt, blocklayer)\n",
    "                branch_cnt += 1\n",
    "\n",
    "        self.shared_blocks = nn.ModuleList(self.shared_blocks)\n",
    "        self.separate_blocks = nn.ModuleList(self.separate_blocks) \n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_seed(self):\n",
    "        seed = nn.Sequential(nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "                             nn.BatchNorm2d(64, affine=affine_par),\n",
    "                             nn.ReLU(inplace=True),\n",
    "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)) \n",
    "        return seed\n",
    "    \n",
    "    def _make_downsample(self, block, inplanes, planes, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion or dilation == 2 or dilation == 4:\n",
    "            downsample = nn.Sequential(nn.Conv2d(inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                                       nn.BatchNorm2d(planes * block.expansion, affine = affine_par))\n",
    "        return downsample\n",
    "    \n",
    "    def _make_blocklayer(self, block_idx, block, planes, stride=1, dilation=1):\n",
    "        ds = None\n",
    "        if block_idx == 0:\n",
    "            basic_block = block(self.inplanes, planes, stride, dilation=dilation)\n",
    "            ds = self._make_downsample(block, self.inplanes, planes, stride=stride, dilation=dilation)\n",
    "            self.inplanes = planes * block.expansion\n",
    "        else:\n",
    "            basic_block = block(self.inplanes, planes, dilation=dilation)\n",
    "            \n",
    "        blocklayer = ResidualBlock(basic_block, ds)\n",
    "        return blocklayer\n",
    "    \n",
    "    def __add_to_share_or_separate(self, branch_cnt, block):\n",
    "        if self.branch is None or branch_cnt < self.branch:\n",
    "            self.shared_blocks.append(block)\n",
    "        else:\n",
    "            multiple_blocks = []\n",
    "            for i in range(self.task_num):\n",
    "                multiple_blocks.append(copy.deepcopy(block))\n",
    "            self.separate_blocks.append(nn.ModuleList(multiple_blocks))\n",
    "        return\n",
    "\n",
    "    def forward(self, x): \n",
    "        for block in self.shared_blocks:\n",
    "            x = block(x)\n",
    "#         return x\n",
    "        output = [x] * self.task_num\n",
    "        for multiple_blocks in self.separate_blocks:\n",
    "            for i in range(self.task_num):\n",
    "                output[i] = multiple_blocks[i](output[i])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = Deeplab_ResNet_Backbone_Branch(BasicBlock, [3, 4, 6, 3], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deeplab_ResNet_Backbone_Branch(\n",
      "  (shared_blocks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (ds): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (ds): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (ds): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): ResidualBlock(\n",
      "      (block): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (separate_blocks): ModuleList()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dot(var, params=None):\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style=\"filled\", shape=\"box\", align=\"left\", fontsize=\"12\", ranksep=\"0.1\", height=\"0.2\")\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return \"(\" + (\", \").join([\"%d\" % v for v in size]) + \")\"\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor=\"orange\")\n",
    "                dot.edge(str(id(var.grad_fn)), str(id(var)))\n",
    "                var = var.grad_fn\n",
    "            if hasattr(var, \"variable\"):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else \"\"\n",
    "                node_name = \"%s\\n %s\" % (name, size_to_str(u.size()))\n",
    "#                 print(node_name)\n",
    "                \n",
    "                dot.node(str(id(var)), node_name, fillcolor=\"lightblue\")\n",
    "            else:\n",
    "                print(type(var).__name__)\n",
    "                \n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, \"next_functions\"):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, \"saved_tensors\"):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "\n",
    "    add_nodes(var)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReluBackward0\n",
      "AddBackward0\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "ReluBackward0\n",
      "AddBackward0\n",
      "MaxPool2DWithIndicesBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "MkldnnConvolutionBackward\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n",
      "ReluBackward1\n",
      "NativeBatchNormBackward\n",
      "SlowConvDilated2DBackward\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(1, 3, 224, 224)\n",
    "y = backbone(inputs)\n",
    "g = make_dot(y)\n",
    "g.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deeplab_ASPP_Branch(nn.Module):\n",
    "    def __init__(self, branch, cls_num):\n",
    "        super(Deeplab_ASPP_Branch, self).__init__()\n",
    "        self.branch = branch\n",
    "        self.backbone = Deeplab_ResNet_Backbone_Branch(BasicBlock, [3, 4, 6, 3], branch, len(cls_num))\n",
    "        self.heads = nn.ModuleDict()\n",
    "        for task in cls_num:\n",
    "            self.heads[task] = ASPPHeadNode(512, cls_num[task])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        output = {}\n",
    "        idx = 0\n",
    "        for task in self.heads:\n",
    "            output[task] = self.heads[task](features[idx])\n",
    "            idx += 1\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on NYUv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, two_task, train_dataloader, val_dataloader, criterion_dict, metric_dict, \n",
    "                 lr=0.001, decay_lr_freq=4000, decay_lr_rate=0.5,\n",
    "                 print_iters=50, val_iters=200, save_iters=200):\n",
    "        super(Trainer, self).__init__()\n",
    "        self.model = model\n",
    "        self.startIter = 0\n",
    "        self.optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()), lr=lr, betas=(0.5, 0.999), weight_decay=0.0001)\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=decay_lr_freq, gamma=decay_lr_rate)\n",
    "        \n",
    "        self.two_task = two_task\n",
    "        \n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.train_iter = iter(self.train_dataloader)\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.criterion_dict = criterion_dict\n",
    "        self.metric_dict = metric_dict\n",
    "        \n",
    "        self.loss_list = {}\n",
    "        self.set_train_loss()\n",
    "        \n",
    "        self.print_iters = print_iters\n",
    "        self.val_iters = val_iters\n",
    "        self.save_iters = save_iters\n",
    "    \n",
    "    def train(self, iters, loss_lambda, savePath=None, reload=None):\n",
    "        self.model.train()\n",
    "        if reload is not None and savePath is not None:\n",
    "            self.load_model(savePath, reload)\n",
    "\n",
    "        for i in range(self.startIter, iters):\n",
    "            self.train_step(loss_lambda)\n",
    "\n",
    "            if (i+1) % self.print_iters == 0:\n",
    "                self.print_train_loss(i)\n",
    "                self.set_train_loss()\n",
    "            if (i+1) % self.val_iters == 0:\n",
    "                self.validate(i)\n",
    "            if (i+1) % self.save_iters == 0:\n",
    "                if savePath is not None:\n",
    "                    self.save_model(i, savePath)\n",
    "            \n",
    "        # Reset loss list and the data iters\n",
    "        self.set_train_loss()\n",
    "        return\n",
    "    \n",
    "    def train_step(self, loss_lambda):\n",
    "        self.model.train()\n",
    "        try:\n",
    "            data = next(self.train_iter)\n",
    "        except StopIteration:\n",
    "            self.train_iter = iter(self.train_dataloader)\n",
    "            data = next(self.train_iter)\n",
    "            \n",
    "        x = data['input'].cuda()\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(x)\n",
    "        \n",
    "        loss = 0\n",
    "        for task in self.two_task:\n",
    "            y = data[task].cuda()\n",
    "            if task + '_mask' in data:\n",
    "                tloss = self.criterion_dict[task](output[task], y, data[task + '_mask'].cuda())\n",
    "            else:\n",
    "                tloss = self.criterion_dict[task](output[task], y)\n",
    "                \n",
    "            self.loss_list[task].append(tloss.item())\n",
    "            loss += loss_lambda[task] * tloss\n",
    "        self.loss_list['total'].append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        if self.scheduler is not None:\n",
    "            self.scheduler.step()\n",
    "        return\n",
    "    \n",
    "    def validate(self, it):\n",
    "        self.model.eval()\n",
    "        loss_list = {}\n",
    "        for task in self.two_task:\n",
    "            loss_list[task] = []\n",
    "        \n",
    "        for i, data in enumerate(self.val_dataloader):\n",
    "            x = data['input'].cuda()\n",
    "            output = self.model(x)\n",
    "\n",
    "            for task in self.two_task:\n",
    "                y = data[task].cuda()\n",
    "                if task + '_mask' in data:\n",
    "                    tloss = self.criterion_dict[task](output[task], y, data[task + '_mask'].cuda())\n",
    "                    self.metric_dict[task](output[task], y, data[task + '_mask'].cuda())\n",
    "                else:\n",
    "                    tloss = self.criterion_dict[task](output[task], y)\n",
    "                    self.metric_dict[task](output[task], y)\n",
    "                loss_list[task].append(tloss.item())\n",
    "\n",
    "        for task in self.two_task:\n",
    "            val_results = self.metric_dict[task].val_metrics()\n",
    "            print('[Iter {} Task {}] Val Loss: {:.4f}'.format((it+1), task[:4], np.mean(loss_list[task])), flush=True)\n",
    "            print(val_results, flush=True)\n",
    "        print('======================================================================', flush=True)\n",
    "        return\n",
    "    \n",
    "    # helper functions\n",
    "    def set_train_loss(self):\n",
    "        for task in self.two_task:\n",
    "            self.loss_list[task] = []\n",
    "        self.loss_list['total'] = []\n",
    "        return\n",
    "    \n",
    "    def load_model(self, savePath, reload):\n",
    "        state = torch.load(savePath + reload)\n",
    "        if self.two_task[0] in reload and self.two_task[1] in reload:\n",
    "            self.startIter = state['iter'] + 1\n",
    "            self.model.load_state_dict(state['state_dict'])\n",
    "            self.optimizer.load_state_dict(state['optimizer'])\n",
    "            self.scheduler.load_state_dict(state['scheduler'])\n",
    "        else:\n",
    "            print('Cannot load from models trained from different tasks.')\n",
    "            exit()\n",
    "        return\n",
    "    \n",
    "    def save_model(self, it, savePath):\n",
    "        state = {'iter': it,\n",
    "                'state_dict': self.model.state_dict(),\n",
    "                'optimizer': self.optimizer.state_dict(),\n",
    "                'scheduler': self.scheduler.state_dict()}\n",
    "        branch = '_allshare' if self.model.branch is None else '_b'+ str(self.model.branch)\n",
    "        torch.save(state, savePath + self.two_task[0] + '_' + self.two_task[1] + branch + '.model')\n",
    "        return\n",
    "    \n",
    "    def print_train_loss(self, it):\n",
    "        # Function: Print loss for each task\n",
    "        for task in self.two_task:\n",
    "            if self.loss_list[task]:\n",
    "                avg_loss = np.mean(self.loss_list[task])\n",
    "            else:\n",
    "                continue\n",
    "            print('[Iter {} Task {}] Train Loss: {:.4f}'.format((it+1), task[:4], avg_loss), flush=True)\n",
    "        print('[Iter {} Total] Train Loss: {:.4f}'.format((it+1), np.mean(self.loss_list['total'])), flush=True)\n",
    "        print('======================================================================', flush=True)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/mnt/nfs/work1/huiguan/lijunzhang/policymtl/data/NYUv2/'\n",
    "tasks = ('segment_semantic','normal','depth_zbuffer')\n",
    "task_cls_num = {'segment_semantic': 40, 'normal':3, 'depth_zbuffer': 1}\n",
    "\n",
    "\n",
    "criterionDict = {}\n",
    "metricDict = {}\n",
    "clsNum = {}\n",
    "two_task = ['segment_semantic','depth_zbuffer']\n",
    "dataset = NYU_v2(dataroot, 'train', crop_h=321, crop_w=321)\n",
    "trainDataloader = DataLoader(dataset, 16, shuffle=True)\n",
    "\n",
    "dataset = NYU_v2(dataroot, 'test', crop_h=321, crop_w=321)\n",
    "valDataloader = DataLoader(dataset, 16, shuffle=True)\n",
    "\n",
    "for task in two_task:\n",
    "    criterionDict[task] = NYUCriterions(task)\n",
    "    metricDict[task] = NYUMetrics(task)\n",
    "    clsNum[task] = task_cls_num[task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(0,1): # in shell\n",
    "    model = Deeplab_ASPP_Branch(b, clsNum)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 50 Task segm] Train Loss: 3.4915\n",
      "[Iter 50 Task dept] Train Loss: 2.5242\n",
      "[Iter 50 Total] Train Loss: 6.0157\n",
      "======================================================================\n",
      "[Iter 100 Task segm] Train Loss: 2.7859\n",
      "[Iter 100 Task dept] Train Loss: 1.1379\n",
      "[Iter 100 Total] Train Loss: 3.9238\n",
      "======================================================================\n",
      "[Iter 150 Task segm] Train Loss: 2.7230\n",
      "[Iter 150 Task dept] Train Loss: 1.0866\n",
      "[Iter 150 Total] Train Loss: 3.8096\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Train Loss: 2.6157\n",
      "[Iter 200 Task dept] Train Loss: 1.0742\n",
      "[Iter 200 Total] Train Loss: 3.6899\n",
      "======================================================================\n",
      "[Iter 200 Task segm] Val Loss: 2.5310\n",
      "{'mIoU': 0.1232, 'Pixel Acc': 0.3489}\n",
      "[Iter 200 Task dept] Val Loss: 1.0999\n",
      "{'abs_err': 1.0833, 'rel_err': 0.3499, 'sigma_1.25': 28.6498, 'sigma_1.25^2': 57.9327, 'sigma_1.25^3': 80.7769}\n",
      "======================================================================\n",
      "[Iter 250 Task segm] Train Loss: 2.5960\n",
      "[Iter 250 Task dept] Train Loss: 1.0750\n",
      "[Iter 250 Total] Train Loss: 3.6710\n",
      "======================================================================\n",
      "[Iter 300 Task segm] Train Loss: 2.6063\n",
      "[Iter 300 Task dept] Train Loss: 1.0867\n",
      "[Iter 300 Total] Train Loss: 3.6930\n",
      "======================================================================\n",
      "[Iter 350 Task segm] Train Loss: 2.5760\n",
      "[Iter 350 Task dept] Train Loss: 1.1205\n",
      "[Iter 350 Total] Train Loss: 3.6965\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Train Loss: 2.5294\n",
      "[Iter 400 Task dept] Train Loss: 1.0804\n",
      "[Iter 400 Total] Train Loss: 3.6098\n",
      "======================================================================\n",
      "[Iter 400 Task segm] Val Loss: 2.5098\n",
      "{'mIoU': 0.1332, 'Pixel Acc': 0.3545}\n",
      "[Iter 400 Task dept] Val Loss: 1.1182\n",
      "{'abs_err': 1.1021, 'rel_err': 0.3516, 'sigma_1.25': 27.917, 'sigma_1.25^2': 56.7136, 'sigma_1.25^3': 79.97}\n",
      "======================================================================\n",
      "[Iter 450 Task segm] Train Loss: 2.4952\n",
      "[Iter 450 Task dept] Train Loss: 1.0699\n",
      "[Iter 450 Total] Train Loss: 3.5651\n",
      "======================================================================\n",
      "[Iter 500 Task segm] Train Loss: 2.5588\n",
      "[Iter 500 Task dept] Train Loss: 1.1130\n",
      "[Iter 500 Total] Train Loss: 3.6718\n",
      "======================================================================\n",
      "[Iter 550 Task segm] Train Loss: 2.4943\n",
      "[Iter 550 Task dept] Train Loss: 1.0771\n",
      "[Iter 550 Total] Train Loss: 3.5714\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Train Loss: 2.4610\n",
      "[Iter 600 Task dept] Train Loss: 1.0396\n",
      "[Iter 600 Total] Train Loss: 3.5007\n",
      "======================================================================\n",
      "[Iter 600 Task segm] Val Loss: 2.5009\n",
      "{'mIoU': 0.103, 'Pixel Acc': 0.3601}\n",
      "[Iter 600 Task dept] Val Loss: 1.1263\n",
      "{'abs_err': 1.1112, 'rel_err': 0.353, 'sigma_1.25': 26.8852, 'sigma_1.25^2': 55.7188, 'sigma_1.25^3': 79.4982}\n",
      "======================================================================\n",
      "[Iter 650 Task segm] Train Loss: 2.4395\n",
      "[Iter 650 Task dept] Train Loss: 1.0507\n",
      "[Iter 650 Total] Train Loss: 3.4902\n",
      "======================================================================\n",
      "[Iter 700 Task segm] Train Loss: 2.4248\n",
      "[Iter 700 Task dept] Train Loss: 1.0988\n",
      "[Iter 700 Total] Train Loss: 3.5236\n",
      "======================================================================\n",
      "[Iter 750 Task segm] Train Loss: 2.4217\n",
      "[Iter 750 Task dept] Train Loss: 1.0618\n",
      "[Iter 750 Total] Train Loss: 3.4834\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Train Loss: 2.3857\n",
      "[Iter 800 Task dept] Train Loss: 1.0283\n",
      "[Iter 800 Total] Train Loss: 3.4140\n",
      "======================================================================\n",
      "[Iter 800 Task segm] Val Loss: 2.4332\n",
      "{'mIoU': 0.1302, 'Pixel Acc': 0.3494}\n",
      "[Iter 800 Task dept] Val Loss: 1.1384\n",
      "{'abs_err': 1.123, 'rel_err': 0.3558, 'sigma_1.25': 26.3939, 'sigma_1.25^2': 54.8809, 'sigma_1.25^3': 78.9108}\n",
      "======================================================================\n",
      "[Iter 850 Task segm] Train Loss: 2.3599\n",
      "[Iter 850 Task dept] Train Loss: 1.1062\n",
      "[Iter 850 Total] Train Loss: 3.4661\n",
      "======================================================================\n",
      "[Iter 900 Task segm] Train Loss: 2.3711\n",
      "[Iter 900 Task dept] Train Loss: 1.0469\n",
      "[Iter 900 Total] Train Loss: 3.4180\n",
      "======================================================================\n",
      "[Iter 950 Task segm] Train Loss: 2.3575\n",
      "[Iter 950 Task dept] Train Loss: 1.0393\n",
      "[Iter 950 Total] Train Loss: 3.3968\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Train Loss: 2.3127\n",
      "[Iter 1000 Task dept] Train Loss: 1.0224\n",
      "[Iter 1000 Total] Train Loss: 3.3350\n",
      "======================================================================\n",
      "[Iter 1000 Task segm] Val Loss: 2.5304\n",
      "{'mIoU': 0.0812, 'Pixel Acc': 0.3296}\n",
      "[Iter 1000 Task dept] Val Loss: 1.1663\n",
      "{'abs_err': 1.1514, 'rel_err': 0.3645, 'sigma_1.25': 26.7919, 'sigma_1.25^2': 54.0629, 'sigma_1.25^3': 76.8165}\n",
      "======================================================================\n",
      "[Iter 1050 Task segm] Train Loss: 2.3054\n",
      "[Iter 1050 Task dept] Train Loss: 1.0262\n",
      "[Iter 1050 Total] Train Loss: 3.3317\n",
      "======================================================================\n",
      "[Iter 1100 Task segm] Train Loss: 2.2512\n",
      "[Iter 1100 Task dept] Train Loss: 1.0293\n",
      "[Iter 1100 Total] Train Loss: 3.2805\n",
      "======================================================================\n",
      "[Iter 1150 Task segm] Train Loss: 2.3030\n",
      "[Iter 1150 Task dept] Train Loss: 1.0420\n",
      "[Iter 1150 Total] Train Loss: 3.3450\n",
      "======================================================================\n",
      "[Iter 1200 Task segm] Train Loss: 2.2434\n",
      "[Iter 1200 Task dept] Train Loss: 1.0361\n",
      "[Iter 1200 Total] Train Loss: 3.2795\n",
      "======================================================================\n",
      "[Iter 1200 Task segm] Val Loss: 2.3779\n",
      "{'mIoU': 0.1041, 'Pixel Acc': 0.3538}\n",
      "[Iter 1200 Task dept] Val Loss: 1.0310\n",
      "{'abs_err': 1.0167, 'rel_err': 0.3386, 'sigma_1.25': 32.757, 'sigma_1.25^2': 63.8553, 'sigma_1.25^3': 84.0213}\n",
      "======================================================================\n",
      "[Iter 1250 Task segm] Train Loss: 2.2131\n",
      "[Iter 1250 Task dept] Train Loss: 1.0426\n",
      "[Iter 1250 Total] Train Loss: 3.2556\n",
      "======================================================================\n",
      "[Iter 1300 Task segm] Train Loss: 2.2243\n",
      "[Iter 1300 Task dept] Train Loss: 1.0551\n",
      "[Iter 1300 Total] Train Loss: 3.2795\n",
      "======================================================================\n",
      "[Iter 1350 Task segm] Train Loss: 2.1837\n",
      "[Iter 1350 Task dept] Train Loss: 1.0001\n",
      "[Iter 1350 Total] Train Loss: 3.1838\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Train Loss: 2.1640\n",
      "[Iter 1400 Task dept] Train Loss: 1.0309\n",
      "[Iter 1400 Total] Train Loss: 3.1949\n",
      "======================================================================\n",
      "[Iter 1400 Task segm] Val Loss: 2.3774\n",
      "{'mIoU': 0.0945, 'Pixel Acc': 0.35}\n",
      "[Iter 1400 Task dept] Val Loss: 0.9271\n",
      "{'abs_err': 0.917, 'rel_err': 0.3419, 'sigma_1.25': 39.9019, 'sigma_1.25^2': 70.279, 'sigma_1.25^3': 87.2946}\n",
      "======================================================================\n",
      "[Iter 1450 Task segm] Train Loss: 2.1421\n",
      "[Iter 1450 Task dept] Train Loss: 1.0723\n",
      "[Iter 1450 Total] Train Loss: 3.2145\n",
      "======================================================================\n",
      "[Iter 1500 Task segm] Train Loss: 2.1303\n",
      "[Iter 1500 Task dept] Train Loss: 1.0277\n",
      "[Iter 1500 Total] Train Loss: 3.1580\n",
      "======================================================================\n",
      "[Iter 1550 Task segm] Train Loss: 2.1191\n",
      "[Iter 1550 Task dept] Train Loss: 1.0459\n",
      "[Iter 1550 Total] Train Loss: 3.1650\n",
      "======================================================================\n",
      "[Iter 1600 Task segm] Train Loss: 2.0737\n",
      "[Iter 1600 Task dept] Train Loss: 1.0306\n",
      "[Iter 1600 Total] Train Loss: 3.1043\n",
      "======================================================================\n",
      "[Iter 1600 Task segm] Val Loss: 2.1243\n",
      "{'mIoU': 0.103, 'Pixel Acc': 0.4224}\n",
      "[Iter 1600 Task dept] Val Loss: 0.9603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abs_err': 0.9491, 'rel_err': 0.3347, 'sigma_1.25': 37.5332, 'sigma_1.25^2': 68.5595, 'sigma_1.25^3': 86.4294}\n",
      "======================================================================\n",
      "[Iter 1650 Task segm] Train Loss: 2.0657\n",
      "[Iter 1650 Task dept] Train Loss: 1.0116\n",
      "[Iter 1650 Total] Train Loss: 3.0773\n",
      "======================================================================\n",
      "[Iter 1700 Task segm] Train Loss: 2.0888\n",
      "[Iter 1700 Task dept] Train Loss: 1.0177\n",
      "[Iter 1700 Total] Train Loss: 3.1065\n",
      "======================================================================\n",
      "[Iter 1750 Task segm] Train Loss: 2.0309\n",
      "[Iter 1750 Task dept] Train Loss: 1.0119\n",
      "[Iter 1750 Total] Train Loss: 3.0428\n",
      "======================================================================\n",
      "[Iter 1800 Task segm] Train Loss: 2.0348\n",
      "[Iter 1800 Task dept] Train Loss: 1.0511\n",
      "[Iter 1800 Total] Train Loss: 3.0860\n",
      "======================================================================\n",
      "[Iter 1800 Task segm] Val Loss: 2.5144\n",
      "{'mIoU': 0.0968, 'Pixel Acc': 0.383}\n",
      "[Iter 1800 Task dept] Val Loss: 0.8844\n",
      "{'abs_err': 0.8771, 'rel_err': 0.3523, 'sigma_1.25': 42.7551, 'sigma_1.25^2': 72.0901, 'sigma_1.25^3': 88.4133}\n",
      "======================================================================\n",
      "[Iter 1850 Task segm] Train Loss: 2.0320\n",
      "[Iter 1850 Task dept] Train Loss: 1.0121\n",
      "[Iter 1850 Total] Train Loss: 3.0440\n",
      "======================================================================\n",
      "[Iter 1900 Task segm] Train Loss: 2.0154\n",
      "[Iter 1900 Task dept] Train Loss: 1.0177\n",
      "[Iter 1900 Total] Train Loss: 3.0331\n",
      "======================================================================\n",
      "[Iter 1950 Task segm] Train Loss: 1.9834\n",
      "[Iter 1950 Task dept] Train Loss: 1.0376\n",
      "[Iter 1950 Total] Train Loss: 3.0210\n",
      "======================================================================\n",
      "[Iter 2000 Task segm] Train Loss: 1.9737\n",
      "[Iter 2000 Task dept] Train Loss: 1.0000\n",
      "[Iter 2000 Total] Train Loss: 2.9737\n",
      "======================================================================\n",
      "[Iter 2000 Task segm] Val Loss: 2.1224\n",
      "{'mIoU': 0.1096, 'Pixel Acc': 0.4172}\n",
      "[Iter 2000 Task dept] Val Loss: 0.9120\n",
      "{'abs_err': 0.9026, 'rel_err': 0.3438, 'sigma_1.25': 40.6503, 'sigma_1.25^2': 71.0175, 'sigma_1.25^3': 87.9676}\n",
      "======================================================================\n",
      "[Iter 2050 Task segm] Train Loss: 1.9750\n",
      "[Iter 2050 Task dept] Train Loss: 1.0131\n",
      "[Iter 2050 Total] Train Loss: 2.9881\n",
      "======================================================================\n",
      "[Iter 2100 Task segm] Train Loss: 1.9475\n",
      "[Iter 2100 Task dept] Train Loss: 1.0039\n",
      "[Iter 2100 Total] Train Loss: 2.9513\n",
      "======================================================================\n",
      "[Iter 2150 Task segm] Train Loss: 1.9504\n",
      "[Iter 2150 Task dept] Train Loss: 1.0047\n",
      "[Iter 2150 Total] Train Loss: 2.9550\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Train Loss: 1.9310\n",
      "[Iter 2200 Task dept] Train Loss: 0.9934\n",
      "[Iter 2200 Total] Train Loss: 2.9243\n",
      "======================================================================\n",
      "[Iter 2200 Task segm] Val Loss: 2.0396\n",
      "{'mIoU': 0.1246, 'Pixel Acc': 0.4483}\n",
      "[Iter 2200 Task dept] Val Loss: 0.9832\n",
      "{'abs_err': 0.9712, 'rel_err': 0.3414, 'sigma_1.25': 36.6369, 'sigma_1.25^2': 67.0947, 'sigma_1.25^3': 85.2724}\n",
      "======================================================================\n",
      "[Iter 2250 Task segm] Train Loss: 1.9028\n",
      "[Iter 2250 Task dept] Train Loss: 0.9867\n",
      "[Iter 2250 Total] Train Loss: 2.8895\n",
      "======================================================================\n",
      "[Iter 2300 Task segm] Train Loss: 1.9006\n",
      "[Iter 2300 Task dept] Train Loss: 0.9922\n",
      "[Iter 2300 Total] Train Loss: 2.8928\n",
      "======================================================================\n",
      "[Iter 2350 Task segm] Train Loss: 1.8730\n",
      "[Iter 2350 Task dept] Train Loss: 0.9918\n",
      "[Iter 2350 Total] Train Loss: 2.8648\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Train Loss: 1.8650\n",
      "[Iter 2400 Task dept] Train Loss: 0.9868\n",
      "[Iter 2400 Total] Train Loss: 2.8518\n",
      "======================================================================\n",
      "[Iter 2400 Task segm] Val Loss: 2.2928\n",
      "{'mIoU': 0.1183, 'Pixel Acc': 0.4244}\n",
      "[Iter 2400 Task dept] Val Loss: 0.8927\n",
      "{'abs_err': 0.8851, 'rel_err': 0.3587, 'sigma_1.25': 42.2823, 'sigma_1.25^2': 71.8148, 'sigma_1.25^3': 87.8909}\n",
      "======================================================================\n",
      "[Iter 2450 Task segm] Train Loss: 1.8618\n",
      "[Iter 2450 Task dept] Train Loss: 0.9949\n",
      "[Iter 2450 Total] Train Loss: 2.8567\n",
      "======================================================================\n",
      "[Iter 2500 Task segm] Train Loss: 1.8625\n",
      "[Iter 2500 Task dept] Train Loss: 0.9779\n",
      "[Iter 2500 Total] Train Loss: 2.8404\n",
      "======================================================================\n",
      "[Iter 2550 Task segm] Train Loss: 1.8397\n",
      "[Iter 2550 Task dept] Train Loss: 0.9783\n",
      "[Iter 2550 Total] Train Loss: 2.8181\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Train Loss: 1.8098\n",
      "[Iter 2600 Task dept] Train Loss: 0.9658\n",
      "[Iter 2600 Total] Train Loss: 2.7756\n",
      "======================================================================\n",
      "[Iter 2600 Task segm] Val Loss: 1.8418\n",
      "{'mIoU': 0.1256, 'Pixel Acc': 0.475}\n",
      "[Iter 2600 Task dept] Val Loss: 0.8615\n",
      "{'abs_err': 0.8553, 'rel_err': 0.3512, 'sigma_1.25': 43.7469, 'sigma_1.25^2': 73.3927, 'sigma_1.25^3': 88.9832}\n",
      "======================================================================\n",
      "[Iter 2650 Task segm] Train Loss: 1.7952\n",
      "[Iter 2650 Task dept] Train Loss: 1.0072\n",
      "[Iter 2650 Total] Train Loss: 2.8024\n",
      "======================================================================\n",
      "[Iter 2700 Task segm] Train Loss: 1.8238\n",
      "[Iter 2700 Task dept] Train Loss: 0.9829\n",
      "[Iter 2700 Total] Train Loss: 2.8068\n",
      "======================================================================\n",
      "[Iter 2750 Task segm] Train Loss: 1.7560\n",
      "[Iter 2750 Task dept] Train Loss: 0.9593\n",
      "[Iter 2750 Total] Train Loss: 2.7154\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Train Loss: 1.7388\n",
      "[Iter 2800 Task dept] Train Loss: 1.0096\n",
      "[Iter 2800 Total] Train Loss: 2.7484\n",
      "======================================================================\n",
      "[Iter 2800 Task segm] Val Loss: 2.2364\n",
      "{'mIoU': 0.1264, 'Pixel Acc': 0.4273}\n",
      "[Iter 2800 Task dept] Val Loss: 0.8528\n",
      "{'abs_err': 0.8468, 'rel_err': 0.3674, 'sigma_1.25': 44.2895, 'sigma_1.25^2': 73.8186, 'sigma_1.25^3': 88.9491}\n",
      "======================================================================\n",
      "[Iter 2850 Task segm] Train Loss: 1.7448\n",
      "[Iter 2850 Task dept] Train Loss: 1.0048\n",
      "[Iter 2850 Total] Train Loss: 2.7495\n",
      "======================================================================\n",
      "[Iter 2900 Task segm] Train Loss: 1.7458\n",
      "[Iter 2900 Task dept] Train Loss: 0.9906\n",
      "[Iter 2900 Total] Train Loss: 2.7364\n",
      "======================================================================\n",
      "[Iter 2950 Task segm] Train Loss: 1.7347\n",
      "[Iter 2950 Task dept] Train Loss: 0.9677\n",
      "[Iter 2950 Total] Train Loss: 2.7023\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Train Loss: 1.7446\n",
      "[Iter 3000 Task dept] Train Loss: 0.9527\n",
      "[Iter 3000 Total] Train Loss: 2.6973\n",
      "======================================================================\n",
      "[Iter 3000 Task segm] Val Loss: 1.9093\n",
      "{'mIoU': 0.133, 'Pixel Acc': 0.4629}\n",
      "[Iter 3000 Task dept] Val Loss: 1.0062\n",
      "{'abs_err': 0.9939, 'rel_err': 0.3412, 'sigma_1.25': 35.3512, 'sigma_1.25^2': 65.7675, 'sigma_1.25^3': 84.4651}\n",
      "======================================================================\n",
      "[Iter 3050 Task segm] Train Loss: 1.6987\n",
      "[Iter 3050 Task dept] Train Loss: 0.9786\n",
      "[Iter 3050 Total] Train Loss: 2.6773\n",
      "======================================================================\n",
      "[Iter 3100 Task segm] Train Loss: 1.7044\n",
      "[Iter 3100 Task dept] Train Loss: 0.9897\n",
      "[Iter 3100 Total] Train Loss: 2.6941\n",
      "======================================================================\n",
      "[Iter 3150 Task segm] Train Loss: 1.6942\n",
      "[Iter 3150 Task dept] Train Loss: 0.9824\n",
      "[Iter 3150 Total] Train Loss: 2.6766\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Train Loss: 1.6436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 3200 Task dept] Train Loss: 0.9738\n",
      "[Iter 3200 Total] Train Loss: 2.6174\n",
      "======================================================================\n",
      "[Iter 3200 Task segm] Val Loss: 1.8375\n",
      "{'mIoU': 0.1634, 'Pixel Acc': 0.4861}\n",
      "[Iter 3200 Task dept] Val Loss: 0.8653\n",
      "{'abs_err': 0.8598, 'rel_err': 0.3718, 'sigma_1.25': 44.4399, 'sigma_1.25^2': 72.4958, 'sigma_1.25^3': 88.6351}\n",
      "======================================================================\n",
      "[Iter 3250 Task segm] Train Loss: 1.6363\n",
      "[Iter 3250 Task dept] Train Loss: 0.9772\n",
      "[Iter 3250 Total] Train Loss: 2.6135\n",
      "======================================================================\n",
      "[Iter 3300 Task segm] Train Loss: 1.6454\n",
      "[Iter 3300 Task dept] Train Loss: 1.0154\n",
      "[Iter 3300 Total] Train Loss: 2.6608\n",
      "======================================================================\n",
      "[Iter 3350 Task segm] Train Loss: 1.6443\n",
      "[Iter 3350 Task dept] Train Loss: 0.9918\n",
      "[Iter 3350 Total] Train Loss: 2.6361\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Train Loss: 1.6687\n",
      "[Iter 3400 Task dept] Train Loss: 0.9576\n",
      "[Iter 3400 Total] Train Loss: 2.6263\n",
      "======================================================================\n",
      "[Iter 3400 Task segm] Val Loss: 1.9532\n",
      "{'mIoU': 0.1414, 'Pixel Acc': 0.4555}\n",
      "[Iter 3400 Task dept] Val Loss: 0.8732\n",
      "{'abs_err': 0.8646, 'rel_err': 0.3417, 'sigma_1.25': 42.5594, 'sigma_1.25^2': 73.0343, 'sigma_1.25^3': 89.0462}\n",
      "======================================================================\n",
      "[Iter 3450 Task segm] Train Loss: 1.5997\n",
      "[Iter 3450 Task dept] Train Loss: 0.9691\n",
      "[Iter 3450 Total] Train Loss: 2.5688\n",
      "======================================================================\n",
      "[Iter 3500 Task segm] Train Loss: 1.6165\n",
      "[Iter 3500 Task dept] Train Loss: 0.9524\n",
      "[Iter 3500 Total] Train Loss: 2.5689\n",
      "======================================================================\n",
      "[Iter 3550 Task segm] Train Loss: 1.5940\n",
      "[Iter 3550 Task dept] Train Loss: 0.9659\n",
      "[Iter 3550 Total] Train Loss: 2.5599\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Train Loss: 1.6177\n",
      "[Iter 3600 Task dept] Train Loss: 0.9748\n",
      "[Iter 3600 Total] Train Loss: 2.5925\n",
      "======================================================================\n",
      "[Iter 3600 Task segm] Val Loss: 1.7889\n",
      "{'mIoU': 0.1573, 'Pixel Acc': 0.4847}\n",
      "[Iter 3600 Task dept] Val Loss: 0.8571\n",
      "{'abs_err': 0.8505, 'rel_err': 0.353, 'sigma_1.25': 44.4094, 'sigma_1.25^2': 73.4765, 'sigma_1.25^3': 89.1247}\n",
      "======================================================================\n",
      "[Iter 3650 Task segm] Train Loss: 1.5432\n",
      "[Iter 3650 Task dept] Train Loss: 0.9566\n",
      "[Iter 3650 Total] Train Loss: 2.4998\n",
      "======================================================================\n",
      "[Iter 3700 Task segm] Train Loss: 1.5903\n",
      "[Iter 3700 Task dept] Train Loss: 0.9663\n",
      "[Iter 3700 Total] Train Loss: 2.5566\n",
      "======================================================================\n",
      "[Iter 3750 Task segm] Train Loss: 1.5703\n",
      "[Iter 3750 Task dept] Train Loss: 0.9642\n",
      "[Iter 3750 Total] Train Loss: 2.5345\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Train Loss: 1.5841\n",
      "[Iter 3800 Task dept] Train Loss: 0.9549\n",
      "[Iter 3800 Total] Train Loss: 2.5390\n",
      "======================================================================\n",
      "[Iter 3800 Task segm] Val Loss: 1.8234\n",
      "{'mIoU': 0.1424, 'Pixel Acc': 0.4792}\n",
      "[Iter 3800 Task dept] Val Loss: 0.8734\n",
      "{'abs_err': 0.8704, 'rel_err': 0.3784, 'sigma_1.25': 44.0739, 'sigma_1.25^2': 72.2725, 'sigma_1.25^3': 87.8799}\n",
      "======================================================================\n",
      "[Iter 3850 Task segm] Train Loss: 1.5402\n",
      "[Iter 3850 Task dept] Train Loss: 0.9683\n",
      "[Iter 3850 Total] Train Loss: 2.5085\n",
      "======================================================================\n",
      "[Iter 3900 Task segm] Train Loss: 1.5086\n",
      "[Iter 3900 Task dept] Train Loss: 0.9435\n",
      "[Iter 3900 Total] Train Loss: 2.4520\n",
      "======================================================================\n",
      "[Iter 3950 Task segm] Train Loss: 1.5071\n",
      "[Iter 3950 Task dept] Train Loss: 0.9606\n",
      "[Iter 3950 Total] Train Loss: 2.4677\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Train Loss: 1.5006\n",
      "[Iter 4000 Task dept] Train Loss: 0.9486\n",
      "[Iter 4000 Total] Train Loss: 2.4492\n",
      "======================================================================\n",
      "[Iter 4000 Task segm] Val Loss: 1.7183\n",
      "{'mIoU': 0.1845, 'Pixel Acc': 0.5098}\n",
      "[Iter 4000 Task dept] Val Loss: 0.8750\n",
      "{'abs_err': 0.8677, 'rel_err': 0.3465, 'sigma_1.25': 43.1696, 'sigma_1.25^2': 72.8613, 'sigma_1.25^3': 88.7763}\n",
      "======================================================================\n",
      "[Iter 4050 Task segm] Train Loss: 1.4073\n",
      "[Iter 4050 Task dept] Train Loss: 0.9383\n",
      "[Iter 4050 Total] Train Loss: 2.3456\n",
      "======================================================================\n",
      "[Iter 4100 Task segm] Train Loss: 1.3586\n",
      "[Iter 4100 Task dept] Train Loss: 0.9419\n",
      "[Iter 4100 Total] Train Loss: 2.3005\n",
      "======================================================================\n",
      "[Iter 4150 Task segm] Train Loss: 1.3739\n",
      "[Iter 4150 Task dept] Train Loss: 0.9514\n",
      "[Iter 4150 Total] Train Loss: 2.3253\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Train Loss: 1.3396\n",
      "[Iter 4200 Task dept] Train Loss: 0.9411\n",
      "[Iter 4200 Total] Train Loss: 2.2807\n",
      "======================================================================\n",
      "[Iter 4200 Task segm] Val Loss: 1.6762\n",
      "{'mIoU': 0.1899, 'Pixel Acc': 0.5079}\n",
      "[Iter 4200 Task dept] Val Loss: 0.8553\n",
      "{'abs_err': 0.8481, 'rel_err': 0.3458, 'sigma_1.25': 44.1336, 'sigma_1.25^2': 73.776, 'sigma_1.25^3': 89.3637}\n",
      "======================================================================\n",
      "[Iter 4250 Task segm] Train Loss: 1.3024\n",
      "[Iter 4250 Task dept] Train Loss: 0.9454\n",
      "[Iter 4250 Total] Train Loss: 2.2478\n",
      "======================================================================\n",
      "[Iter 4300 Task segm] Train Loss: 1.3033\n",
      "[Iter 4300 Task dept] Train Loss: 0.9375\n",
      "[Iter 4300 Total] Train Loss: 2.2408\n",
      "======================================================================\n",
      "[Iter 4350 Task segm] Train Loss: 1.2933\n",
      "[Iter 4350 Task dept] Train Loss: 0.9598\n",
      "[Iter 4350 Total] Train Loss: 2.2531\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Train Loss: 1.2885\n",
      "[Iter 4400 Task dept] Train Loss: 0.9292\n",
      "[Iter 4400 Total] Train Loss: 2.2177\n",
      "======================================================================\n",
      "[Iter 4400 Task segm] Val Loss: 1.7507\n",
      "{'mIoU': 0.1982, 'Pixel Acc': 0.5088}\n",
      "[Iter 4400 Task dept] Val Loss: 0.9476\n",
      "{'abs_err': 0.9471, 'rel_err': 0.4465, 'sigma_1.25': 42.5094, 'sigma_1.25^2': 70.1179, 'sigma_1.25^3': 86.0588}\n",
      "======================================================================\n",
      "[Iter 4450 Task segm] Train Loss: 1.3189\n",
      "[Iter 4450 Task dept] Train Loss: 0.9322\n",
      "[Iter 4450 Total] Train Loss: 2.2511\n",
      "======================================================================\n",
      "[Iter 4500 Task segm] Train Loss: 1.2721\n",
      "[Iter 4500 Task dept] Train Loss: 0.9412\n",
      "[Iter 4500 Total] Train Loss: 2.2134\n",
      "======================================================================\n",
      "[Iter 4550 Task segm] Train Loss: 1.2833\n",
      "[Iter 4550 Task dept] Train Loss: 0.9357\n",
      "[Iter 4550 Total] Train Loss: 2.2190\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Train Loss: 1.2596\n",
      "[Iter 4600 Task dept] Train Loss: 0.9363\n",
      "[Iter 4600 Total] Train Loss: 2.1959\n",
      "======================================================================\n",
      "[Iter 4600 Task segm] Val Loss: 1.6020\n",
      "{'mIoU': 0.2141, 'Pixel Acc': 0.5344}\n",
      "[Iter 4600 Task dept] Val Loss: 0.8333\n",
      "{'abs_err': 0.8305, 'rel_err': 0.3677, 'sigma_1.25': 45.9824, 'sigma_1.25^2': 74.632, 'sigma_1.25^3': 89.2716}\n",
      "======================================================================\n",
      "[Iter 4650 Task segm] Train Loss: 1.2213\n",
      "[Iter 4650 Task dept] Train Loss: 0.9474\n",
      "[Iter 4650 Total] Train Loss: 2.1687\n",
      "======================================================================\n",
      "[Iter 4700 Task segm] Train Loss: 1.2629\n",
      "[Iter 4700 Task dept] Train Loss: 0.9473\n",
      "[Iter 4700 Total] Train Loss: 2.2102\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 4750 Task segm] Train Loss: 1.2529\n",
      "[Iter 4750 Task dept] Train Loss: 0.9404\n",
      "[Iter 4750 Total] Train Loss: 2.1933\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Train Loss: 1.2349\n",
      "[Iter 4800 Task dept] Train Loss: 0.9202\n",
      "[Iter 4800 Total] Train Loss: 2.1551\n",
      "======================================================================\n",
      "[Iter 4800 Task segm] Val Loss: 1.6546\n",
      "{'mIoU': 0.2051, 'Pixel Acc': 0.5191}\n",
      "[Iter 4800 Task dept] Val Loss: 0.8395\n",
      "{'abs_err': 0.8361, 'rel_err': 0.3689, 'sigma_1.25': 45.6967, 'sigma_1.25^2': 74.2456, 'sigma_1.25^3': 89.0871}\n",
      "======================================================================\n",
      "[Iter 4850 Task segm] Train Loss: 1.2198\n",
      "[Iter 4850 Task dept] Train Loss: 0.9252\n",
      "[Iter 4850 Total] Train Loss: 2.1450\n",
      "======================================================================\n",
      "[Iter 4900 Task segm] Train Loss: 1.2258\n",
      "[Iter 4900 Task dept] Train Loss: 0.9013\n",
      "[Iter 4900 Total] Train Loss: 2.1271\n",
      "======================================================================\n",
      "[Iter 4950 Task segm] Train Loss: 1.1846\n",
      "[Iter 4950 Task dept] Train Loss: 0.9313\n",
      "[Iter 4950 Total] Train Loss: 2.1159\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Train Loss: 1.2448\n",
      "[Iter 5000 Task dept] Train Loss: 0.9111\n",
      "[Iter 5000 Total] Train Loss: 2.1559\n",
      "======================================================================\n",
      "[Iter 5000 Task segm] Val Loss: 1.6400\n",
      "{'mIoU': 0.217, 'Pixel Acc': 0.5274}\n",
      "[Iter 5000 Task dept] Val Loss: 0.8354\n",
      "{'abs_err': 0.8327, 'rel_err': 0.3664, 'sigma_1.25': 45.7645, 'sigma_1.25^2': 74.4708, 'sigma_1.25^3': 89.1526}\n",
      "======================================================================\n",
      "[Iter 5050 Task segm] Train Loss: 1.2053\n",
      "[Iter 5050 Task dept] Train Loss: 0.9329\n",
      "[Iter 5050 Total] Train Loss: 2.1382\n",
      "======================================================================\n",
      "[Iter 5100 Task segm] Train Loss: 1.1743\n",
      "[Iter 5100 Task dept] Train Loss: 0.9337\n",
      "[Iter 5100 Total] Train Loss: 2.1079\n",
      "======================================================================\n",
      "[Iter 5150 Task segm] Train Loss: 1.1749\n",
      "[Iter 5150 Task dept] Train Loss: 0.9288\n",
      "[Iter 5150 Total] Train Loss: 2.1037\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Train Loss: 1.1958\n",
      "[Iter 5200 Task dept] Train Loss: 0.9246\n",
      "[Iter 5200 Total] Train Loss: 2.1203\n",
      "======================================================================\n",
      "[Iter 5200 Task segm] Val Loss: 1.7286\n",
      "{'mIoU': 0.184, 'Pixel Acc': 0.502}\n",
      "[Iter 5200 Task dept] Val Loss: 0.8564\n",
      "{'abs_err': 0.8515, 'rel_err': 0.3561, 'sigma_1.25': 44.7395, 'sigma_1.25^2': 73.3591, 'sigma_1.25^3': 88.8324}\n",
      "======================================================================\n",
      "[Iter 5250 Task segm] Train Loss: 1.1539\n",
      "[Iter 5250 Task dept] Train Loss: 0.9219\n",
      "[Iter 5250 Total] Train Loss: 2.0758\n",
      "======================================================================\n",
      "[Iter 5300 Task segm] Train Loss: 1.1505\n",
      "[Iter 5300 Task dept] Train Loss: 0.9088\n",
      "[Iter 5300 Total] Train Loss: 2.0593\n",
      "======================================================================\n",
      "[Iter 5350 Task segm] Train Loss: 1.1585\n",
      "[Iter 5350 Task dept] Train Loss: 0.9273\n",
      "[Iter 5350 Total] Train Loss: 2.0857\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Train Loss: 1.1065\n",
      "[Iter 5400 Task dept] Train Loss: 0.9225\n",
      "[Iter 5400 Total] Train Loss: 2.0290\n",
      "======================================================================\n",
      "[Iter 5400 Task segm] Val Loss: 1.6385\n",
      "{'mIoU': 0.2109, 'Pixel Acc': 0.5274}\n",
      "[Iter 5400 Task dept] Val Loss: 0.8382\n",
      "{'abs_err': 0.8341, 'rel_err': 0.3501, 'sigma_1.25': 45.4766, 'sigma_1.25^2': 74.4506, 'sigma_1.25^3': 89.5187}\n",
      "======================================================================\n",
      "[Iter 5450 Task segm] Train Loss: 1.1304\n",
      "[Iter 5450 Task dept] Train Loss: 0.9312\n",
      "[Iter 5450 Total] Train Loss: 2.0616\n",
      "======================================================================\n",
      "[Iter 5500 Task segm] Train Loss: 1.1248\n",
      "[Iter 5500 Task dept] Train Loss: 0.9121\n",
      "[Iter 5500 Total] Train Loss: 2.0369\n",
      "======================================================================\n",
      "[Iter 5550 Task segm] Train Loss: 1.1082\n",
      "[Iter 5550 Task dept] Train Loss: 0.9070\n",
      "[Iter 5550 Total] Train Loss: 2.0153\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Train Loss: 1.1278\n",
      "[Iter 5600 Task dept] Train Loss: 0.9189\n",
      "[Iter 5600 Total] Train Loss: 2.0468\n",
      "======================================================================\n",
      "[Iter 5600 Task segm] Val Loss: 1.6001\n",
      "{'mIoU': 0.2222, 'Pixel Acc': 0.5305}\n",
      "[Iter 5600 Task dept] Val Loss: 0.8186\n",
      "{'abs_err': 0.8141, 'rel_err': 0.3515, 'sigma_1.25': 46.7069, 'sigma_1.25^2': 75.2044, 'sigma_1.25^3': 89.8722}\n",
      "======================================================================\n",
      "[Iter 5650 Task segm] Train Loss: 1.1069\n",
      "[Iter 5650 Task dept] Train Loss: 0.9157\n",
      "[Iter 5650 Total] Train Loss: 2.0226\n",
      "======================================================================\n",
      "[Iter 5700 Task segm] Train Loss: 1.0897\n",
      "[Iter 5700 Task dept] Train Loss: 0.9121\n",
      "[Iter 5700 Total] Train Loss: 2.0018\n",
      "======================================================================\n",
      "[Iter 5750 Task segm] Train Loss: 1.1069\n",
      "[Iter 5750 Task dept] Train Loss: 0.9190\n",
      "[Iter 5750 Total] Train Loss: 2.0259\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Train Loss: 1.0883\n",
      "[Iter 5800 Task dept] Train Loss: 0.9077\n",
      "[Iter 5800 Total] Train Loss: 1.9961\n",
      "======================================================================\n",
      "[Iter 5800 Task segm] Val Loss: 1.5735\n",
      "{'mIoU': 0.2279, 'Pixel Acc': 0.5395}\n",
      "[Iter 5800 Task dept] Val Loss: 0.8347\n",
      "{'abs_err': 0.8286, 'rel_err': 0.3454, 'sigma_1.25': 45.7632, 'sigma_1.25^2': 74.8178, 'sigma_1.25^3': 89.8096}\n",
      "======================================================================\n",
      "[Iter 5850 Task segm] Train Loss: 1.0601\n",
      "[Iter 5850 Task dept] Train Loss: 0.9178\n",
      "[Iter 5850 Total] Train Loss: 1.9779\n",
      "======================================================================\n",
      "[Iter 5900 Task segm] Train Loss: 1.1005\n",
      "[Iter 5900 Task dept] Train Loss: 0.9032\n",
      "[Iter 5900 Total] Train Loss: 2.0037\n",
      "======================================================================\n",
      "[Iter 5950 Task segm] Train Loss: 1.1054\n",
      "[Iter 5950 Task dept] Train Loss: 0.9239\n",
      "[Iter 5950 Total] Train Loss: 2.0293\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Train Loss: 1.0933\n",
      "[Iter 6000 Task dept] Train Loss: 0.9054\n",
      "[Iter 6000 Total] Train Loss: 1.9987\n",
      "======================================================================\n",
      "[Iter 6000 Task segm] Val Loss: 1.6284\n",
      "{'mIoU': 0.2079, 'Pixel Acc': 0.5279}\n",
      "[Iter 6000 Task dept] Val Loss: 0.8188\n",
      "{'abs_err': 0.8142, 'rel_err': 0.3462, 'sigma_1.25': 46.0903, 'sigma_1.25^2': 75.2265, 'sigma_1.25^3': 89.9211}\n",
      "======================================================================\n",
      "[Iter 6050 Task segm] Train Loss: 1.0420\n",
      "[Iter 6050 Task dept] Train Loss: 0.9035\n",
      "[Iter 6050 Total] Train Loss: 1.9456\n",
      "======================================================================\n",
      "[Iter 6100 Task segm] Train Loss: 1.0577\n",
      "[Iter 6100 Task dept] Train Loss: 0.9124\n",
      "[Iter 6100 Total] Train Loss: 1.9701\n",
      "======================================================================\n",
      "[Iter 6150 Task segm] Train Loss: 1.0129\n",
      "[Iter 6150 Task dept] Train Loss: 0.8896\n",
      "[Iter 6150 Total] Train Loss: 1.9025\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Train Loss: 1.0505\n",
      "[Iter 6200 Task dept] Train Loss: 0.8916\n",
      "[Iter 6200 Total] Train Loss: 1.9421\n",
      "======================================================================\n",
      "[Iter 6200 Task segm] Val Loss: 1.6338\n",
      "{'mIoU': 0.2064, 'Pixel Acc': 0.5241}\n",
      "[Iter 6200 Task dept] Val Loss: 0.8182\n",
      "{'abs_err': 0.8137, 'rel_err': 0.3401, 'sigma_1.25': 46.3702, 'sigma_1.25^2': 75.5246, 'sigma_1.25^3': 90.1723}\n",
      "======================================================================\n",
      "[Iter 6250 Task segm] Train Loss: 1.0060\n",
      "[Iter 6250 Task dept] Train Loss: 0.8988\n",
      "[Iter 6250 Total] Train Loss: 1.9048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 6300 Task segm] Train Loss: 0.9967\n",
      "[Iter 6300 Task dept] Train Loss: 0.9136\n",
      "[Iter 6300 Total] Train Loss: 1.9103\n",
      "======================================================================\n",
      "[Iter 6350 Task segm] Train Loss: 1.0498\n",
      "[Iter 6350 Task dept] Train Loss: 0.8998\n",
      "[Iter 6350 Total] Train Loss: 1.9495\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Train Loss: 1.0077\n",
      "[Iter 6400 Task dept] Train Loss: 0.8814\n",
      "[Iter 6400 Total] Train Loss: 1.8891\n",
      "======================================================================\n",
      "[Iter 6400 Task segm] Val Loss: 1.5615\n",
      "{'mIoU': 0.2235, 'Pixel Acc': 0.5423}\n",
      "[Iter 6400 Task dept] Val Loss: 0.8046\n",
      "{'abs_err': 0.801, 'rel_err': 0.3443, 'sigma_1.25': 47.3838, 'sigma_1.25^2': 76.1108, 'sigma_1.25^3': 90.3446}\n",
      "======================================================================\n",
      "[Iter 6450 Task segm] Train Loss: 0.9913\n",
      "[Iter 6450 Task dept] Train Loss: 0.8721\n",
      "[Iter 6450 Total] Train Loss: 1.8634\n",
      "======================================================================\n",
      "[Iter 6500 Task segm] Train Loss: 0.9993\n",
      "[Iter 6500 Task dept] Train Loss: 0.8891\n",
      "[Iter 6500 Total] Train Loss: 1.8884\n",
      "======================================================================\n",
      "[Iter 6550 Task segm] Train Loss: 1.0759\n",
      "[Iter 6550 Task dept] Train Loss: 0.9081\n",
      "[Iter 6550 Total] Train Loss: 1.9840\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Train Loss: 0.9971\n",
      "[Iter 6600 Task dept] Train Loss: 0.8994\n",
      "[Iter 6600 Total] Train Loss: 1.8965\n",
      "======================================================================\n",
      "[Iter 6600 Task segm] Val Loss: 1.5149\n",
      "{'mIoU': 0.2287, 'Pixel Acc': 0.5519}\n",
      "[Iter 6600 Task dept] Val Loss: 0.8309\n",
      "{'abs_err': 0.8243, 'rel_err': 0.3277, 'sigma_1.25': 45.6627, 'sigma_1.25^2': 75.2142, 'sigma_1.25^3': 90.462}\n",
      "======================================================================\n",
      "[Iter 6650 Task segm] Train Loss: 1.0050\n",
      "[Iter 6650 Task dept] Train Loss: 0.8733\n",
      "[Iter 6650 Total] Train Loss: 1.8782\n",
      "======================================================================\n",
      "[Iter 6700 Task segm] Train Loss: 0.9938\n",
      "[Iter 6700 Task dept] Train Loss: 0.8891\n",
      "[Iter 6700 Total] Train Loss: 1.8830\n",
      "======================================================================\n",
      "[Iter 6750 Task segm] Train Loss: 0.9830\n",
      "[Iter 6750 Task dept] Train Loss: 0.8843\n",
      "[Iter 6750 Total] Train Loss: 1.8673\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Train Loss: 0.9783\n",
      "[Iter 6800 Task dept] Train Loss: 0.8715\n",
      "[Iter 6800 Total] Train Loss: 1.8498\n",
      "======================================================================\n",
      "[Iter 6800 Task segm] Val Loss: 1.5742\n",
      "{'mIoU': 0.2332, 'Pixel Acc': 0.5444}\n",
      "[Iter 6800 Task dept] Val Loss: 0.7951\n",
      "{'abs_err': 0.7909, 'rel_err': 0.3304, 'sigma_1.25': 47.8225, 'sigma_1.25^2': 76.8274, 'sigma_1.25^3': 91.0676}\n",
      "======================================================================\n",
      "[Iter 6850 Task segm] Train Loss: 1.0053\n",
      "[Iter 6850 Task dept] Train Loss: 0.8612\n",
      "[Iter 6850 Total] Train Loss: 1.8665\n",
      "======================================================================\n",
      "[Iter 6900 Task segm] Train Loss: 0.9875\n",
      "[Iter 6900 Task dept] Train Loss: 0.8877\n",
      "[Iter 6900 Total] Train Loss: 1.8751\n",
      "======================================================================\n",
      "[Iter 6950 Task segm] Train Loss: 0.9648\n",
      "[Iter 6950 Task dept] Train Loss: 0.8825\n",
      "[Iter 6950 Total] Train Loss: 1.8473\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Train Loss: 0.9884\n",
      "[Iter 7000 Task dept] Train Loss: 0.8830\n",
      "[Iter 7000 Total] Train Loss: 1.8713\n",
      "======================================================================\n",
      "[Iter 7000 Task segm] Val Loss: 1.5657\n",
      "{'mIoU': 0.2327, 'Pixel Acc': 0.5411}\n",
      "[Iter 7000 Task dept] Val Loss: 0.8137\n",
      "{'abs_err': 0.8067, 'rel_err': 0.3161, 'sigma_1.25': 46.6546, 'sigma_1.25^2': 76.2225, 'sigma_1.25^3': 90.8935}\n",
      "======================================================================\n",
      "[Iter 7050 Task segm] Train Loss: 0.9512\n",
      "[Iter 7050 Task dept] Train Loss: 0.8812\n",
      "[Iter 7050 Total] Train Loss: 1.8324\n",
      "======================================================================\n",
      "[Iter 7100 Task segm] Train Loss: 0.9524\n",
      "[Iter 7100 Task dept] Train Loss: 0.8587\n",
      "[Iter 7100 Total] Train Loss: 1.8112\n",
      "======================================================================\n",
      "[Iter 7150 Task segm] Train Loss: 0.9359\n",
      "[Iter 7150 Task dept] Train Loss: 0.8720\n",
      "[Iter 7150 Total] Train Loss: 1.8079\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Train Loss: 0.9250\n",
      "[Iter 7200 Task dept] Train Loss: 0.8712\n",
      "[Iter 7200 Total] Train Loss: 1.7962\n",
      "======================================================================\n",
      "[Iter 7200 Task segm] Val Loss: 1.6016\n",
      "{'mIoU': 0.2219, 'Pixel Acc': 0.5362}\n",
      "[Iter 7200 Task dept] Val Loss: 0.7680\n",
      "{'abs_err': 0.7639, 'rel_err': 0.3248, 'sigma_1.25': 49.1747, 'sigma_1.25^2': 77.9673, 'sigma_1.25^3': 91.6532}\n",
      "======================================================================\n",
      "[Iter 7250 Task segm] Train Loss: 0.9614\n",
      "[Iter 7250 Task dept] Train Loss: 0.8658\n",
      "[Iter 7250 Total] Train Loss: 1.8272\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# bs = 16, Adam\n",
    "loss_lambda = {'segment_semantic': 1, 'normal':1, 'depth_zbuffer': 1}\n",
    "checkpoint = '/mnt/nfs/work1/huiguan/lijunzhang/multibranch/checkpoint/NYUv2/exp/'\n",
    "\n",
    "trainer = Trainer(model, two_task, trainDataloader, valDataloader, criterionDict, metricDict)\n",
    "trainer.train(20000, loss_lambda, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 7250 Task segm] Train Loss: 0.9060\n",
      "[Iter 7250 Task dept] Train Loss: 0.8417\n",
      "[Iter 7250 Total] Train Loss: 1.7477\n",
      "======================================================================\n",
      "[Iter 7300 Task segm] Train Loss: 0.9274\n",
      "[Iter 7300 Task dept] Train Loss: 0.8713\n",
      "[Iter 7300 Total] Train Loss: 1.7987\n",
      "======================================================================\n",
      "[Iter 7350 Task segm] Train Loss: 0.9272\n",
      "[Iter 7350 Task dept] Train Loss: 0.8598\n",
      "[Iter 7350 Total] Train Loss: 1.7870\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Train Loss: 0.8955\n",
      "[Iter 7400 Task dept] Train Loss: 0.8578\n",
      "[Iter 7400 Total] Train Loss: 1.7533\n",
      "======================================================================\n",
      "[Iter 7400 Task segm] Val Loss: 1.5620\n",
      "{'mIoU': 0.232, 'Pixel Acc': 0.5459}\n",
      "[Iter 7400 Task dept] Val Loss: 0.7815\n",
      "{'abs_err': 0.7787, 'rel_err': 0.3372, 'sigma_1.25': 48.2351, 'sigma_1.25^2': 77.511, 'sigma_1.25^3': 90.9162}\n",
      "======================================================================\n",
      "[Iter 7450 Task segm] Train Loss: 0.9142\n",
      "[Iter 7450 Task dept] Train Loss: 0.8479\n",
      "[Iter 7450 Total] Train Loss: 1.7621\n",
      "======================================================================\n",
      "[Iter 7500 Task segm] Train Loss: 0.9131\n",
      "[Iter 7500 Task dept] Train Loss: 0.8602\n",
      "[Iter 7500 Total] Train Loss: 1.7733\n",
      "======================================================================\n",
      "[Iter 7550 Task segm] Train Loss: 0.9008\n",
      "[Iter 7550 Task dept] Train Loss: 0.8451\n",
      "[Iter 7550 Total] Train Loss: 1.7459\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Train Loss: 0.9108\n",
      "[Iter 7600 Task dept] Train Loss: 0.8335\n",
      "[Iter 7600 Total] Train Loss: 1.7443\n",
      "======================================================================\n",
      "[Iter 7600 Task segm] Val Loss: 1.5865\n",
      "{'mIoU': 0.2252, 'Pixel Acc': 0.5412}\n",
      "[Iter 7600 Task dept] Val Loss: 0.7848\n",
      "{'abs_err': 0.781, 'rel_err': 0.3233, 'sigma_1.25': 48.653, 'sigma_1.25^2': 77.3714, 'sigma_1.25^3': 90.9913}\n",
      "======================================================================\n",
      "[Iter 7650 Task segm] Train Loss: 0.9084\n",
      "[Iter 7650 Task dept] Train Loss: 0.8581\n",
      "[Iter 7650 Total] Train Loss: 1.7665\n",
      "======================================================================\n",
      "[Iter 7700 Task segm] Train Loss: 0.9131\n",
      "[Iter 7700 Task dept] Train Loss: 0.8423\n",
      "[Iter 7700 Total] Train Loss: 1.7555\n",
      "======================================================================\n",
      "[Iter 7750 Task segm] Train Loss: 0.9248\n",
      "[Iter 7750 Task dept] Train Loss: 0.8468\n",
      "[Iter 7750 Total] Train Loss: 1.7716\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Train Loss: 0.8901\n",
      "[Iter 7800 Task dept] Train Loss: 0.8183\n",
      "[Iter 7800 Total] Train Loss: 1.7085\n",
      "======================================================================\n",
      "[Iter 7800 Task segm] Val Loss: 1.6205\n",
      "{'mIoU': 0.2201, 'Pixel Acc': 0.5449}\n",
      "[Iter 7800 Task dept] Val Loss: 0.8006\n",
      "{'abs_err': 0.7951, 'rel_err': 0.321, 'sigma_1.25': 47.3896, 'sigma_1.25^2': 76.8992, 'sigma_1.25^3': 90.9264}\n",
      "======================================================================\n",
      "[Iter 7850 Task segm] Train Loss: 0.8993\n",
      "[Iter 7850 Task dept] Train Loss: 0.8561\n",
      "[Iter 7850 Total] Train Loss: 1.7554\n",
      "======================================================================\n",
      "[Iter 7900 Task segm] Train Loss: 0.8621\n",
      "[Iter 7900 Task dept] Train Loss: 0.8540\n",
      "[Iter 7900 Total] Train Loss: 1.7161\n",
      "======================================================================\n",
      "[Iter 7950 Task segm] Train Loss: 0.8435\n",
      "[Iter 7950 Task dept] Train Loss: 0.8544\n",
      "[Iter 7950 Total] Train Loss: 1.6979\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Train Loss: 0.8459\n",
      "[Iter 8000 Task dept] Train Loss: 0.8374\n",
      "[Iter 8000 Total] Train Loss: 1.6834\n",
      "======================================================================\n",
      "[Iter 8000 Task segm] Val Loss: 1.5748\n",
      "{'mIoU': 0.2241, 'Pixel Acc': 0.5473}\n",
      "[Iter 8000 Task dept] Val Loss: 0.7921\n",
      "{'abs_err': 0.7869, 'rel_err': 0.3193, 'sigma_1.25': 47.8217, 'sigma_1.25^2': 76.6656, 'sigma_1.25^3': 91.1682}\n",
      "======================================================================\n",
      "[Iter 8050 Task segm] Train Loss: 0.8177\n",
      "[Iter 8050 Task dept] Train Loss: 0.8152\n",
      "[Iter 8050 Total] Train Loss: 1.6329\n",
      "======================================================================\n",
      "[Iter 8100 Task segm] Train Loss: 0.7781\n",
      "[Iter 8100 Task dept] Train Loss: 0.8197\n",
      "[Iter 8100 Total] Train Loss: 1.5978\n",
      "======================================================================\n",
      "[Iter 8150 Task segm] Train Loss: 0.7599\n",
      "[Iter 8150 Task dept] Train Loss: 0.8139\n",
      "[Iter 8150 Total] Train Loss: 1.5737\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Train Loss: 0.7552\n",
      "[Iter 8200 Task dept] Train Loss: 0.8169\n",
      "[Iter 8200 Total] Train Loss: 1.5721\n",
      "======================================================================\n",
      "[Iter 8200 Task segm] Val Loss: 1.5157\n",
      "{'mIoU': 0.2356, 'Pixel Acc': 0.5589}\n",
      "[Iter 8200 Task dept] Val Loss: 0.7634\n",
      "{'abs_err': 0.7604, 'rel_err': 0.3118, 'sigma_1.25': 50.0323, 'sigma_1.25^2': 78.7204, 'sigma_1.25^3': 91.67}\n",
      "======================================================================\n",
      "[Iter 8250 Task segm] Train Loss: 0.7461\n",
      "[Iter 8250 Task dept] Train Loss: 0.7938\n",
      "[Iter 8250 Total] Train Loss: 1.5400\n",
      "======================================================================\n",
      "[Iter 8300 Task segm] Train Loss: 0.7375\n",
      "[Iter 8300 Task dept] Train Loss: 0.7998\n",
      "[Iter 8300 Total] Train Loss: 1.5373\n",
      "======================================================================\n",
      "[Iter 8350 Task segm] Train Loss: 0.7200\n",
      "[Iter 8350 Task dept] Train Loss: 0.8000\n",
      "[Iter 8350 Total] Train Loss: 1.5200\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Train Loss: 0.7291\n",
      "[Iter 8400 Task dept] Train Loss: 0.8126\n",
      "[Iter 8400 Total] Train Loss: 1.5417\n",
      "======================================================================\n",
      "[Iter 8400 Task segm] Val Loss: 1.5225\n",
      "{'mIoU': 0.2511, 'Pixel Acc': 0.559}\n",
      "[Iter 8400 Task dept] Val Loss: 0.7638\n",
      "{'abs_err': 0.7618, 'rel_err': 0.328, 'sigma_1.25': 49.5364, 'sigma_1.25^2': 78.4576, 'sigma_1.25^3': 91.3287}\n",
      "======================================================================\n",
      "[Iter 8450 Task segm] Train Loss: 0.7249\n",
      "[Iter 8450 Task dept] Train Loss: 0.7858\n",
      "[Iter 8450 Total] Train Loss: 1.5107\n",
      "======================================================================\n",
      "[Iter 8500 Task segm] Train Loss: 0.7183\n",
      "[Iter 8500 Task dept] Train Loss: 0.7810\n",
      "[Iter 8500 Total] Train Loss: 1.4994\n",
      "======================================================================\n",
      "[Iter 8550 Task segm] Train Loss: 0.7113\n",
      "[Iter 8550 Task dept] Train Loss: 0.8034\n",
      "[Iter 8550 Total] Train Loss: 1.5147\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Train Loss: 0.6910\n",
      "[Iter 8600 Task dept] Train Loss: 0.7852\n",
      "[Iter 8600 Total] Train Loss: 1.4762\n",
      "======================================================================\n",
      "[Iter 8600 Task segm] Val Loss: 1.5150\n",
      "{'mIoU': 0.2532, 'Pixel Acc': 0.5636}\n",
      "[Iter 8600 Task dept] Val Loss: 0.7568\n",
      "{'abs_err': 0.7503, 'rel_err': 0.298, 'sigma_1.25': 49.7853, 'sigma_1.25^2': 79.207, 'sigma_1.25^3': 92.3515}\n",
      "======================================================================\n",
      "[Iter 8650 Task segm] Train Loss: 0.6707\n",
      "[Iter 8650 Task dept] Train Loss: 0.8075\n",
      "[Iter 8650 Total] Train Loss: 1.4782\n",
      "======================================================================\n",
      "[Iter 8700 Task segm] Train Loss: 0.7063\n",
      "[Iter 8700 Task dept] Train Loss: 0.7852\n",
      "[Iter 8700 Total] Train Loss: 1.4915\n",
      "======================================================================\n",
      "[Iter 8750 Task segm] Train Loss: 0.7012\n",
      "[Iter 8750 Task dept] Train Loss: 0.7932\n",
      "[Iter 8750 Total] Train Loss: 1.4944\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Train Loss: 0.7021\n",
      "[Iter 8800 Task dept] Train Loss: 0.7795\n",
      "[Iter 8800 Total] Train Loss: 1.4816\n",
      "======================================================================\n",
      "[Iter 8800 Task segm] Val Loss: 1.5545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mIoU': 0.2426, 'Pixel Acc': 0.5557}\n",
      "[Iter 8800 Task dept] Val Loss: 0.7611\n",
      "{'abs_err': 0.7553, 'rel_err': 0.297, 'sigma_1.25': 49.1501, 'sigma_1.25^2': 78.7395, 'sigma_1.25^3': 92.0939}\n",
      "======================================================================\n",
      "[Iter 8850 Task segm] Train Loss: 0.6792\n",
      "[Iter 8850 Task dept] Train Loss: 0.7771\n",
      "[Iter 8850 Total] Train Loss: 1.4562\n",
      "======================================================================\n",
      "[Iter 8900 Task segm] Train Loss: 0.7038\n",
      "[Iter 8900 Task dept] Train Loss: 0.8042\n",
      "[Iter 8900 Total] Train Loss: 1.5080\n",
      "======================================================================\n",
      "[Iter 8950 Task segm] Train Loss: 0.7104\n",
      "[Iter 8950 Task dept] Train Loss: 0.7848\n",
      "[Iter 8950 Total] Train Loss: 1.4952\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Train Loss: 0.6969\n",
      "[Iter 9000 Task dept] Train Loss: 0.7623\n",
      "[Iter 9000 Total] Train Loss: 1.4592\n",
      "======================================================================\n",
      "[Iter 9000 Task segm] Val Loss: 1.5217\n",
      "{'mIoU': 0.2502, 'Pixel Acc': 0.5659}\n",
      "[Iter 9000 Task dept] Val Loss: 0.7743\n",
      "{'abs_err': 0.7669, 'rel_err': 0.2859, 'sigma_1.25': 47.6748, 'sigma_1.25^2': 78.3512, 'sigma_1.25^3': 92.4897}\n",
      "======================================================================\n",
      "[Iter 9050 Task segm] Train Loss: 0.6665\n",
      "[Iter 9050 Task dept] Train Loss: 0.7893\n",
      "[Iter 9050 Total] Train Loss: 1.4558\n",
      "======================================================================\n",
      "[Iter 9100 Task segm] Train Loss: 0.6807\n",
      "[Iter 9100 Task dept] Train Loss: 0.7701\n",
      "[Iter 9100 Total] Train Loss: 1.4508\n",
      "======================================================================\n",
      "[Iter 9150 Task segm] Train Loss: 0.6763\n",
      "[Iter 9150 Task dept] Train Loss: 0.7634\n",
      "[Iter 9150 Total] Train Loss: 1.4397\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Train Loss: 0.6818\n",
      "[Iter 9200 Task dept] Train Loss: 0.7868\n",
      "[Iter 9200 Total] Train Loss: 1.4686\n",
      "======================================================================\n",
      "[Iter 9200 Task segm] Val Loss: 1.5688\n",
      "{'mIoU': 0.2351, 'Pixel Acc': 0.5643}\n",
      "[Iter 9200 Task dept] Val Loss: 0.7468\n",
      "{'abs_err': 0.7418, 'rel_err': 0.2897, 'sigma_1.25': 50.1731, 'sigma_1.25^2': 79.5994, 'sigma_1.25^3': 92.7412}\n",
      "======================================================================\n",
      "[Iter 9250 Task segm] Train Loss: 0.6722\n",
      "[Iter 9250 Task dept] Train Loss: 0.7751\n",
      "[Iter 9250 Total] Train Loss: 1.4473\n",
      "======================================================================\n",
      "[Iter 9300 Task segm] Train Loss: 0.6673\n",
      "[Iter 9300 Task dept] Train Loss: 0.7755\n",
      "[Iter 9300 Total] Train Loss: 1.4428\n",
      "======================================================================\n",
      "[Iter 9350 Task segm] Train Loss: 0.6476\n",
      "[Iter 9350 Task dept] Train Loss: 0.7613\n",
      "[Iter 9350 Total] Train Loss: 1.4089\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Train Loss: 0.6524\n",
      "[Iter 9400 Task dept] Train Loss: 0.7847\n",
      "[Iter 9400 Total] Train Loss: 1.4371\n",
      "======================================================================\n",
      "[Iter 9400 Task segm] Val Loss: 1.5447\n",
      "{'mIoU': 0.2517, 'Pixel Acc': 0.5709}\n",
      "[Iter 9400 Task dept] Val Loss: 0.7320\n",
      "{'abs_err': 0.7288, 'rel_err': 0.3057, 'sigma_1.25': 51.2908, 'sigma_1.25^2': 80.0388, 'sigma_1.25^3': 92.3057}\n",
      "======================================================================\n",
      "[Iter 9450 Task segm] Train Loss: 0.6434\n",
      "[Iter 9450 Task dept] Train Loss: 0.7744\n",
      "[Iter 9450 Total] Train Loss: 1.4178\n",
      "======================================================================\n",
      "[Iter 9500 Task segm] Train Loss: 0.6750\n",
      "[Iter 9500 Task dept] Train Loss: 0.7586\n",
      "[Iter 9500 Total] Train Loss: 1.4336\n",
      "======================================================================\n",
      "[Iter 9550 Task segm] Train Loss: 0.6692\n",
      "[Iter 9550 Task dept] Train Loss: 0.7559\n",
      "[Iter 9550 Total] Train Loss: 1.4251\n",
      "======================================================================\n",
      "[Iter 9600 Task segm] Train Loss: 0.6658\n",
      "[Iter 9600 Task dept] Train Loss: 0.7777\n",
      "[Iter 9600 Total] Train Loss: 1.4434\n",
      "======================================================================\n",
      "[Iter 9600 Task segm] Val Loss: 1.5309\n",
      "{'mIoU': 0.2545, 'Pixel Acc': 0.5675}\n",
      "[Iter 9600 Task dept] Val Loss: 0.7096\n",
      "{'abs_err': 0.7071, 'rel_err': 0.2983, 'sigma_1.25': 52.6747, 'sigma_1.25^2': 81.1005, 'sigma_1.25^3': 93.0268}\n",
      "======================================================================\n",
      "[Iter 9650 Task segm] Train Loss: 0.6394\n",
      "[Iter 9650 Task dept] Train Loss: 0.7595\n",
      "[Iter 9650 Total] Train Loss: 1.3988\n",
      "======================================================================\n",
      "[Iter 9700 Task segm] Train Loss: 0.6677\n",
      "[Iter 9700 Task dept] Train Loss: 0.7542\n",
      "[Iter 9700 Total] Train Loss: 1.4219\n",
      "======================================================================\n",
      "[Iter 9750 Task segm] Train Loss: 0.6662\n",
      "[Iter 9750 Task dept] Train Loss: 0.7632\n",
      "[Iter 9750 Total] Train Loss: 1.4294\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Train Loss: 0.6504\n",
      "[Iter 9800 Task dept] Train Loss: 0.7613\n",
      "[Iter 9800 Total] Train Loss: 1.4116\n",
      "======================================================================\n",
      "[Iter 9800 Task segm] Val Loss: 1.5463\n",
      "{'mIoU': 0.2417, 'Pixel Acc': 0.5652}\n",
      "[Iter 9800 Task dept] Val Loss: 0.7232\n",
      "{'abs_err': 0.7189, 'rel_err': 0.2898, 'sigma_1.25': 51.6511, 'sigma_1.25^2': 80.8744, 'sigma_1.25^3': 93.1131}\n",
      "======================================================================\n",
      "[Iter 9850 Task segm] Train Loss: 0.6238\n",
      "[Iter 9850 Task dept] Train Loss: 0.7523\n",
      "[Iter 9850 Total] Train Loss: 1.3760\n",
      "======================================================================\n",
      "[Iter 9900 Task segm] Train Loss: 0.6353\n",
      "[Iter 9900 Task dept] Train Loss: 0.7550\n",
      "[Iter 9900 Total] Train Loss: 1.3903\n",
      "======================================================================\n",
      "[Iter 9950 Task segm] Train Loss: 0.6204\n",
      "[Iter 9950 Task dept] Train Loss: 0.7514\n",
      "[Iter 9950 Total] Train Loss: 1.3718\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Train Loss: 0.6297\n",
      "[Iter 10000 Task dept] Train Loss: 0.7340\n",
      "[Iter 10000 Total] Train Loss: 1.3637\n",
      "======================================================================\n",
      "[Iter 10000 Task segm] Val Loss: 1.5586\n",
      "{'mIoU': 0.2509, 'Pixel Acc': 0.568}\n",
      "[Iter 10000 Task dept] Val Loss: 0.7629\n",
      "{'abs_err': 0.7574, 'rel_err': 0.2984, 'sigma_1.25': 49.3767, 'sigma_1.25^2': 78.6384, 'sigma_1.25^3': 92.1541}\n",
      "======================================================================\n",
      "[Iter 10050 Task segm] Train Loss: 0.6281\n",
      "[Iter 10050 Task dept] Train Loss: 0.7312\n",
      "[Iter 10050 Total] Train Loss: 1.3593\n",
      "======================================================================\n",
      "[Iter 10100 Task segm] Train Loss: 0.6142\n",
      "[Iter 10100 Task dept] Train Loss: 0.7487\n",
      "[Iter 10100 Total] Train Loss: 1.3629\n",
      "======================================================================\n",
      "[Iter 10150 Task segm] Train Loss: 0.6017\n",
      "[Iter 10150 Task dept] Train Loss: 0.7515\n",
      "[Iter 10150 Total] Train Loss: 1.3532\n",
      "======================================================================\n",
      "[Iter 10200 Task segm] Train Loss: 0.6130\n",
      "[Iter 10200 Task dept] Train Loss: 0.7396\n",
      "[Iter 10200 Total] Train Loss: 1.3526\n",
      "======================================================================\n",
      "[Iter 10200 Task segm] Val Loss: 1.5466\n",
      "{'mIoU': 0.2559, 'Pixel Acc': 0.5695}\n",
      "[Iter 10200 Task dept] Val Loss: 0.7666\n",
      "{'abs_err': 0.759, 'rel_err': 0.2808, 'sigma_1.25': 48.7517, 'sigma_1.25^2': 79.0541, 'sigma_1.25^3': 92.6957}\n",
      "======================================================================\n",
      "[Iter 10250 Task segm] Train Loss: 0.6083\n",
      "[Iter 10250 Task dept] Train Loss: 0.7715\n",
      "[Iter 10250 Total] Train Loss: 1.3798\n",
      "======================================================================\n",
      "[Iter 10300 Task segm] Train Loss: 0.6136\n",
      "[Iter 10300 Task dept] Train Loss: 0.7344\n",
      "[Iter 10300 Total] Train Loss: 1.3480\n",
      "======================================================================\n",
      "[Iter 10350 Task segm] Train Loss: 0.6434\n",
      "[Iter 10350 Task dept] Train Loss: 0.7416\n",
      "[Iter 10350 Total] Train Loss: 1.3850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 10400 Task segm] Train Loss: 0.6328\n",
      "[Iter 10400 Task dept] Train Loss: 0.7328\n",
      "[Iter 10400 Total] Train Loss: 1.3657\n",
      "======================================================================\n",
      "[Iter 10400 Task segm] Val Loss: 1.6136\n",
      "{'mIoU': 0.2353, 'Pixel Acc': 0.5546}\n",
      "[Iter 10400 Task dept] Val Loss: 0.7830\n",
      "{'abs_err': 0.7739, 'rel_err': 0.2837, 'sigma_1.25': 46.9386, 'sigma_1.25^2': 77.5763, 'sigma_1.25^3': 92.4057}\n",
      "======================================================================\n",
      "[Iter 10450 Task segm] Train Loss: 0.5810\n",
      "[Iter 10450 Task dept] Train Loss: 0.7317\n",
      "[Iter 10450 Total] Train Loss: 1.3126\n",
      "======================================================================\n",
      "[Iter 10500 Task segm] Train Loss: 0.5918\n",
      "[Iter 10500 Task dept] Train Loss: 0.7347\n",
      "[Iter 10500 Total] Train Loss: 1.3266\n",
      "======================================================================\n",
      "[Iter 10550 Task segm] Train Loss: 0.6087\n",
      "[Iter 10550 Task dept] Train Loss: 0.7366\n",
      "[Iter 10550 Total] Train Loss: 1.3453\n",
      "======================================================================\n",
      "[Iter 10600 Task segm] Train Loss: 0.6220\n",
      "[Iter 10600 Task dept] Train Loss: 0.7491\n",
      "[Iter 10600 Total] Train Loss: 1.3711\n",
      "======================================================================\n",
      "[Iter 10600 Task segm] Val Loss: 1.5942\n",
      "{'mIoU': 0.2454, 'Pixel Acc': 0.567}\n",
      "[Iter 10600 Task dept] Val Loss: 0.7851\n",
      "{'abs_err': 0.7794, 'rel_err': 0.3003, 'sigma_1.25': 47.4572, 'sigma_1.25^2': 77.7881, 'sigma_1.25^3': 91.8473}\n",
      "======================================================================\n",
      "[Iter 10650 Task segm] Train Loss: 0.6055\n",
      "[Iter 10650 Task dept] Train Loss: 0.7278\n",
      "[Iter 10650 Total] Train Loss: 1.3333\n",
      "======================================================================\n",
      "[Iter 10700 Task segm] Train Loss: 0.6029\n",
      "[Iter 10700 Task dept] Train Loss: 0.7269\n",
      "[Iter 10700 Total] Train Loss: 1.3298\n",
      "======================================================================\n",
      "[Iter 10750 Task segm] Train Loss: 0.6067\n",
      "[Iter 10750 Task dept] Train Loss: 0.7276\n",
      "[Iter 10750 Total] Train Loss: 1.3344\n",
      "======================================================================\n",
      "[Iter 10800 Task segm] Train Loss: 0.6104\n",
      "[Iter 10800 Task dept] Train Loss: 0.7166\n",
      "[Iter 10800 Total] Train Loss: 1.3270\n",
      "======================================================================\n",
      "[Iter 10800 Task segm] Val Loss: 1.5924\n",
      "{'mIoU': 0.2472, 'Pixel Acc': 0.5668}\n",
      "[Iter 10800 Task dept] Val Loss: 0.7526\n",
      "{'abs_err': 0.746, 'rel_err': 0.2899, 'sigma_1.25': 50.1168, 'sigma_1.25^2': 79.3683, 'sigma_1.25^3': 92.5667}\n",
      "======================================================================\n",
      "[Iter 10850 Task segm] Train Loss: 0.6083\n",
      "[Iter 10850 Task dept] Train Loss: 0.7126\n",
      "[Iter 10850 Total] Train Loss: 1.3209\n",
      "======================================================================\n",
      "[Iter 10900 Task segm] Train Loss: 0.5964\n",
      "[Iter 10900 Task dept] Train Loss: 0.7369\n",
      "[Iter 10900 Total] Train Loss: 1.3333\n",
      "======================================================================\n",
      "[Iter 10950 Task segm] Train Loss: 0.5696\n",
      "[Iter 10950 Task dept] Train Loss: 0.7156\n",
      "[Iter 10950 Total] Train Loss: 1.2852\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-25ad36a14b60>\", line 6, in <module>\n",
      "    trainer.train(20000, loss_lambda, checkpoint, reload='segment_semantic_depth_zbuffer_b0.model')\n",
      "  File \"<ipython-input-5-3958f6b9c3a9>\", line 32, in train\n",
      "    self.train_step(loss_lambda)\n",
      "  File \"<ipython-input-5-3958f6b9c3a9>\", line 72, in train_step\n",
      "    self.optimizer.step()\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/torch/optim/lr_scheduler.py\", line 67, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 15, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/torch/optim/adam.py\", line 111, in step\n",
      "    p.addcdiv_(exp_avg, denom, value=-step_size)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# bs = 16, Adam, reload\n",
    "loss_lambda = {'segment_semantic': 1, 'normal':1, 'depth_zbuffer': 1}\n",
    "checkpoint = '/mnt/nfs/work1/huiguan/lijunzhang/multibranch/checkpoint/NYUv2/exp/'\n",
    "\n",
    "trainer = Trainer(model, two_task, trainDataloader, valDataloader, criterionDict, metricDict)\n",
    "trainer.train(20000, loss_lambda, checkpoint, reload='segment_semantic_depth_zbuffer_b0.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 10850 Task segm] Train Loss: 0.6160\n",
      "[Iter 10850 Task dept] Train Loss: 0.7187\n",
      "[Iter 10850 Total] Train Loss: 1.3347\n",
      "======================================================================\n",
      "[Iter 10900 Task segm] Train Loss: 0.6028\n",
      "[Iter 10900 Task dept] Train Loss: 0.7065\n",
      "[Iter 10900 Total] Train Loss: 1.3092\n",
      "======================================================================\n",
      "[Iter 10950 Task segm] Train Loss: 0.6142\n",
      "[Iter 10950 Task dept] Train Loss: 0.7414\n",
      "[Iter 10950 Total] Train Loss: 1.3557\n",
      "======================================================================\n",
      "[Iter 11000 Task segm] Train Loss: 0.5974\n",
      "[Iter 11000 Task dept] Train Loss: 0.7149\n",
      "[Iter 11000 Total] Train Loss: 1.3123\n",
      "======================================================================\n",
      "[Iter 11000 Task segm] Val Loss: 1.5378\n",
      "{'mIoU': 0.2508, 'Pixel Acc': 0.5752}\n",
      "[Iter 11000 Task dept] Val Loss: 0.7344\n",
      "{'abs_err': 0.7276, 'rel_err': 0.2768, 'sigma_1.25': 51.0981, 'sigma_1.25^2': 80.4403, 'sigma_1.25^3': 93.4942}\n",
      "======================================================================\n",
      "[Iter 11050 Task segm] Train Loss: 0.5802\n",
      "[Iter 11050 Task dept] Train Loss: 0.7121\n",
      "[Iter 11050 Total] Train Loss: 1.2923\n",
      "======================================================================\n",
      "[Iter 11100 Task segm] Train Loss: 0.6012\n",
      "[Iter 11100 Task dept] Train Loss: 0.7325\n",
      "[Iter 11100 Total] Train Loss: 1.3337\n",
      "======================================================================\n",
      "[Iter 11150 Task segm] Train Loss: 0.5981\n",
      "[Iter 11150 Task dept] Train Loss: 0.7171\n",
      "[Iter 11150 Total] Train Loss: 1.3151\n",
      "======================================================================\n",
      "[Iter 11200 Task segm] Train Loss: 0.5923\n",
      "[Iter 11200 Task dept] Train Loss: 0.7083\n",
      "[Iter 11200 Total] Train Loss: 1.3006\n",
      "======================================================================\n",
      "[Iter 11200 Task segm] Val Loss: 1.6453\n",
      "{'mIoU': 0.2482, 'Pixel Acc': 0.5584}\n",
      "[Iter 11200 Task dept] Val Loss: 0.7161\n",
      "{'abs_err': 0.7118, 'rel_err': 0.2769, 'sigma_1.25': 52.675, 'sigma_1.25^2': 81.1578, 'sigma_1.25^3': 93.3895}\n",
      "======================================================================\n",
      "[Iter 11250 Task segm] Train Loss: 0.5932\n",
      "[Iter 11250 Task dept] Train Loss: 0.7383\n",
      "[Iter 11250 Total] Train Loss: 1.3316\n",
      "======================================================================\n",
      "[Iter 11300 Task segm] Train Loss: 0.5540\n",
      "[Iter 11300 Task dept] Train Loss: 0.7167\n",
      "[Iter 11300 Total] Train Loss: 1.2707\n",
      "======================================================================\n",
      "[Iter 11350 Task segm] Train Loss: 0.5597\n",
      "[Iter 11350 Task dept] Train Loss: 0.7021\n",
      "[Iter 11350 Total] Train Loss: 1.2618\n",
      "======================================================================\n",
      "[Iter 11400 Task segm] Train Loss: 0.5749\n",
      "[Iter 11400 Task dept] Train Loss: 0.7110\n",
      "[Iter 11400 Total] Train Loss: 1.2859\n",
      "======================================================================\n",
      "[Iter 11400 Task segm] Val Loss: 1.5974\n",
      "{'mIoU': 0.2578, 'Pixel Acc': 0.5715}\n",
      "[Iter 11400 Task dept] Val Loss: 0.7146\n",
      "{'abs_err': 0.7128, 'rel_err': 0.3031, 'sigma_1.25': 52.2562, 'sigma_1.25^2': 80.6974, 'sigma_1.25^3': 93.0169}\n",
      "======================================================================\n",
      "[Iter 11450 Task segm] Train Loss: 0.6109\n",
      "[Iter 11450 Task dept] Train Loss: 0.7128\n",
      "[Iter 11450 Total] Train Loss: 1.3236\n",
      "======================================================================\n",
      "[Iter 11500 Task segm] Train Loss: 0.5601\n",
      "[Iter 11500 Task dept] Train Loss: 0.6878\n",
      "[Iter 11500 Total] Train Loss: 1.2479\n",
      "======================================================================\n",
      "[Iter 11550 Task segm] Train Loss: 0.5652\n",
      "[Iter 11550 Task dept] Train Loss: 0.7247\n",
      "[Iter 11550 Total] Train Loss: 1.2899\n",
      "======================================================================\n",
      "[Iter 11600 Task segm] Train Loss: 0.5897\n",
      "[Iter 11600 Task dept] Train Loss: 0.7263\n",
      "[Iter 11600 Total] Train Loss: 1.3160\n",
      "======================================================================\n",
      "[Iter 11600 Task segm] Val Loss: 1.6090\n",
      "{'mIoU': 0.2457, 'Pixel Acc': 0.5648}\n",
      "[Iter 11600 Task dept] Val Loss: 0.7204\n",
      "{'abs_err': 0.7202, 'rel_err': 0.2951, 'sigma_1.25': 51.7134, 'sigma_1.25^2': 80.8592, 'sigma_1.25^3': 92.9052}\n",
      "======================================================================\n",
      "[Iter 11650 Task segm] Train Loss: 0.5536\n",
      "[Iter 11650 Task dept] Train Loss: 0.7050\n",
      "[Iter 11650 Total] Train Loss: 1.2586\n",
      "======================================================================\n",
      "[Iter 11700 Task segm] Train Loss: 0.5482\n",
      "[Iter 11700 Task dept] Train Loss: 0.6936\n",
      "[Iter 11700 Total] Train Loss: 1.2419\n",
      "======================================================================\n",
      "[Iter 11750 Task segm] Train Loss: 0.5529\n",
      "[Iter 11750 Task dept] Train Loss: 0.7040\n",
      "[Iter 11750 Total] Train Loss: 1.2569\n",
      "======================================================================\n",
      "[Iter 11800 Task segm] Train Loss: 0.5665\n",
      "[Iter 11800 Task dept] Train Loss: 0.6979\n",
      "[Iter 11800 Total] Train Loss: 1.2644\n",
      "======================================================================\n",
      "[Iter 11800 Task segm] Val Loss: 1.6787\n",
      "{'mIoU': 0.2338, 'Pixel Acc': 0.5506}\n",
      "[Iter 11800 Task dept] Val Loss: 0.6969\n",
      "{'abs_err': 0.6933, 'rel_err': 0.2762, 'sigma_1.25': 53.529, 'sigma_1.25^2': 82.0308, 'sigma_1.25^3': 93.7941}\n",
      "======================================================================\n",
      "[Iter 11850 Task segm] Train Loss: 0.5463\n",
      "[Iter 11850 Task dept] Train Loss: 0.7164\n",
      "[Iter 11850 Total] Train Loss: 1.2627\n",
      "======================================================================\n",
      "[Iter 11900 Task segm] Train Loss: 0.5533\n",
      "[Iter 11900 Task dept] Train Loss: 0.7010\n",
      "[Iter 11900 Total] Train Loss: 1.2543\n",
      "======================================================================\n",
      "[Iter 11950 Task segm] Train Loss: 0.5413\n",
      "[Iter 11950 Task dept] Train Loss: 0.7053\n",
      "[Iter 11950 Total] Train Loss: 1.2466\n",
      "======================================================================\n",
      "[Iter 12000 Task segm] Train Loss: 0.5315\n",
      "[Iter 12000 Task dept] Train Loss: 0.6932\n",
      "[Iter 12000 Total] Train Loss: 1.2247\n",
      "======================================================================\n",
      "[Iter 12000 Task segm] Val Loss: 1.5790\n",
      "{'mIoU': 0.251, 'Pixel Acc': 0.5697}\n",
      "[Iter 12000 Task dept] Val Loss: 0.7663\n",
      "{'abs_err': 0.7605, 'rel_err': 0.286, 'sigma_1.25': 49.0176, 'sigma_1.25^2': 78.5693, 'sigma_1.25^3': 92.3112}\n",
      "======================================================================\n",
      "[Iter 12050 Task segm] Train Loss: 0.5450\n",
      "[Iter 12050 Task dept] Train Loss: 0.6777\n",
      "[Iter 12050 Total] Train Loss: 1.2226\n",
      "======================================================================\n",
      "[Iter 12100 Task segm] Train Loss: 0.5138\n",
      "[Iter 12100 Task dept] Train Loss: 0.6571\n",
      "[Iter 12100 Total] Train Loss: 1.1709\n",
      "======================================================================\n",
      "[Iter 12150 Task segm] Train Loss: 0.4763\n",
      "[Iter 12150 Task dept] Train Loss: 0.6464\n",
      "[Iter 12150 Total] Train Loss: 1.1228\n",
      "======================================================================\n",
      "[Iter 12200 Task segm] Train Loss: 0.4958\n",
      "[Iter 12200 Task dept] Train Loss: 0.6740\n",
      "[Iter 12200 Total] Train Loss: 1.1698\n",
      "======================================================================\n",
      "[Iter 12200 Task segm] Val Loss: 1.5793\n",
      "{'mIoU': 0.2633, 'Pixel Acc': 0.5792}\n",
      "[Iter 12200 Task dept] Val Loss: 0.7255\n",
      "{'abs_err': 0.7194, 'rel_err': 0.27, 'sigma_1.25': 50.9106, 'sigma_1.25^2': 80.6602, 'sigma_1.25^3': 93.6961}\n",
      "======================================================================\n",
      "[Iter 12250 Task segm] Train Loss: 0.4785\n",
      "[Iter 12250 Task dept] Train Loss: 0.6588\n",
      "[Iter 12250 Total] Train Loss: 1.1373\n",
      "======================================================================\n",
      "[Iter 12300 Task segm] Train Loss: 0.4729\n",
      "[Iter 12300 Task dept] Train Loss: 0.6515\n",
      "[Iter 12300 Total] Train Loss: 1.1244\n",
      "======================================================================\n",
      "[Iter 12350 Task segm] Train Loss: 0.4782\n",
      "[Iter 12350 Task dept] Train Loss: 0.6695\n",
      "[Iter 12350 Total] Train Loss: 1.1476\n",
      "======================================================================\n",
      "[Iter 12400 Task segm] Train Loss: 0.4823\n",
      "[Iter 12400 Task dept] Train Loss: 0.6738\n",
      "[Iter 12400 Total] Train Loss: 1.1561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 12400 Task segm] Val Loss: 1.5733\n",
      "{'mIoU': 0.2621, 'Pixel Acc': 0.577}\n",
      "[Iter 12400 Task dept] Val Loss: 0.6986\n",
      "{'abs_err': 0.6961, 'rel_err': 0.2797, 'sigma_1.25': 53.0811, 'sigma_1.25^2': 81.9836, 'sigma_1.25^3': 93.7027}\n",
      "======================================================================\n",
      "[Iter 12450 Task segm] Train Loss: 0.4889\n",
      "[Iter 12450 Task dept] Train Loss: 0.6520\n",
      "[Iter 12450 Total] Train Loss: 1.1409\n",
      "======================================================================\n",
      "[Iter 12500 Task segm] Train Loss: 0.4627\n",
      "[Iter 12500 Task dept] Train Loss: 0.6489\n",
      "[Iter 12500 Total] Train Loss: 1.1116\n",
      "======================================================================\n",
      "[Iter 12550 Task segm] Train Loss: 0.4770\n",
      "[Iter 12550 Task dept] Train Loss: 0.6439\n",
      "[Iter 12550 Total] Train Loss: 1.1209\n",
      "======================================================================\n",
      "[Iter 12600 Task segm] Train Loss: 0.4803\n",
      "[Iter 12600 Task dept] Train Loss: 0.6673\n",
      "[Iter 12600 Total] Train Loss: 1.1476\n",
      "======================================================================\n",
      "[Iter 12600 Task segm] Val Loss: 1.5824\n",
      "{'mIoU': 0.262, 'Pixel Acc': 0.5786}\n",
      "[Iter 12600 Task dept] Val Loss: 0.7108\n",
      "{'abs_err': 0.7075, 'rel_err': 0.2844, 'sigma_1.25': 51.7958, 'sigma_1.25^2': 81.2837, 'sigma_1.25^3': 93.6387}\n",
      "======================================================================\n",
      "[Iter 12650 Task segm] Train Loss: 0.4700\n",
      "[Iter 12650 Task dept] Train Loss: 0.6481\n",
      "[Iter 12650 Total] Train Loss: 1.1181\n",
      "======================================================================\n",
      "[Iter 12700 Task segm] Train Loss: 0.4422\n",
      "[Iter 12700 Task dept] Train Loss: 0.6432\n",
      "[Iter 12700 Total] Train Loss: 1.0855\n",
      "======================================================================\n",
      "[Iter 12750 Task segm] Train Loss: 0.4681\n",
      "[Iter 12750 Task dept] Train Loss: 0.6299\n",
      "[Iter 12750 Total] Train Loss: 1.0980\n",
      "======================================================================\n",
      "[Iter 12800 Task segm] Train Loss: 0.4798\n",
      "[Iter 12800 Task dept] Train Loss: 0.6412\n",
      "[Iter 12800 Total] Train Loss: 1.1210\n",
      "======================================================================\n",
      "[Iter 12800 Task segm] Val Loss: 1.5766\n",
      "{'mIoU': 0.2656, 'Pixel Acc': 0.5818}\n",
      "[Iter 12800 Task dept] Val Loss: 0.7009\n",
      "{'abs_err': 0.6946, 'rel_err': 0.2702, 'sigma_1.25': 52.7197, 'sigma_1.25^2': 82.1711, 'sigma_1.25^3': 94.2493}\n",
      "======================================================================\n",
      "[Iter 12850 Task segm] Train Loss: 0.4750\n",
      "[Iter 12850 Task dept] Train Loss: 0.6622\n",
      "[Iter 12850 Total] Train Loss: 1.1371\n",
      "======================================================================\n",
      "[Iter 12900 Task segm] Train Loss: 0.4480\n",
      "[Iter 12900 Task dept] Train Loss: 0.6391\n",
      "[Iter 12900 Total] Train Loss: 1.0871\n",
      "======================================================================\n",
      "[Iter 12950 Task segm] Train Loss: 0.4758\n",
      "[Iter 12950 Task dept] Train Loss: 0.6479\n",
      "[Iter 12950 Total] Train Loss: 1.1237\n",
      "======================================================================\n",
      "[Iter 13000 Task segm] Train Loss: 0.4619\n",
      "[Iter 13000 Task dept] Train Loss: 0.6414\n",
      "[Iter 13000 Total] Train Loss: 1.1032\n",
      "======================================================================\n",
      "[Iter 13000 Task segm] Val Loss: 1.6181\n",
      "{'mIoU': 0.2556, 'Pixel Acc': 0.5729}\n",
      "[Iter 13000 Task dept] Val Loss: 0.7316\n",
      "{'abs_err': 0.7255, 'rel_err': 0.2722, 'sigma_1.25': 50.8776, 'sigma_1.25^2': 80.6456, 'sigma_1.25^3': 93.4817}\n",
      "======================================================================\n",
      "[Iter 13050 Task segm] Train Loss: 0.4563\n",
      "[Iter 13050 Task dept] Train Loss: 0.6205\n",
      "[Iter 13050 Total] Train Loss: 1.0768\n",
      "======================================================================\n",
      "[Iter 13100 Task segm] Train Loss: 0.4374\n",
      "[Iter 13100 Task dept] Train Loss: 0.6369\n",
      "[Iter 13100 Total] Train Loss: 1.0743\n",
      "======================================================================\n",
      "[Iter 13150 Task segm] Train Loss: 0.4506\n",
      "[Iter 13150 Task dept] Train Loss: 0.6454\n",
      "[Iter 13150 Total] Train Loss: 1.0961\n",
      "======================================================================\n",
      "[Iter 13200 Task segm] Train Loss: 0.4460\n",
      "[Iter 13200 Task dept] Train Loss: 0.6236\n",
      "[Iter 13200 Total] Train Loss: 1.0696\n",
      "======================================================================\n",
      "[Iter 13200 Task segm] Val Loss: 1.5904\n",
      "{'mIoU': 0.2654, 'Pixel Acc': 0.5824}\n",
      "[Iter 13200 Task dept] Val Loss: 0.7133\n",
      "{'abs_err': 0.7076, 'rel_err': 0.2651, 'sigma_1.25': 51.8487, 'sigma_1.25^2': 81.4774, 'sigma_1.25^3': 94.0861}\n",
      "======================================================================\n",
      "[Iter 13250 Task segm] Train Loss: 0.4423\n",
      "[Iter 13250 Task dept] Train Loss: 0.6585\n",
      "[Iter 13250 Total] Train Loss: 1.1007\n",
      "======================================================================\n",
      "[Iter 13300 Task segm] Train Loss: 0.4525\n",
      "[Iter 13300 Task dept] Train Loss: 0.6517\n",
      "[Iter 13300 Total] Train Loss: 1.1042\n",
      "======================================================================\n",
      "[Iter 13350 Task segm] Train Loss: 0.4511\n",
      "[Iter 13350 Task dept] Train Loss: 0.6242\n",
      "[Iter 13350 Total] Train Loss: 1.0753\n",
      "======================================================================\n",
      "[Iter 13400 Task segm] Train Loss: 0.4427\n",
      "[Iter 13400 Task dept] Train Loss: 0.6547\n",
      "[Iter 13400 Total] Train Loss: 1.0974\n",
      "======================================================================\n",
      "[Iter 13400 Task segm] Val Loss: 1.6210\n",
      "{'mIoU': 0.2612, 'Pixel Acc': 0.5785}\n",
      "[Iter 13400 Task dept] Val Loss: 0.7125\n",
      "{'abs_err': 0.7066, 'rel_err': 0.2686, 'sigma_1.25': 52.6855, 'sigma_1.25^2': 81.4464, 'sigma_1.25^3': 93.7441}\n",
      "======================================================================\n",
      "[Iter 13450 Task segm] Train Loss: 0.4497\n",
      "[Iter 13450 Task dept] Train Loss: 0.6310\n",
      "[Iter 13450 Total] Train Loss: 1.0807\n",
      "======================================================================\n",
      "[Iter 13500 Task segm] Train Loss: 0.4638\n",
      "[Iter 13500 Task dept] Train Loss: 0.6296\n",
      "[Iter 13500 Total] Train Loss: 1.0935\n",
      "======================================================================\n",
      "[Iter 13550 Task segm] Train Loss: 0.4372\n",
      "[Iter 13550 Task dept] Train Loss: 0.6217\n",
      "[Iter 13550 Total] Train Loss: 1.0589\n",
      "======================================================================\n",
      "[Iter 13600 Task segm] Train Loss: 0.4468\n",
      "[Iter 13600 Task dept] Train Loss: 0.6229\n",
      "[Iter 13600 Total] Train Loss: 1.0697\n",
      "======================================================================\n",
      "[Iter 13600 Task segm] Val Loss: 1.6450\n",
      "{'mIoU': 0.2607, 'Pixel Acc': 0.577}\n",
      "[Iter 13600 Task dept] Val Loss: 0.6912\n",
      "{'abs_err': 0.6886, 'rel_err': 0.2799, 'sigma_1.25': 53.5114, 'sigma_1.25^2': 82.201, 'sigma_1.25^3': 93.8833}\n",
      "======================================================================\n",
      "[Iter 13650 Task segm] Train Loss: 0.4378\n",
      "[Iter 13650 Task dept] Train Loss: 0.6218\n",
      "[Iter 13650 Total] Train Loss: 1.0597\n",
      "======================================================================\n",
      "[Iter 13700 Task segm] Train Loss: 0.4355\n",
      "[Iter 13700 Task dept] Train Loss: 0.6291\n",
      "[Iter 13700 Total] Train Loss: 1.0646\n",
      "======================================================================\n",
      "[Iter 13750 Task segm] Train Loss: 0.4417\n",
      "[Iter 13750 Task dept] Train Loss: 0.6109\n",
      "[Iter 13750 Total] Train Loss: 1.0525\n",
      "======================================================================\n",
      "[Iter 13800 Task segm] Train Loss: 0.4495\n",
      "[Iter 13800 Task dept] Train Loss: 0.6302\n",
      "[Iter 13800 Total] Train Loss: 1.0797\n",
      "======================================================================\n",
      "[Iter 13800 Task segm] Val Loss: 1.6474\n",
      "{'mIoU': 0.2587, 'Pixel Acc': 0.5746}\n",
      "[Iter 13800 Task dept] Val Loss: 0.6925\n",
      "{'abs_err': 0.6872, 'rel_err': 0.2648, 'sigma_1.25': 53.1193, 'sigma_1.25^2': 82.5763, 'sigma_1.25^3': 94.5361}\n",
      "======================================================================\n",
      "[Iter 13850 Task segm] Train Loss: 0.4452\n",
      "[Iter 13850 Task dept] Train Loss: 0.6248\n",
      "[Iter 13850 Total] Train Loss: 1.0700\n",
      "======================================================================\n",
      "[Iter 13900 Task segm] Train Loss: 0.4630\n",
      "[Iter 13900 Task dept] Train Loss: 0.6223\n",
      "[Iter 13900 Total] Train Loss: 1.0853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 13950 Task segm] Train Loss: 0.4461\n",
      "[Iter 13950 Task dept] Train Loss: 0.6095\n",
      "[Iter 13950 Total] Train Loss: 1.0556\n",
      "======================================================================\n",
      "[Iter 14000 Task segm] Train Loss: 0.4260\n",
      "[Iter 14000 Task dept] Train Loss: 0.6098\n",
      "[Iter 14000 Total] Train Loss: 1.0358\n",
      "======================================================================\n",
      "[Iter 14000 Task segm] Val Loss: 1.6324\n",
      "{'mIoU': 0.2539, 'Pixel Acc': 0.5741}\n",
      "[Iter 14000 Task dept] Val Loss: 0.6990\n",
      "{'abs_err': 0.6929, 'rel_err': 0.2659, 'sigma_1.25': 53.2549, 'sigma_1.25^2': 82.315, 'sigma_1.25^3': 94.3209}\n",
      "======================================================================\n",
      "[Iter 14050 Task segm] Train Loss: 0.4542\n",
      "[Iter 14050 Task dept] Train Loss: 0.6005\n",
      "[Iter 14050 Total] Train Loss: 1.0547\n",
      "======================================================================\n",
      "[Iter 14100 Task segm] Train Loss: 0.4327\n",
      "[Iter 14100 Task dept] Train Loss: 0.6156\n",
      "[Iter 14100 Total] Train Loss: 1.0483\n",
      "======================================================================\n",
      "[Iter 14150 Task segm] Train Loss: 0.4351\n",
      "[Iter 14150 Task dept] Train Loss: 0.6135\n",
      "[Iter 14150 Total] Train Loss: 1.0486\n",
      "======================================================================\n",
      "[Iter 14200 Task segm] Train Loss: 0.4307\n",
      "[Iter 14200 Task dept] Train Loss: 0.6203\n",
      "[Iter 14200 Total] Train Loss: 1.0510\n",
      "======================================================================\n",
      "[Iter 14200 Task segm] Val Loss: 1.6663\n",
      "{'mIoU': 0.2611, 'Pixel Acc': 0.5728}\n",
      "[Iter 14200 Task dept] Val Loss: 0.7075\n",
      "{'abs_err': 0.7002, 'rel_err': 0.2594, 'sigma_1.25': 52.1274, 'sigma_1.25^2': 81.7079, 'sigma_1.25^3': 94.2924}\n",
      "======================================================================\n",
      "[Iter 14250 Task segm] Train Loss: 0.4360\n",
      "[Iter 14250 Task dept] Train Loss: 0.6264\n",
      "[Iter 14250 Total] Train Loss: 1.0625\n",
      "======================================================================\n",
      "[Iter 14300 Task segm] Train Loss: 0.4139\n",
      "[Iter 14300 Task dept] Train Loss: 0.6125\n",
      "[Iter 14300 Total] Train Loss: 1.0265\n",
      "======================================================================\n",
      "[Iter 14350 Task segm] Train Loss: 0.4180\n",
      "[Iter 14350 Task dept] Train Loss: 0.6053\n",
      "[Iter 14350 Total] Train Loss: 1.0234\n",
      "======================================================================\n",
      "[Iter 14400 Task segm] Train Loss: 0.4135\n",
      "[Iter 14400 Task dept] Train Loss: 0.6004\n",
      "[Iter 14400 Total] Train Loss: 1.0140\n",
      "======================================================================\n",
      "[Iter 14400 Task segm] Val Loss: 1.6418\n",
      "{'mIoU': 0.2635, 'Pixel Acc': 0.5785}\n",
      "[Iter 14400 Task dept] Val Loss: 0.6899\n",
      "{'abs_err': 0.6844, 'rel_err': 0.2638, 'sigma_1.25': 53.8419, 'sigma_1.25^2': 82.5752, 'sigma_1.25^3': 94.522}\n",
      "======================================================================\n",
      "[Iter 14450 Task segm] Train Loss: 0.4372\n",
      "[Iter 14450 Task dept] Train Loss: 0.6047\n",
      "[Iter 14450 Total] Train Loss: 1.0419\n",
      "======================================================================\n",
      "[Iter 14500 Task segm] Train Loss: 0.4198\n",
      "[Iter 14500 Task dept] Train Loss: 0.6140\n",
      "[Iter 14500 Total] Train Loss: 1.0338\n",
      "======================================================================\n",
      "[Iter 14550 Task segm] Train Loss: 0.4237\n",
      "[Iter 14550 Task dept] Train Loss: 0.6026\n",
      "[Iter 14550 Total] Train Loss: 1.0262\n",
      "======================================================================\n",
      "[Iter 14600 Task segm] Train Loss: 0.4257\n",
      "[Iter 14600 Task dept] Train Loss: 0.6171\n",
      "[Iter 14600 Total] Train Loss: 1.0428\n",
      "======================================================================\n",
      "[Iter 14600 Task segm] Val Loss: 1.6359\n",
      "{'mIoU': 0.2648, 'Pixel Acc': 0.5847}\n",
      "[Iter 14600 Task dept] Val Loss: 0.7143\n",
      "{'abs_err': 0.7091, 'rel_err': 0.268, 'sigma_1.25': 51.8007, 'sigma_1.25^2': 81.6901, 'sigma_1.25^3': 93.9426}\n",
      "======================================================================\n",
      "[Iter 14650 Task segm] Train Loss: 0.4019\n",
      "[Iter 14650 Task dept] Train Loss: 0.6126\n",
      "[Iter 14650 Total] Train Loss: 1.0145\n",
      "======================================================================\n",
      "[Iter 14700 Task segm] Train Loss: 0.4265\n",
      "[Iter 14700 Task dept] Train Loss: 0.6146\n",
      "[Iter 14700 Total] Train Loss: 1.0412\n",
      "======================================================================\n",
      "[Iter 14750 Task segm] Train Loss: 0.4165\n",
      "[Iter 14750 Task dept] Train Loss: 0.5928\n",
      "[Iter 14750 Total] Train Loss: 1.0092\n",
      "======================================================================\n",
      "[Iter 14800 Task segm] Train Loss: 0.4090\n",
      "[Iter 14800 Task dept] Train Loss: 0.6084\n",
      "[Iter 14800 Total] Train Loss: 1.0174\n",
      "======================================================================\n",
      "[Iter 14800 Task segm] Val Loss: 1.7124\n",
      "{'mIoU': 0.2546, 'Pixel Acc': 0.5678}\n",
      "[Iter 14800 Task dept] Val Loss: 0.6732\n",
      "{'abs_err': 0.6694, 'rel_err': 0.2687, 'sigma_1.25': 54.9567, 'sigma_1.25^2': 83.0322, 'sigma_1.25^3': 94.3697}\n",
      "======================================================================\n",
      "[Iter 14850 Task segm] Train Loss: 0.4225\n",
      "[Iter 14850 Task dept] Train Loss: 0.5946\n",
      "[Iter 14850 Total] Train Loss: 1.0171\n",
      "======================================================================\n",
      "[Iter 14900 Task segm] Train Loss: 0.4126\n",
      "[Iter 14900 Task dept] Train Loss: 0.5945\n",
      "[Iter 14900 Total] Train Loss: 1.0071\n",
      "======================================================================\n",
      "[Iter 14950 Task segm] Train Loss: 0.4165\n",
      "[Iter 14950 Task dept] Train Loss: 0.6054\n",
      "[Iter 14950 Total] Train Loss: 1.0219\n",
      "======================================================================\n",
      "[Iter 15000 Task segm] Train Loss: 0.4284\n",
      "[Iter 15000 Task dept] Train Loss: 0.6075\n",
      "[Iter 15000 Total] Train Loss: 1.0358\n",
      "======================================================================\n",
      "[Iter 15000 Task segm] Val Loss: 1.6328\n",
      "{'mIoU': 0.2633, 'Pixel Acc': 0.5792}\n",
      "[Iter 15000 Task dept] Val Loss: 0.7649\n",
      "{'abs_err': 0.7564, 'rel_err': 0.2682, 'sigma_1.25': 48.2083, 'sigma_1.25^2': 78.7133, 'sigma_1.25^3': 93.1358}\n",
      "======================================================================\n",
      "[Iter 15050 Task segm] Train Loss: 0.4100\n",
      "[Iter 15050 Task dept] Train Loss: 0.5948\n",
      "[Iter 15050 Total] Train Loss: 1.0049\n",
      "======================================================================\n",
      "[Iter 15100 Task segm] Train Loss: 0.4065\n",
      "[Iter 15100 Task dept] Train Loss: 0.5958\n",
      "[Iter 15100 Total] Train Loss: 1.0023\n",
      "======================================================================\n",
      "[Iter 15150 Task segm] Train Loss: 0.4108\n",
      "[Iter 15150 Task dept] Train Loss: 0.6032\n",
      "[Iter 15150 Total] Train Loss: 1.0139\n",
      "======================================================================\n",
      "[Iter 15200 Task segm] Train Loss: 0.3902\n",
      "[Iter 15200 Task dept] Train Loss: 0.5823\n",
      "[Iter 15200 Total] Train Loss: 0.9725\n",
      "======================================================================\n",
      "[Iter 15200 Task segm] Val Loss: 1.5990\n",
      "{'mIoU': 0.2698, 'Pixel Acc': 0.5836}\n",
      "[Iter 15200 Task dept] Val Loss: 0.6838\n",
      "{'abs_err': 0.6821, 'rel_err': 0.2762, 'sigma_1.25': 54.6496, 'sigma_1.25^2': 82.6503, 'sigma_1.25^3': 94.0728}\n",
      "======================================================================\n",
      "[Iter 15250 Task segm] Train Loss: 0.4220\n",
      "[Iter 15250 Task dept] Train Loss: 0.6113\n",
      "[Iter 15250 Total] Train Loss: 1.0333\n",
      "======================================================================\n",
      "[Iter 15300 Task segm] Train Loss: 0.4218\n",
      "[Iter 15300 Task dept] Train Loss: 0.5811\n",
      "[Iter 15300 Total] Train Loss: 1.0029\n",
      "======================================================================\n",
      "[Iter 15350 Task segm] Train Loss: 0.4003\n",
      "[Iter 15350 Task dept] Train Loss: 0.5898\n",
      "[Iter 15350 Total] Train Loss: 0.9901\n",
      "======================================================================\n",
      "[Iter 15400 Task segm] Train Loss: 0.3943\n",
      "[Iter 15400 Task dept] Train Loss: 0.5813\n",
      "[Iter 15400 Total] Train Loss: 0.9757\n",
      "======================================================================\n",
      "[Iter 15400 Task segm] Val Loss: 1.6413\n",
      "{'mIoU': 0.2648, 'Pixel Acc': 0.5832}\n",
      "[Iter 15400 Task dept] Val Loss: 0.6998\n",
      "{'abs_err': 0.6938, 'rel_err': 0.2598, 'sigma_1.25': 52.4484, 'sigma_1.25^2': 82.3328, 'sigma_1.25^3': 94.5554}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[Iter 15450 Task segm] Train Loss: 0.3971\n",
      "[Iter 15450 Task dept] Train Loss: 0.5783\n",
      "[Iter 15450 Total] Train Loss: 0.9754\n",
      "======================================================================\n",
      "[Iter 15500 Task segm] Train Loss: 0.3873\n",
      "[Iter 15500 Task dept] Train Loss: 0.5890\n",
      "[Iter 15500 Total] Train Loss: 0.9763\n",
      "======================================================================\n",
      "[Iter 15550 Task segm] Train Loss: 0.3974\n",
      "[Iter 15550 Task dept] Train Loss: 0.5775\n",
      "[Iter 15550 Total] Train Loss: 0.9748\n",
      "======================================================================\n",
      "[Iter 15600 Task segm] Train Loss: 0.3895\n",
      "[Iter 15600 Task dept] Train Loss: 0.5878\n",
      "[Iter 15600 Total] Train Loss: 0.9773\n",
      "======================================================================\n",
      "[Iter 15600 Task segm] Val Loss: 1.6061\n",
      "{'mIoU': 0.2715, 'Pixel Acc': 0.5847}\n",
      "[Iter 15600 Task dept] Val Loss: 0.7206\n",
      "{'abs_err': 0.7143, 'rel_err': 0.2612, 'sigma_1.25': 51.8557, 'sigma_1.25^2': 81.1298, 'sigma_1.25^3': 93.8368}\n",
      "======================================================================\n",
      "[Iter 15650 Task segm] Train Loss: 0.4028\n",
      "[Iter 15650 Task dept] Train Loss: 0.5856\n",
      "[Iter 15650 Total] Train Loss: 0.9883\n",
      "======================================================================\n",
      "[Iter 15700 Task segm] Train Loss: 0.4119\n",
      "[Iter 15700 Task dept] Train Loss: 0.5913\n",
      "[Iter 15700 Total] Train Loss: 1.0032\n",
      "======================================================================\n",
      "[Iter 15750 Task segm] Train Loss: 0.3982\n",
      "[Iter 15750 Task dept] Train Loss: 0.5810\n",
      "[Iter 15750 Total] Train Loss: 0.9792\n",
      "======================================================================\n",
      "[Iter 15800 Task segm] Train Loss: 0.3769\n",
      "[Iter 15800 Task dept] Train Loss: 0.5759\n",
      "[Iter 15800 Total] Train Loss: 0.9528\n",
      "======================================================================\n",
      "[Iter 15800 Task segm] Val Loss: 1.6190\n",
      "{'mIoU': 0.2641, 'Pixel Acc': 0.5822}\n",
      "[Iter 15800 Task dept] Val Loss: 0.6676\n",
      "{'abs_err': 0.6619, 'rel_err': 0.255, 'sigma_1.25': 54.7086, 'sigma_1.25^2': 83.9873, 'sigma_1.25^3': 95.1737}\n",
      "======================================================================\n",
      "[Iter 15850 Task segm] Train Loss: 0.3947\n",
      "[Iter 15850 Task dept] Train Loss: 0.5875\n",
      "[Iter 15850 Total] Train Loss: 0.9822\n",
      "======================================================================\n",
      "[Iter 15900 Task segm] Train Loss: 0.3942\n",
      "[Iter 15900 Task dept] Train Loss: 0.5890\n",
      "[Iter 15900 Total] Train Loss: 0.9832\n",
      "======================================================================\n",
      "[Iter 15950 Task segm] Train Loss: 0.3846\n",
      "[Iter 15950 Task dept] Train Loss: 0.5762\n",
      "[Iter 15950 Total] Train Loss: 0.9607\n",
      "======================================================================\n",
      "[Iter 16000 Task segm] Train Loss: 0.3907\n",
      "[Iter 16000 Task dept] Train Loss: 0.5740\n",
      "[Iter 16000 Total] Train Loss: 0.9647\n",
      "======================================================================\n",
      "[Iter 16000 Task segm] Val Loss: 1.6404\n",
      "{'mIoU': 0.2651, 'Pixel Acc': 0.576}\n",
      "[Iter 16000 Task dept] Val Loss: 0.6718\n",
      "{'abs_err': 0.6656, 'rel_err': 0.2539, 'sigma_1.25': 54.1587, 'sigma_1.25^2': 83.6647, 'sigma_1.25^3': 95.4012}\n",
      "======================================================================\n",
      "[Iter 16050 Task segm] Train Loss: 0.3905\n",
      "[Iter 16050 Task dept] Train Loss: 0.5493\n",
      "[Iter 16050 Total] Train Loss: 0.9398\n",
      "======================================================================\n",
      "[Iter 16100 Task segm] Train Loss: 0.3789\n",
      "[Iter 16100 Task dept] Train Loss: 0.5638\n",
      "[Iter 16100 Total] Train Loss: 0.9427\n",
      "======================================================================\n",
      "[Iter 16150 Task segm] Train Loss: 0.3586\n",
      "[Iter 16150 Task dept] Train Loss: 0.5469\n",
      "[Iter 16150 Total] Train Loss: 0.9055\n",
      "======================================================================\n",
      "[Iter 16200 Task segm] Train Loss: 0.3624\n",
      "[Iter 16200 Task dept] Train Loss: 0.5639\n",
      "[Iter 16200 Total] Train Loss: 0.9264\n",
      "======================================================================\n",
      "[Iter 16200 Task segm] Val Loss: 1.6163\n",
      "{'mIoU': 0.2697, 'Pixel Acc': 0.585}\n",
      "[Iter 16200 Task dept] Val Loss: 0.6696\n",
      "{'abs_err': 0.6641, 'rel_err': 0.2532, 'sigma_1.25': 54.858, 'sigma_1.25^2': 83.8069, 'sigma_1.25^3': 95.2002}\n",
      "======================================================================\n",
      "[Iter 16250 Task segm] Train Loss: 0.3522\n",
      "[Iter 16250 Task dept] Train Loss: 0.5554\n",
      "[Iter 16250 Total] Train Loss: 0.9076\n",
      "======================================================================\n",
      "[Iter 16300 Task segm] Train Loss: 0.3572\n",
      "[Iter 16300 Task dept] Train Loss: 0.5593\n",
      "[Iter 16300 Total] Train Loss: 0.9165\n",
      "======================================================================\n",
      "[Iter 16350 Task segm] Train Loss: 0.3588\n",
      "[Iter 16350 Task dept] Train Loss: 0.5728\n",
      "[Iter 16350 Total] Train Loss: 0.9316\n",
      "======================================================================\n",
      "[Iter 16400 Task segm] Train Loss: 0.3734\n",
      "[Iter 16400 Task dept] Train Loss: 0.5516\n",
      "[Iter 16400 Total] Train Loss: 0.9251\n",
      "======================================================================\n",
      "[Iter 16400 Task segm] Val Loss: 1.6493\n",
      "{'mIoU': 0.2636, 'Pixel Acc': 0.5813}\n",
      "[Iter 16400 Task dept] Val Loss: 0.6886\n",
      "{'abs_err': 0.6827, 'rel_err': 0.2518, 'sigma_1.25': 53.1785, 'sigma_1.25^2': 82.7633, 'sigma_1.25^3': 94.9671}\n",
      "======================================================================\n",
      "[Iter 16450 Task segm] Train Loss: 0.3728\n",
      "[Iter 16450 Task dept] Train Loss: 0.5464\n",
      "[Iter 16450 Total] Train Loss: 0.9192\n",
      "======================================================================\n",
      "[Iter 16500 Task segm] Train Loss: 0.3581\n",
      "[Iter 16500 Task dept] Train Loss: 0.5539\n",
      "[Iter 16500 Total] Train Loss: 0.9120\n",
      "======================================================================\n",
      "[Iter 16550 Task segm] Train Loss: 0.3471\n",
      "[Iter 16550 Task dept] Train Loss: 0.5540\n",
      "[Iter 16550 Total] Train Loss: 0.9011\n",
      "======================================================================\n",
      "[Iter 16600 Task segm] Train Loss: 0.3396\n",
      "[Iter 16600 Task dept] Train Loss: 0.5507\n",
      "[Iter 16600 Total] Train Loss: 0.8903\n",
      "======================================================================\n",
      "[Iter 16600 Task segm] Val Loss: 1.6354\n",
      "{'mIoU': 0.2677, 'Pixel Acc': 0.5862}\n",
      "[Iter 16600 Task dept] Val Loss: 0.6908\n",
      "{'abs_err': 0.6836, 'rel_err': 0.2547, 'sigma_1.25': 53.2251, 'sigma_1.25^2': 82.6262, 'sigma_1.25^3': 94.8966}\n",
      "======================================================================\n",
      "[Iter 16650 Task segm] Train Loss: 0.3621\n",
      "[Iter 16650 Task dept] Train Loss: 0.5623\n",
      "[Iter 16650 Total] Train Loss: 0.9244\n",
      "======================================================================\n",
      "[Iter 16700 Task segm] Train Loss: 0.3449\n",
      "[Iter 16700 Task dept] Train Loss: 0.5603\n",
      "[Iter 16700 Total] Train Loss: 0.9052\n",
      "======================================================================\n",
      "[Iter 16750 Task segm] Train Loss: 0.3379\n",
      "[Iter 16750 Task dept] Train Loss: 0.5528\n",
      "[Iter 16750 Total] Train Loss: 0.8907\n",
      "======================================================================\n",
      "[Iter 16800 Task segm] Train Loss: 0.3405\n",
      "[Iter 16800 Task dept] Train Loss: 0.5421\n",
      "[Iter 16800 Total] Train Loss: 0.8827\n",
      "======================================================================\n",
      "[Iter 16800 Task segm] Val Loss: 1.6362\n",
      "{'mIoU': 0.2727, 'Pixel Acc': 0.5868}\n",
      "[Iter 16800 Task dept] Val Loss: 0.6560\n",
      "{'abs_err': 0.6514, 'rel_err': 0.2562, 'sigma_1.25': 56.2395, 'sigma_1.25^2': 84.451, 'sigma_1.25^3': 95.2164}\n",
      "======================================================================\n",
      "[Iter 16850 Task segm] Train Loss: 0.3434\n",
      "[Iter 16850 Task dept] Train Loss: 0.5520\n",
      "[Iter 16850 Total] Train Loss: 0.8954\n",
      "======================================================================\n",
      "[Iter 16900 Task segm] Train Loss: 0.3453\n",
      "[Iter 16900 Task dept] Train Loss: 0.5324\n",
      "[Iter 16900 Total] Train Loss: 0.8777\n",
      "======================================================================\n",
      "[Iter 16950 Task segm] Train Loss: 0.3450\n",
      "[Iter 16950 Task dept] Train Loss: 0.5457\n",
      "[Iter 16950 Total] Train Loss: 0.8908\n",
      "======================================================================\n",
      "[Iter 17000 Task segm] Train Loss: 0.3532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 17000 Task dept] Train Loss: 0.5291\n",
      "[Iter 17000 Total] Train Loss: 0.8823\n",
      "======================================================================\n",
      "[Iter 17000 Task segm] Val Loss: 1.6559\n",
      "{'mIoU': 0.2635, 'Pixel Acc': 0.5822}\n",
      "[Iter 17000 Task dept] Val Loss: 0.6584\n",
      "{'abs_err': 0.6549, 'rel_err': 0.2578, 'sigma_1.25': 55.6321, 'sigma_1.25^2': 84.1517, 'sigma_1.25^3': 95.226}\n",
      "======================================================================\n",
      "[Iter 17050 Task segm] Train Loss: 0.3468\n",
      "[Iter 17050 Task dept] Train Loss: 0.5385\n",
      "[Iter 17050 Total] Train Loss: 0.8853\n",
      "======================================================================\n",
      "[Iter 17100 Task segm] Train Loss: 0.3393\n",
      "[Iter 17100 Task dept] Train Loss: 0.5436\n",
      "[Iter 17100 Total] Train Loss: 0.8829\n",
      "======================================================================\n",
      "[Iter 17150 Task segm] Train Loss: 0.3521\n",
      "[Iter 17150 Task dept] Train Loss: 0.5530\n",
      "[Iter 17150 Total] Train Loss: 0.9051\n",
      "======================================================================\n",
      "[Iter 17200 Task segm] Train Loss: 0.3468\n",
      "[Iter 17200 Task dept] Train Loss: 0.5525\n",
      "[Iter 17200 Total] Train Loss: 0.8993\n",
      "======================================================================\n",
      "[Iter 17200 Task segm] Val Loss: 1.6586\n",
      "{'mIoU': 0.2639, 'Pixel Acc': 0.5805}\n",
      "[Iter 17200 Task dept] Val Loss: 0.6899\n",
      "{'abs_err': 0.6825, 'rel_err': 0.2546, 'sigma_1.25': 53.273, 'sigma_1.25^2': 82.7799, 'sigma_1.25^3': 94.7523}\n",
      "======================================================================\n",
      "[Iter 17250 Task segm] Train Loss: 0.3575\n",
      "[Iter 17250 Task dept] Train Loss: 0.5505\n",
      "[Iter 17250 Total] Train Loss: 0.9080\n",
      "======================================================================\n",
      "[Iter 17300 Task segm] Train Loss: 0.3501\n",
      "[Iter 17300 Task dept] Train Loss: 0.5447\n",
      "[Iter 17300 Total] Train Loss: 0.8947\n",
      "======================================================================\n",
      "[Iter 17350 Task segm] Train Loss: 0.3516\n",
      "[Iter 17350 Task dept] Train Loss: 0.5389\n",
      "[Iter 17350 Total] Train Loss: 0.8905\n",
      "======================================================================\n",
      "[Iter 17400 Task segm] Train Loss: 0.3308\n",
      "[Iter 17400 Task dept] Train Loss: 0.5368\n",
      "[Iter 17400 Total] Train Loss: 0.8676\n",
      "======================================================================\n",
      "[Iter 17400 Task segm] Val Loss: 1.6883\n",
      "{'mIoU': 0.2672, 'Pixel Acc': 0.5829}\n",
      "[Iter 17400 Task dept] Val Loss: 0.6838\n",
      "{'abs_err': 0.678, 'rel_err': 0.2552, 'sigma_1.25': 54.1229, 'sigma_1.25^2': 83.2534, 'sigma_1.25^3': 94.9575}\n",
      "======================================================================\n",
      "[Iter 17450 Task segm] Train Loss: 0.3521\n",
      "[Iter 17450 Task dept] Train Loss: 0.5466\n",
      "[Iter 17450 Total] Train Loss: 0.8987\n",
      "======================================================================\n",
      "[Iter 17500 Task segm] Train Loss: 0.3264\n",
      "[Iter 17500 Task dept] Train Loss: 0.5373\n",
      "[Iter 17500 Total] Train Loss: 0.8637\n",
      "======================================================================\n",
      "[Iter 17550 Task segm] Train Loss: 0.3460\n",
      "[Iter 17550 Task dept] Train Loss: 0.5458\n",
      "[Iter 17550 Total] Train Loss: 0.8917\n",
      "======================================================================\n",
      "[Iter 17600 Task segm] Train Loss: 0.3214\n",
      "[Iter 17600 Task dept] Train Loss: 0.5372\n",
      "[Iter 17600 Total] Train Loss: 0.8586\n",
      "======================================================================\n",
      "[Iter 17600 Task segm] Val Loss: 1.6593\n",
      "{'mIoU': 0.2688, 'Pixel Acc': 0.5857}\n",
      "[Iter 17600 Task dept] Val Loss: 0.6681\n",
      "{'abs_err': 0.6612, 'rel_err': 0.2513, 'sigma_1.25': 54.6991, 'sigma_1.25^2': 83.9549, 'sigma_1.25^3': 95.4395}\n",
      "======================================================================\n",
      "[Iter 17650 Task segm] Train Loss: 0.3370\n",
      "[Iter 17650 Task dept] Train Loss: 0.5389\n",
      "[Iter 17650 Total] Train Loss: 0.8759\n",
      "======================================================================\n",
      "[Iter 17700 Task segm] Train Loss: 0.3441\n",
      "[Iter 17700 Task dept] Train Loss: 0.5372\n",
      "[Iter 17700 Total] Train Loss: 0.8813\n",
      "======================================================================\n",
      "[Iter 17750 Task segm] Train Loss: 0.3412\n",
      "[Iter 17750 Task dept] Train Loss: 0.5419\n",
      "[Iter 17750 Total] Train Loss: 0.8832\n",
      "======================================================================\n",
      "[Iter 17800 Task segm] Train Loss: 0.3435\n",
      "[Iter 17800 Task dept] Train Loss: 0.5296\n",
      "[Iter 17800 Total] Train Loss: 0.8731\n",
      "======================================================================\n",
      "[Iter 17800 Task segm] Val Loss: 1.6559\n",
      "{'mIoU': 0.2657, 'Pixel Acc': 0.5838}\n",
      "[Iter 17800 Task dept] Val Loss: 0.6462\n",
      "{'abs_err': 0.6435, 'rel_err': 0.2596, 'sigma_1.25': 56.6587, 'sigma_1.25^2': 84.7246, 'sigma_1.25^3': 95.4272}\n",
      "======================================================================\n",
      "[Iter 17850 Task segm] Train Loss: 0.3416\n",
      "[Iter 17850 Task dept] Train Loss: 0.5360\n",
      "[Iter 17850 Total] Train Loss: 0.8776\n",
      "======================================================================\n",
      "[Iter 17900 Task segm] Train Loss: 0.3378\n",
      "[Iter 17900 Task dept] Train Loss: 0.5346\n",
      "[Iter 17900 Total] Train Loss: 0.8724\n",
      "======================================================================\n",
      "[Iter 17950 Task segm] Train Loss: 0.3368\n",
      "[Iter 17950 Task dept] Train Loss: 0.5297\n",
      "[Iter 17950 Total] Train Loss: 0.8666\n",
      "======================================================================\n",
      "[Iter 18000 Task segm] Train Loss: 0.3485\n",
      "[Iter 18000 Task dept] Train Loss: 0.5356\n",
      "[Iter 18000 Total] Train Loss: 0.8841\n",
      "======================================================================\n",
      "[Iter 18000 Task segm] Val Loss: 1.6676\n",
      "{'mIoU': 0.2678, 'Pixel Acc': 0.5827}\n",
      "[Iter 18000 Task dept] Val Loss: 0.6754\n",
      "{'abs_err': 0.6704, 'rel_err': 0.2585, 'sigma_1.25': 54.8694, 'sigma_1.25^2': 83.2409, 'sigma_1.25^3': 94.869}\n",
      "======================================================================\n",
      "[Iter 18050 Task segm] Train Loss: 0.3405\n",
      "[Iter 18050 Task dept] Train Loss: 0.5437\n",
      "[Iter 18050 Total] Train Loss: 0.8842\n",
      "======================================================================\n",
      "[Iter 18100 Task segm] Train Loss: 0.3223\n",
      "[Iter 18100 Task dept] Train Loss: 0.5353\n",
      "[Iter 18100 Total] Train Loss: 0.8576\n",
      "======================================================================\n",
      "[Iter 18150 Task segm] Train Loss: 0.3287\n",
      "[Iter 18150 Task dept] Train Loss: 0.5341\n",
      "[Iter 18150 Total] Train Loss: 0.8628\n",
      "======================================================================\n",
      "[Iter 18200 Task segm] Train Loss: 0.3437\n",
      "[Iter 18200 Task dept] Train Loss: 0.5492\n",
      "[Iter 18200 Total] Train Loss: 0.8929\n",
      "======================================================================\n",
      "[Iter 18200 Task segm] Val Loss: 1.6888\n",
      "{'mIoU': 0.2669, 'Pixel Acc': 0.5797}\n",
      "[Iter 18200 Task dept] Val Loss: 0.6605\n",
      "{'abs_err': 0.6577, 'rel_err': 0.2597, 'sigma_1.25': 55.9422, 'sigma_1.25^2': 84.0678, 'sigma_1.25^3': 95.0108}\n",
      "======================================================================\n",
      "[Iter 18250 Task segm] Train Loss: 0.3235\n",
      "[Iter 18250 Task dept] Train Loss: 0.5269\n",
      "[Iter 18250 Total] Train Loss: 0.8504\n",
      "======================================================================\n",
      "[Iter 18300 Task segm] Train Loss: 0.3348\n",
      "[Iter 18300 Task dept] Train Loss: 0.5324\n",
      "[Iter 18300 Total] Train Loss: 0.8672\n",
      "======================================================================\n",
      "[Iter 18350 Task segm] Train Loss: 0.3301\n",
      "[Iter 18350 Task dept] Train Loss: 0.5421\n",
      "[Iter 18350 Total] Train Loss: 0.8723\n",
      "======================================================================\n",
      "[Iter 18400 Task segm] Train Loss: 0.3283\n",
      "[Iter 18400 Task dept] Train Loss: 0.5310\n",
      "[Iter 18400 Total] Train Loss: 0.8593\n",
      "======================================================================\n",
      "[Iter 18400 Task segm] Val Loss: 1.7001\n",
      "{'mIoU': 0.2597, 'Pixel Acc': 0.5766}\n",
      "[Iter 18400 Task dept] Val Loss: 0.6860\n",
      "{'abs_err': 0.6804, 'rel_err': 0.2541, 'sigma_1.25': 53.4997, 'sigma_1.25^2': 82.9261, 'sigma_1.25^3': 94.8263}\n",
      "======================================================================\n",
      "[Iter 18450 Task segm] Train Loss: 0.3254\n",
      "[Iter 18450 Task dept] Train Loss: 0.5437\n",
      "[Iter 18450 Total] Train Loss: 0.8691\n",
      "======================================================================\n",
      "[Iter 18500 Task segm] Train Loss: 0.3222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 18500 Task dept] Train Loss: 0.5329\n",
      "[Iter 18500 Total] Train Loss: 0.8552\n",
      "======================================================================\n",
      "[Iter 18550 Task segm] Train Loss: 0.3325\n",
      "[Iter 18550 Task dept] Train Loss: 0.5380\n",
      "[Iter 18550 Total] Train Loss: 0.8705\n",
      "======================================================================\n",
      "[Iter 18600 Task segm] Train Loss: 0.3219\n",
      "[Iter 18600 Task dept] Train Loss: 0.5247\n",
      "[Iter 18600 Total] Train Loss: 0.8466\n",
      "======================================================================\n",
      "[Iter 18600 Task segm] Val Loss: 1.6699\n",
      "{'mIoU': 0.2666, 'Pixel Acc': 0.5832}\n",
      "[Iter 18600 Task dept] Val Loss: 0.6596\n",
      "{'abs_err': 0.6535, 'rel_err': 0.2482, 'sigma_1.25': 55.1234, 'sigma_1.25^2': 84.0872, 'sigma_1.25^3': 95.6125}\n",
      "======================================================================\n",
      "[Iter 18650 Task segm] Train Loss: 0.3263\n",
      "[Iter 18650 Task dept] Train Loss: 0.5278\n",
      "[Iter 18650 Total] Train Loss: 0.8541\n",
      "======================================================================\n",
      "[Iter 18700 Task segm] Train Loss: 0.3221\n",
      "[Iter 18700 Task dept] Train Loss: 0.5371\n",
      "[Iter 18700 Total] Train Loss: 0.8591\n",
      "======================================================================\n",
      "[Iter 18750 Task segm] Train Loss: 0.3268\n",
      "[Iter 18750 Task dept] Train Loss: 0.5139\n",
      "[Iter 18750 Total] Train Loss: 0.8407\n",
      "======================================================================\n",
      "[Iter 18800 Task segm] Train Loss: 0.3239\n",
      "[Iter 18800 Task dept] Train Loss: 0.5233\n",
      "[Iter 18800 Total] Train Loss: 0.8472\n",
      "======================================================================\n",
      "[Iter 18800 Task segm] Val Loss: 1.6961\n",
      "{'mIoU': 0.263, 'Pixel Acc': 0.5825}\n",
      "[Iter 18800 Task dept] Val Loss: 0.6618\n",
      "{'abs_err': 0.6587, 'rel_err': 0.2596, 'sigma_1.25': 55.721, 'sigma_1.25^2': 83.9915, 'sigma_1.25^3': 95.0481}\n",
      "======================================================================\n",
      "[Iter 18850 Task segm] Train Loss: 0.3217\n",
      "[Iter 18850 Task dept] Train Loss: 0.5189\n",
      "[Iter 18850 Total] Train Loss: 0.8406\n",
      "======================================================================\n",
      "[Iter 18900 Task segm] Train Loss: 0.3153\n",
      "[Iter 18900 Task dept] Train Loss: 0.5010\n",
      "[Iter 18900 Total] Train Loss: 0.8163\n",
      "======================================================================\n",
      "[Iter 18950 Task segm] Train Loss: 0.3243\n",
      "[Iter 18950 Task dept] Train Loss: 0.5169\n",
      "[Iter 18950 Total] Train Loss: 0.8412\n",
      "======================================================================\n",
      "[Iter 19000 Task segm] Train Loss: 0.3316\n",
      "[Iter 19000 Task dept] Train Loss: 0.5219\n",
      "[Iter 19000 Total] Train Loss: 0.8535\n",
      "======================================================================\n",
      "[Iter 19000 Task segm] Val Loss: 1.6953\n",
      "{'mIoU': 0.2671, 'Pixel Acc': 0.5788}\n",
      "[Iter 19000 Task dept] Val Loss: 0.6582\n",
      "{'abs_err': 0.6552, 'rel_err': 0.2649, 'sigma_1.25': 56.0885, 'sigma_1.25^2': 84.1025, 'sigma_1.25^3': 94.8383}\n",
      "======================================================================\n",
      "[Iter 19050 Task segm] Train Loss: 0.3331\n",
      "[Iter 19050 Task dept] Train Loss: 0.5349\n",
      "[Iter 19050 Total] Train Loss: 0.8680\n",
      "======================================================================\n",
      "[Iter 19100 Task segm] Train Loss: 0.3263\n",
      "[Iter 19100 Task dept] Train Loss: 0.5302\n",
      "[Iter 19100 Total] Train Loss: 0.8565\n",
      "======================================================================\n",
      "[Iter 19150 Task segm] Train Loss: 0.3167\n",
      "[Iter 19150 Task dept] Train Loss: 0.5230\n",
      "[Iter 19150 Total] Train Loss: 0.8397\n",
      "======================================================================\n",
      "[Iter 19200 Task segm] Train Loss: 0.3252\n",
      "[Iter 19200 Task dept] Train Loss: 0.5082\n",
      "[Iter 19200 Total] Train Loss: 0.8334\n",
      "======================================================================\n",
      "[Iter 19200 Task segm] Val Loss: 1.6804\n",
      "{'mIoU': 0.2676, 'Pixel Acc': 0.5836}\n",
      "[Iter 19200 Task dept] Val Loss: 0.6514\n",
      "{'abs_err': 0.647, 'rel_err': 0.2529, 'sigma_1.25': 56.1095, 'sigma_1.25^2': 84.6679, 'sigma_1.25^3': 95.487}\n",
      "======================================================================\n",
      "[Iter 19250 Task segm] Train Loss: 0.3304\n",
      "[Iter 19250 Task dept] Train Loss: 0.5198\n",
      "[Iter 19250 Total] Train Loss: 0.8503\n",
      "======================================================================\n",
      "[Iter 19300 Task segm] Train Loss: 0.3446\n",
      "[Iter 19300 Task dept] Train Loss: 0.5173\n",
      "[Iter 19300 Total] Train Loss: 0.8619\n",
      "======================================================================\n",
      "[Iter 19350 Task segm] Train Loss: 0.3252\n",
      "[Iter 19350 Task dept] Train Loss: 0.5130\n",
      "[Iter 19350 Total] Train Loss: 0.8382\n",
      "======================================================================\n",
      "[Iter 19400 Task segm] Train Loss: 0.3164\n",
      "[Iter 19400 Task dept] Train Loss: 0.5059\n",
      "[Iter 19400 Total] Train Loss: 0.8223\n",
      "======================================================================\n",
      "[Iter 19400 Task segm] Val Loss: 1.7029\n",
      "{'mIoU': 0.2607, 'Pixel Acc': 0.5778}\n",
      "[Iter 19400 Task dept] Val Loss: 0.6812\n",
      "{'abs_err': 0.6749, 'rel_err': 0.2532, 'sigma_1.25': 53.859, 'sigma_1.25^2': 83.0979, 'sigma_1.25^3': 94.9646}\n",
      "======================================================================\n",
      "[Iter 19450 Task segm] Train Loss: 0.3116\n",
      "[Iter 19450 Task dept] Train Loss: 0.5296\n",
      "[Iter 19450 Total] Train Loss: 0.8412\n",
      "======================================================================\n",
      "[Iter 19500 Task segm] Train Loss: 0.3151\n",
      "[Iter 19500 Task dept] Train Loss: 0.5130\n",
      "[Iter 19500 Total] Train Loss: 0.8281\n",
      "======================================================================\n",
      "[Iter 19550 Task segm] Train Loss: 0.3142\n",
      "[Iter 19550 Task dept] Train Loss: 0.5236\n",
      "[Iter 19550 Total] Train Loss: 0.8378\n",
      "======================================================================\n",
      "[Iter 19600 Task segm] Train Loss: 0.3086\n",
      "[Iter 19600 Task dept] Train Loss: 0.5252\n",
      "[Iter 19600 Total] Train Loss: 0.8338\n",
      "======================================================================\n",
      "[Iter 19600 Task segm] Val Loss: 1.7069\n",
      "{'mIoU': 0.2657, 'Pixel Acc': 0.5839}\n",
      "[Iter 19600 Task dept] Val Loss: 0.6797\n",
      "{'abs_err': 0.673, 'rel_err': 0.2527, 'sigma_1.25': 54.9192, 'sigma_1.25^2': 83.3111, 'sigma_1.25^3': 94.9612}\n",
      "======================================================================\n",
      "[Iter 19650 Task segm] Train Loss: 0.3061\n",
      "[Iter 19650 Task dept] Train Loss: 0.5177\n",
      "[Iter 19650 Total] Train Loss: 0.8237\n",
      "======================================================================\n",
      "[Iter 19700 Task segm] Train Loss: 0.3089\n",
      "[Iter 19700 Task dept] Train Loss: 0.5084\n",
      "[Iter 19700 Total] Train Loss: 0.8173\n",
      "======================================================================\n",
      "[Iter 19750 Task segm] Train Loss: 0.3100\n",
      "[Iter 19750 Task dept] Train Loss: 0.5141\n",
      "[Iter 19750 Total] Train Loss: 0.8241\n",
      "======================================================================\n",
      "[Iter 19800 Task segm] Train Loss: 0.3048\n",
      "[Iter 19800 Task dept] Train Loss: 0.5140\n",
      "[Iter 19800 Total] Train Loss: 0.8188\n",
      "======================================================================\n",
      "[Iter 19800 Task segm] Val Loss: 1.6880\n",
      "{'mIoU': 0.2709, 'Pixel Acc': 0.5861}\n",
      "[Iter 19800 Task dept] Val Loss: 0.6943\n",
      "{'abs_err': 0.6877, 'rel_err': 0.2559, 'sigma_1.25': 52.8951, 'sigma_1.25^2': 82.6867, 'sigma_1.25^3': 94.8459}\n",
      "======================================================================\n",
      "[Iter 19850 Task segm] Train Loss: 0.3063\n",
      "[Iter 19850 Task dept] Train Loss: 0.5075\n",
      "[Iter 19850 Total] Train Loss: 0.8138\n",
      "======================================================================\n",
      "[Iter 19900 Task segm] Train Loss: 0.3144\n",
      "[Iter 19900 Task dept] Train Loss: 0.5283\n",
      "[Iter 19900 Total] Train Loss: 0.8427\n",
      "======================================================================\n",
      "[Iter 19950 Task segm] Train Loss: 0.3218\n",
      "[Iter 19950 Task dept] Train Loss: 0.5105\n",
      "[Iter 19950 Total] Train Loss: 0.8324\n",
      "======================================================================\n",
      "[Iter 20000 Task segm] Train Loss: 0.3085\n",
      "[Iter 20000 Task dept] Train Loss: 0.5211\n",
      "[Iter 20000 Total] Train Loss: 0.8296\n",
      "======================================================================\n",
      "[Iter 20000 Task segm] Val Loss: 1.7008\n",
      "{'mIoU': 0.2661, 'Pixel Acc': 0.5824}\n",
      "[Iter 20000 Task dept] Val Loss: 0.6430\n",
      "{'abs_err': 0.6402, 'rel_err': 0.2562, 'sigma_1.25': 56.7202, 'sigma_1.25^2': 84.8104, 'sigma_1.25^3': 95.5898}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# bs = 16, Adam, reload\n",
    "loss_lambda = {'segment_semantic': 1, 'normal':1, 'depth_zbuffer': 1}\n",
    "checkpoint = '/mnt/nfs/work1/huiguan/lijunzhang/multibranch/checkpoint/NYUv2/exp/'\n",
    "\n",
    "trainer = Trainer(model, two_task, trainDataloader, valDataloader, criterionDict, metricDict)\n",
    "trainer.train(20000, loss_lambda, checkpoint, reload='segment_semantic_depth_zbuffer_b0.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deeplab_ASPP_Branch(\n",
       "  (backbone): Deeplab_ResNet_Backbone_Branch(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
       "    (shared_blocks): ModuleList(\n",
       "      (0): ResidualBlock(\n",
       "        (block): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (block): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ResidualBlock(\n",
       "        (block): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ResidualBlock(\n",
       "        (block): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (ds): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): ResidualBlock(\n",
       "        (block): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): ResidualBlock(\n",
       "        (block): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): ResidualBlock(\n",
       "        (block): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): ResidualBlock(\n",
       "        (block): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (ds): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): ResidualBlock(\n",
       "        (block): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (separate_blocks): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (ds): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (ds): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): ModuleList(\n",
       "        (0): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (block): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (heads): ModuleDict(\n",
       "    (segment_semantic): ASPPHeadNode(\n",
       "      (fc1): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc2): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc3): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc4): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (normal): ASPPHeadNode(\n",
       "      (fc1): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc2): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc3): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc4): Classification_Module(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = \"models/backbone_b10.onnx\"\n",
    "\n",
    "x = torch.rand(1,3,224,224)\n",
    "y = model(x)\n",
    "torch.onnx.export(model,x,PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
