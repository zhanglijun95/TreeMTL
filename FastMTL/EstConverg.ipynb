{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "diverse-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append('/home/lijunzhang/multibranch/')\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from collections import OrderedDict\n",
    "from ptflops import get_model_complexity_info\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from framework.layer_node import Conv2dNode, InputNode\n",
    "from main.layout import Layout\n",
    "from main.algorithms import enum_layout_wo_rdt, init_S, coarse_to_fined\n",
    "from main.auto_models import MTSeqBackbone, MTSeqModel, ComputeBlock\n",
    "from main.head import ASPPHeadNode\n",
    "from main.trainer import Trainer\n",
    "from main.algs_FMTL import simple_alignment, complex_alignment\n",
    "\n",
    "from data.nyuv2_dataloader_adashare import NYU_v2\n",
    "from data.pixel2pixel_loss import NYUCriterions\n",
    "from data.pixel2pixel_metrics import NYUMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "psychological-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0473c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj(obj, name):\n",
    "    with open('./exp/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('./exp/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-clerk",
   "metadata": {},
   "source": [
    "# backbone and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "married-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone\n",
    "# mobilenet\n",
    "backbone_type = 'mobilenet'\n",
    "prototxt = '../models/mobilenetv2.prototxt'\n",
    "D = coarse_B = 5\n",
    "mapping = {0:[0,1,2,3,4,5,6], 1:[7,8,9,10,11,12,13,14,15,16,17], 2:[18,19,20,21,22], \n",
    "           3:[23,24,25,26,27,28,29,30], 4:[31], 5:[32]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "generous-syracuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment_semantic\n",
      "normal\n",
      "depth_zbuffer\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "# NYUv2\n",
    "data = 'NYUv2'\n",
    "dataroot = '/mnt/nfs/work1/huiguan/lijunzhang/policymtl/data/NYUv2/'\n",
    "tasks = ['segment_semantic', 'normal', 'depth_zbuffer']\n",
    "cls_num = {'segment_semantic': 40, 'normal':3, 'depth_zbuffer': 1}\n",
    "\n",
    "dataset = NYU_v2(dataroot, 'train', crop_h=321, crop_w=321)\n",
    "trainDataloader = DataLoader(dataset, 32, shuffle=True)\n",
    "dataset = NYU_v2(dataroot, 'test', crop_h=224, crop_w=224)\n",
    "valDataloader = DataLoader(dataset, 32, shuffle=True)\n",
    "\n",
    "criterionDict = {}\n",
    "metricDict = {}\n",
    "for task in tasks:\n",
    "    print(task, flush=True)\n",
    "    criterionDict[task] = NYUCriterions(task)\n",
    "    metricDict[task] = NYUMetrics(task)\n",
    "\n",
    "input_dim = (3,321,321)\n",
    "T = len(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cloudy-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind. weights\n",
    "ckpt_PATH = '/mnt/nfs/work1/huiguan/lijunzhang/multibranch/checkpoint/'\n",
    "weight_PATH = ckpt_PATH + 'NYUv2/ind/mobilenet/segment_semantic_normal_depth_zbuffer.model' # NYUv2 + MobileNetV2, from the same init\n",
    "# weight_PATH = ckpt_PATH + 'NYUv2/baseline/WPreMobile/2/segment_semantic_normal_depth_zbuffer.model' # NYUv2 + MobileNetV2, from the same init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-veteran",
   "metadata": {},
   "source": [
    "# load independent model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "greek-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    backbone = MTSeqBackbone(prototxt)\n",
    "    fined_B = len(backbone.basic_blocks)\n",
    "    feature_dim = backbone(torch.rand(1,3,224,224)).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sunset-mechanism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ind. Layout:\n",
      "[[{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}]]\n",
      "Construct MTSeqModel from Layout:\n",
      "[[{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}], [{0}, {1}, {2}]]\n"
     ]
    }
   ],
   "source": [
    "# ind. layout\n",
    "S = []\n",
    "for i in range(fined_B):\n",
    "    S.append([set([x]) for x in range(T)])\n",
    "layout = Layout(T, fined_B, S) \n",
    "print('Ind. Layout:', flush=True)\n",
    "print(layout, flush=True)\n",
    "\n",
    "# model\n",
    "with torch.no_grad():\n",
    "    model = MTSeqModel(prototxt, layout=layout, feature_dim=feature_dim, cls_num=cls_num)\n",
    "#     model = model.cuda()\n",
    "\n",
    "    # load ind. model weights\n",
    "    model.load_state_dict(torch.load(weight_PATH)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd92834e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment_semantic: 0.6924\n",
      "------------------------------\n",
      "normal: 0.0691\n",
      "------------------------------\n",
      "depth_zbuffer: 1.0278\n",
      "------------------------------\n",
      "segment_semantic: 0.7632\n",
      "------------------------------\n",
      "normal: 0.0823\n",
      "------------------------------\n",
      "depth_zbuffer: 0.9296\n",
      "------------------------------\n",
      "segment_semantic: 0.6722\n",
      "------------------------------\n",
      "normal: 0.0681\n",
      "------------------------------\n",
      "depth_zbuffer: 1.1606\n",
      "------------------------------\n",
      "segment_semantic: 0.7691\n",
      "------------------------------\n",
      "normal: 0.0812\n",
      "------------------------------\n",
      "depth_zbuffer: 1.0446\n",
      "------------------------------\n",
      "segment_semantic: 0.7071\n",
      "------------------------------\n",
      "normal: 0.0729\n",
      "------------------------------\n",
      "depth_zbuffer: 1.2141\n",
      "------------------------------\n",
      "segment_semantic: 0.6427\n",
      "------------------------------\n",
      "normal: 0.0636\n",
      "------------------------------\n",
      "depth_zbuffer: 0.8945\n",
      "------------------------------\n",
      "segment_semantic: 0.7339\n",
      "------------------------------\n",
      "normal: 0.0732\n",
      "------------------------------\n",
      "depth_zbuffer: 1.1320\n",
      "------------------------------\n",
      "segment_semantic: 0.6472\n",
      "------------------------------\n",
      "normal: 0.0676\n",
      "------------------------------\n",
      "depth_zbuffer: 1.0109\n",
      "------------------------------\n",
      "segment_semantic: 0.6558\n",
      "------------------------------\n",
      "normal: 0.0630\n",
      "------------------------------\n",
      "depth_zbuffer: 1.0305\n",
      "------------------------------\n",
      "segment_semantic: 0.9585\n",
      "------------------------------\n",
      "normal: 0.0725\n",
      "------------------------------\n",
      "depth_zbuffer: 1.2242\n",
      "------------------------------\n",
      "segment_semantic: 0.7801\n",
      "------------------------------\n",
      "normal: 0.0702\n",
      "------------------------------\n",
      "depth_zbuffer: 1.0881\n",
      "------------------------------\n",
      "segment_semantic: 0.6815\n",
      "------------------------------\n",
      "normal: 0.0713\n",
      "------------------------------\n",
      "depth_zbuffer: 0.9355\n",
      "------------------------------\n",
      "segment_semantic: 0.7009\n",
      "------------------------------\n",
      "normal: 0.0703\n",
      "------------------------------\n",
      "depth_zbuffer: 1.0844\n",
      "------------------------------\n",
      "segment_semantic: 0.6787\n",
      "------------------------------\n",
      "normal: 0.0702\n",
      "------------------------------\n",
      "depth_zbuffer: 1.1170\n",
      "------------------------------\n",
      "segment_semantic: 0.6294\n",
      "------------------------------\n",
      "normal: 0.0732\n",
      "------------------------------\n",
      "depth_zbuffer: 1.1987\n",
      "------------------------------\n",
      "segment_semantic: 0.7290\n",
      "------------------------------\n",
      "normal: 0.0792\n",
      "------------------------------\n",
      "depth_zbuffer: 1.4504\n",
      "------------------------------\n",
      "segment_semantic: 0.6770\n",
      "------------------------------\n",
      "normal: 0.0767\n",
      "------------------------------\n",
      "depth_zbuffer: 1.2784\n",
      "------------------------------\n",
      "segment_semantic: 0.7380\n",
      "------------------------------\n",
      "normal: 0.0840\n",
      "------------------------------\n",
      "depth_zbuffer: 1.0424\n",
      "------------------------------\n",
      "segment_semantic: 0.7760\n",
      "------------------------------\n",
      "normal: 0.0755\n",
      "------------------------------\n",
      "depth_zbuffer: 1.1154\n",
      "------------------------------\n",
      "segment_semantic: 0.8095\n",
      "------------------------------\n",
      "normal: 0.0806\n",
      "------------------------------\n",
      "depth_zbuffer: 1.3340\n",
      "------------------------------\n",
      "segment_semantic: 0.7171\n",
      "------------------------------\n",
      "normal: 0.0716\n",
      "------------------------------\n",
      "depth_zbuffer: 1.0815\n",
      "------------------------------\n",
      "segment_semantic: 0.8321\n",
      "------------------------------\n",
      "normal: 0.0749\n",
      "------------------------------\n",
      "depth_zbuffer: 1.1424\n",
      "------------------------------\n",
      "segment_semantic: 0.7494\n",
      "------------------------------\n",
      "normal: 0.0763\n",
      "------------------------------\n",
      "depth_zbuffer: 1.0334\n",
      "------------------------------\n",
      "segment_semantic: 0.7602\n",
      "------------------------------\n",
      "normal: 0.0729\n",
      "------------------------------\n",
      "depth_zbuffer: 0.9388\n",
      "------------------------------\n",
      "segment_semantic: 0.6015\n",
      "------------------------------\n",
      "normal: 0.0846\n",
      "------------------------------\n",
      "depth_zbuffer: 1.1295\n",
      "------------------------------\n",
      "r0: {'segment_semantic': 0.7240976285934448, 'normal': 0.07379929304122924, 'depth_zbuffer': 1.1055510187149047}\n"
     ]
    }
   ],
   "source": [
    "# compute r0 --> stop convergency loss for layout convergency iter estimation\n",
    "loss_lst = {task:[] for task in tasks}\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "for i, data in enumerate(trainDataloader):\n",
    "    x = data['input'].cuda()\n",
    "    output = model(x)\n",
    "    for task in tasks:\n",
    "        y = data[task].cuda()\n",
    "        if task + '_mask' in data:\n",
    "            tloss = criterionDict[task](output[task], y, data[task + '_mask'].cuda())\n",
    "        else:\n",
    "            tloss = criterionDict[task](output[task], y)\n",
    "        loss_lst[task].append(tloss.item())\n",
    "        print('{}: {:.4f}'.format(task,tloss.item()))\n",
    "    print('-'*30)\n",
    "\n",
    "target = {task: np.mean(loss_lst[task]) for task in tasks}\n",
    "print('r0: {}'.format(target))\n",
    "save_obj(target, 'r0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "849f5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = load_obj('r0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1ee8ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segment_semantic': 0.7240976285934448,\n",
       " 'normal': 0.07379929304122924,\n",
       " 'depth_zbuffer': 1.1055510187149047}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8672a0",
   "metadata": {},
   "source": [
    "# enum layouts and channel alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c03889d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enum layout\n",
    "layout_list = [] \n",
    "S0 = init_S(T, coarse_B) # initial state\n",
    "L = Layout(T, coarse_B, S0) # initial layout\n",
    "layout_list.append(L)\n",
    "enum_layout_wo_rdt(L, layout_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e15284aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "align_choice = 2 # 0: no align; 1: simple align (use out_ord only); 2: complex align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3c90818",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "if align_choice == 1:\n",
    "    simple_alignment(model, tasks)\n",
    "elif align_choice == 2:\n",
    "    complex_alignment(model, tasks)\n",
    "elif align_choice == 0:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49848dc0",
   "metadata": {},
   "source": [
    "# est. convergence rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b431159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(scalars, weight):  # Weight between 0 and 1\n",
    "    last = scalars[0]  # First value in the plot (first timestep)\n",
    "    smoothed = list()\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  # Calculate smoothed value\n",
    "        smoothed.append(smoothed_val)                        # Save it\n",
    "        last = smoothed_val                                  # Anchor the last smoothed value\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8241f4e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fined Layout:\n",
      "[[{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}], [{0, 1, 2}]]\n",
      "Finish Weight Loading.\n",
      "Task segment_semantic:\n",
      "loss samples: [6.37286070721575, 4.903586675667633, 4.374546643914657]\n",
      "alpha: 0.4356049592840212\n",
      "est iter: nan\n",
      "final loss: 4.005586908478982\n",
      "--------------------------------------------------\n",
      "Task normal:\n",
      "loss samples: [0.07546639882031059, 0.07293267534603777, 0.0638933990429129]\n",
      "alpha: 3.874606316806775\n",
      "est iter: 51.242273300114135\n",
      "final loss: 0.0\n",
      "--------------------------------------------------\n",
      "Task depth_zbuffer:\n",
      "loss samples: [1.0968553205361786, 0.9696726088789933, 1.10702626406812]\n",
      "alpha: -1.0748927959042853\n",
      "est iter: nan\n",
      "final loss: 0.0\n",
      "--------------------------------------------------\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "total_iter, short_iter, start, step = 20000, 101, 20, 40\n",
    "# loss_slice = [x for x in range(start,short_iter,step)]\n",
    "# if len(loss_slice) < 3:\n",
    "#     sys.exit('Not enough loss samples!')\n",
    "smooth_weight = 0.5\n",
    "\n",
    "layout_est_iter = []\n",
    "layout_est_loss = []\n",
    "\n",
    "# For each layout\n",
    "for L in layout_list:\n",
    "    layout = coarse_to_fined(L, fined_B, mapping)\n",
    "    print('Fined Layout:', flush=True)\n",
    "    print(layout, flush=True)\n",
    "    \n",
    "    mtl_model = MTSeqModel(prototxt, layout=layout, feature_dim=feature_dim, cls_num=cls_num, verbose=False)\n",
    "    \n",
    "    # Step 1: create weight init state_dict\n",
    "    mtl_init = OrderedDict()\n",
    "    for name, module in mtl_model.named_modules():\n",
    "        if isinstance(module, ComputeBlock):\n",
    "            task_set = module.task_set\n",
    "            layer_idx = module.layer_idx\n",
    "            if len(task_set) > 1:\n",
    "                merge_flag = True\n",
    "            else:\n",
    "                # Type 1: save the whole block weights from the corresponding ind. model when no merging\n",
    "                merge_flag = False\n",
    "                for block in model.backbone.mtl_blocks:\n",
    "                    if task_set == block.task_set and block.layer_idx == layer_idx:\n",
    "                        for ind_name, param in block.named_parameters():\n",
    "                            mtl_init['.'.join([name, ind_name])] = param  \n",
    "                        # for BN running mean and running var\n",
    "                        for ind_name, param in block.named_buffers():\n",
    "                            mtl_init['.'.join([name, ind_name])] = param\n",
    "\n",
    "        # # Type 2: when the current block have merged operators, save mean weights for convs\n",
    "        elif isinstance(module, Conv2dNode) and merge_flag: \n",
    "            task_convs = [] # store conv weights from task's ind. block\n",
    "            for task in task_set:\n",
    "                # identify task-corresponding block in the well-trained ind. models \n",
    "                for block in model.backbone.mtl_blocks:\n",
    "                    if task in block.task_set and block.layer_idx == layer_idx:\n",
    "                        task_module = block.compute_nodes[int(name.split('.')[-1])]  \n",
    "                        temp_weight = task_module.basicOp.weight # no channel alignment or no align variable\n",
    "                        if align_choice == 1 and task_module.out_ord is not None: # simple alignment\n",
    "                            temp_weight = temp_weight[task_module.out_ord]\n",
    "                        elif align_choice == 2: # complex alignment\n",
    "                            if task_module.in_ord is not None:\n",
    "                                temp_weight = temp_weight[:,task_module.in_ord]\n",
    "                            if task_module.out_ord is not None: \n",
    "                                temp_weight = temp_weight[task_module.out_ord]\n",
    "                        task_convs.append(temp_weight)\n",
    "            weight_anchor = torch.mean(torch.stack(task_convs),dim=0)\n",
    "            mtl_init[name+'.basicOp.weight'] = weight_anchor\n",
    "\n",
    "        # Type 3: save heads' weights\n",
    "        elif 'heads' in name and isinstance(module, ASPPHeadNode): \n",
    "            ind_head = model.heads[name.split('.')[-1]]\n",
    "            for ind_name, param in ind_head.named_parameters():\n",
    "                mtl_init['.'.join([name, ind_name])] = param\n",
    "            for ind_name, param in ind_head.named_buffers():\n",
    "                mtl_init['.'.join([name, ind_name])] = param\n",
    "    mtl_model.load_state_dict(mtl_init,strict=False)\n",
    "    print('Finish Weight Loading.', flush=True)\n",
    "\n",
    "    # Step 2: Save short train loss list\n",
    "    loss_lst = {task: [] for task in tasks}\n",
    "    \n",
    "    mtl_model = mtl_model.cuda()\n",
    "    mtl_model.train()\n",
    "    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, mtl_model.parameters()), lr=0.0001)\n",
    "    trainIter = iter(trainDataloader)\n",
    "    for i in range(short_iter):\n",
    "        try:\n",
    "            data = next(trainIter)\n",
    "        except StopIteration:\n",
    "            trainIter = iter(trainDataloader)\n",
    "            data = next(trainIter)\n",
    "            \n",
    "        x = data['input'].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = mtl_model(x)\n",
    "\n",
    "        loss = 0\n",
    "        for task in tasks:\n",
    "            y = data[task].cuda()\n",
    "            if task + '_mask' in data:\n",
    "                tloss = criterionDict[task](output[task], y, data[task + '_mask'].cuda())\n",
    "            else:\n",
    "                tloss = criterionDict[task](output[task], y)\n",
    "            loss_lst[task].append(tloss.item())\n",
    "            loss += tloss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # For each task\n",
    "    est_iter ={}\n",
    "    final_loss = {}\n",
    "    for task in tasks:\n",
    "        print('Task {}:'.format(task))\n",
    "        \n",
    "        # Step 3: Smooth and take loss samples\n",
    "        sm_loss_lst = smooth(loss_lst[task], smooth_weight)\n",
    "        loss_samples = sm_loss_lst[start:short_iter:step]\n",
    "        print('loss samples: {}'.format(loss_samples))\n",
    "        \n",
    "        # Step 4: Compute convergence rate \n",
    "        alpha = compute_alpha(loss_samples)\n",
    "        print('alpha: {}'.format(alpha))\n",
    "        \n",
    "        # Step 5: Estimate iters to reach target loss\n",
    "        n = est_recov_n(loss_samples, target[task], alpha)\n",
    "        est_iter[task] = start + n*step\n",
    "        print('est iter: {}'.format(est_iter[task]))\n",
    "        \n",
    "        # Step 6: Estimate final loss after 20000 iters\n",
    "        n = (total_iter - start)//step\n",
    "        final_loss[task] = est_final_loss(loss_samples, n, alpha)\n",
    "        print('final loss: {}'.format(final_loss[task]))\n",
    "        print('-'*50)\n",
    "    layout_est_iter.append(est_iter)\n",
    "    layout_est_loss.append(final_loss)\n",
    "    print('='*50)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9ea81ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task segment_semantic:\n",
      "loss samples: [5.311834793688948, 4.940007649283774, 4.768060193262548]\n",
      "alpha: 0.48817851583175814\n",
      "est iter: nan\n",
      "final loss: 4.6096353339477485\n",
      "--------------------------------------------------\n",
      "Task normal:\n",
      "loss samples: [0.07025943309965477, 0.07313488226350928, 0.07168730783228883]\n",
      "alpha: -0.49841175400357385\n",
      "est iter: nan\n",
      "final loss: 0.07216560125634357\n",
      "--------------------------------------------------\n",
      "Task depth_zbuffer:\n",
      "loss samples: [1.0837086341480626, 0.9685742503090615, 0.9558088031202223]\n",
      "alpha: 0.11812092076281999\n",
      "est iter: 27.95579893488618\n",
      "final loss: 0.9541117952291159\n",
      "--------------------------------------------------\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "total_iter, short_iter, start, step = 20000, 100, 30, 30\n",
    "smooth_weight = 0.6\n",
    "\n",
    "est_iter ={}\n",
    "final_loss = {}\n",
    "for task in tasks:\n",
    "    print('Task {}:'.format(task))\n",
    "\n",
    "    # Step 3: Smooth and take loss samples\n",
    "    sm_loss_lst = smooth(loss_lst[task], smooth_weight)\n",
    "    loss_samples = sm_loss_lst[start:short_iter:step]\n",
    "    print('loss samples: {}'.format(loss_samples))\n",
    "\n",
    "    # Step 4: Compute convergence rate \n",
    "    alpha = compute_alpha(loss_samples)\n",
    "    print('alpha: {}'.format(alpha))\n",
    "\n",
    "    # Step 5: Estimate iters to reach target loss\n",
    "    n = est_recov_n(loss_samples, target[task], alpha)\n",
    "    est_iter[task] = start + n*step\n",
    "    print('est iter: {}'.format(est_iter[task]))\n",
    "\n",
    "    # Step 6: Estimate final loss after 20000 iters\n",
    "    n = (total_iter - start)//step\n",
    "    final_loss[task] = est_final_loss(loss_samples, n, alpha)\n",
    "    print('final loss: {}'.format(final_loss[task]))\n",
    "    print('-'*50)\n",
    "layout_est_iter.append(est_iter)\n",
    "layout_est_loss.append(final_loss)\n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "800df536",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_samples=[2.51,2.50,2.48,1]\n",
    "alpha = compute_alpha(loss_samples)\n",
    "alpha2 = compute_alpha2(loss_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5fef0034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0345584412168006"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_final_loss(loss_samples, 10, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9b64d69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0120563381154453"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7408f538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.209453365628749"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9c988c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijunzhang/anaconda3/envs/multitask/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_recov_n(loss_samples, target[task], alpha2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1248729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alpha(loss_samples):\n",
    "    return np.log(loss_samples[2]/loss_samples[1])/ np.log(loss_samples[1]/loss_samples[0])\n",
    "\n",
    "def compute_alpha2(loss_samples):\n",
    "    return np.log(np.abs((loss_samples[3]-loss_samples[2])/(loss_samples[2]-loss_samples[1])))/ \\\n",
    "            np.log(np.abs((loss_samples[2]-loss_samples[1])/(loss_samples[1]-loss_samples[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30e0c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_recov_n(loss_samples, target, alpha):\n",
    "    up = np.log(target/loss_samples[0]) * (alpha - 1)\n",
    "    down = np.log(loss_samples[1]/loss_samples[0])\n",
    "    return np.log(up/down + 1) / np.log(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dcc30c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_final_loss(loss_samples, n, alpha):\n",
    "    x0, x1 = np.log(loss_samples[0]), np.log(loss_samples[1])\n",
    "    for i in range(2, n+1):\n",
    "        x2 = alpha * (x1-x0) + x1\n",
    "        x0 = x1\n",
    "        x1 = x2\n",
    "    return np.exp(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33381354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03c83641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort\n",
    "rate_list = []\n",
    "for alpha in rate:\n",
    "    rate_list.append(np.mean([alpha[task] for task in alpha]))\n",
    "rate_order = sorted(range(len(rate_list)), key=lambda k: rate_list[k],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca8e1270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segment_semantic': 0.9267602453218206,\n",
       " 'normal': 0.3232763318751182,\n",
       " 'depth_zbuffer': 0.2815663163084714}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae86149f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segment_semantic': 0.6359761891705582,\n",
       " 'normal': 1.0929589100906791,\n",
       " 'depth_zbuffer': 0.5271130297876526}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b73640a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segment_semantic': [0.7516613602638245,\n",
       "  0.7001743912696838,\n",
       "  0.6683229207992554],\n",
       " 'normal': [0.06778442859649658, 0.0672987699508667, 0.06692475080490112],\n",
       " 'depth_zbuffer': [1.0590227842330933, 1.0507172346115112, 1.0439845323562622]}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29540202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segment_semantic': 0.5405179977416993,\n",
       " 'normal': 0.05407652854919434,\n",
       " 'depth_zbuffer': 0.8496493339538574}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-resource",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-retention",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-franklin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-disability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
