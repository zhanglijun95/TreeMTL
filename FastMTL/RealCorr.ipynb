{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c41f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/lijunzhang/multibranch/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "import collections\n",
    "import pickle\n",
    "from statistics import mean, stdev\n",
    "from scipy import stats, spatial\n",
    "\n",
    "from main.algs_EstCon import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc51ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information for NYUv2\n",
    "data = 'NYUv2'\n",
    "model = 'mobilenet'\n",
    "iters = 20000 \n",
    "tasks = ('segment_semantic','normal','depth_zbuffer') # task 0, 1, 2\n",
    "metrics = {'segment_semantic': ['mIoU', 'Pixel Acc'],\n",
    "           'normal': ['Angle Mean', 'Angle Median', 'Angle 11.25', 'Angle 22.5', 'Angle 30'],\n",
    "           'depth_zbuffer': ['abs_err','rel_err','sigma_1.25','sigma_1.25^2','sigma_1.25^3']}\n",
    "metrics_prop = {'mIoU': False, 'Pixel Acc': False, \n",
    "                'Angle Mean': True, 'Angle Median': True, 'Angle 11.25': False, 'Angle 22.5': False, 'Angle 30': False,\n",
    "                'abs_err': True,'rel_err': True,'sigma_1.25': False,'sigma_1.25^2': False,'sigma_1.25^3': False} # True: the lower the better\n",
    "reduce_var_length = {'train_loss': 1, 'val_loss': 1, 'val_acc': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "41ceb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_complete(lines, iters):\n",
    "    rev_lines = lines[::-1]\n",
    "    for line in rev_lines:\n",
    "        if 'Iter' in line:\n",
    "            it = int(line.split(' ')[1])\n",
    "            break\n",
    "    if it != iters:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def extract_loss_results(lines, tasks, reduce_var_length, train=True):\n",
    "    # Function: Extract train loss \n",
    "    loss_lst = {}\n",
    "    for task in tasks:\n",
    "        if train:\n",
    "            loss_lst[task] = collections.deque(reduce_var_length['train_loss']*[0], reduce_var_length['train_loss'])\n",
    "        else:\n",
    "            loss_lst[task] = collections.deque(reduce_var_length['val_loss']*[0], reduce_var_length['val_loss'])\n",
    "    \n",
    "    for line in lines:\n",
    "        for task in tasks:\n",
    "            if task[:4] in line and ((train and 'Train Loss' in line) or (not train and 'Val Loss' in line)):\n",
    "                loss = float(line.split(': ')[1])\n",
    "                loss_lst[task].append(loss)\n",
    "                \n",
    "    final_loss = {task:-1 for task in tasks}\n",
    "    for task in tasks:\n",
    "        final_loss[task] = mean(loss_lst[task])\n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def extract_metric_results(lines, tasks, metrics, metrics_prop, metrics_refer, reduce_var_length):\n",
    "    # Function: Extract val metrics\n",
    "    \n",
    "    def rel_perf(results, refer, lower=True):\n",
    "        # Function: Compute rel. perf.\n",
    "        if lower:\n",
    "            return (refer - np.array(results))/refer*100\n",
    "        else:\n",
    "            return (np.array(results) - refer)/refer*100\n",
    "        \n",
    "    metric_queue = {}\n",
    "    for metric in metrics_prop:\n",
    "        metric_queue[metric] = []\n",
    "\n",
    "    for line in lines:\n",
    "        for metric in metrics_prop:\n",
    "            if \"'\"+metric in line:\n",
    "                value = float(re.findall(\"\\d+\\.\\d+\", line.split(metric)[1])[0])\n",
    "                metric_queue[metric].append(value)\n",
    "                \n",
    "    for metric in metrics_prop:\n",
    "        metric_queue[metric] = rel_perf(metric_queue[metric], metrics_refer[metric], metrics_prop[metric])\n",
    "        \n",
    "    task_rel_perf = {}\n",
    "    for task in tasks:\n",
    "        temp = 0\n",
    "        idx = 0\n",
    "        for metric in metrics[task]:\n",
    "            idx += 1\n",
    "            temp += mean(metric_queue[metric][-reduce_var_length['val_acc']:])\n",
    "        task_rel_perf[task] = temp/idx\n",
    "    return task_rel_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9f41c6",
   "metadata": {},
   "source": [
    "## real train and val loss, and task rel. perf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f2858c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_idx = [0,7,11,10,9,8,16,15,39,31,49,38,48,40,17,4,1,27,6,23] # verify_0221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf4e93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data is 'NYUv2' and model is 'mobilenet':\n",
    "    metrics_refer = {'mIoU': 0.2036, 'Pixel Acc': 0.4944,\n",
    "                     'Angle Mean': 18.1772, 'Angle Median': 16.6208, 'Angle 11.25': 28.3726, 'Angle 22.5': 70.2082, 'Angle 30': 85.5802,\n",
    "                     'abs_err': 0.7721, 'rel_err': 0.28, 'sigma_1.25': 47.9255, 'sigma_1.25^2': 78.4649, 'sigma_1.25^3': 92.813}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e6a74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_results = {'train_loss': {task: [] for task in tasks}, \n",
    "                'val_loss': {task: [] for task in tasks},\n",
    "                'rel_perf': {task: [] for task in tasks}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1366aad3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout Idx: 0\n",
      "Train Loss: {'segment_semantic': 0.9127, 'normal': 0.0564, 'depth_zbuffer': 0.4817}\n",
      "Val Loss: {'segment_semantic': 1.5478, 'normal': 0.0628, 'depth_zbuffer': 0.5709}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 7\n",
      "Train Loss: {'segment_semantic': 0.8639, 'normal': 0.056, 'depth_zbuffer': 0.4753}\n",
      "Val Loss: {'segment_semantic': 1.6028, 'normal': 0.0658, 'depth_zbuffer': 0.5656}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 11\n",
      "Train Loss: {'segment_semantic': 0.8666, 'normal': 0.0559, 'depth_zbuffer': 0.4705}\n",
      "Val Loss: {'segment_semantic': 1.5885, 'normal': 0.0634, 'depth_zbuffer': 0.5894}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 10\n",
      "Train Loss: {'segment_semantic': 0.8742, 'normal': 0.0555, 'depth_zbuffer': 0.4838}\n",
      "Val Loss: {'segment_semantic': 1.5718, 'normal': 0.064, 'depth_zbuffer': 0.6372}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 9\n",
      "Train Loss: {'segment_semantic': 0.8817, 'normal': 0.0562, 'depth_zbuffer': 0.5171}\n",
      "Val Loss: {'segment_semantic': 1.5845, 'normal': 0.0634, 'depth_zbuffer': 0.6646}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 8\n",
      "Train Loss: {'segment_semantic': 0.9187, 'normal': 0.0568, 'depth_zbuffer': 0.6046}\n",
      "Val Loss: {'segment_semantic': 1.5947, 'normal': 0.0634, 'depth_zbuffer': 0.6708}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 16\n",
      "Train Loss: {'segment_semantic': 0.8413, 'normal': 0.0574, 'depth_zbuffer': 0.6636}\n",
      "Val Loss: {'segment_semantic': 1.5435, 'normal': 0.062, 'depth_zbuffer': 0.707}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 15\n",
      "Train Loss: {'segment_semantic': 0.8191, 'normal': 0.0566, 'depth_zbuffer': 0.6458}\n",
      "Val Loss: {'segment_semantic': 1.5628, 'normal': 0.0635, 'depth_zbuffer': 0.7175}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 39\n",
      "Train Loss: {'segment_semantic': 0.8206, 'normal': 0.057, 'depth_zbuffer': 0.4786}\n",
      "Val Loss: {'segment_semantic': 1.589, 'normal': 0.0623, 'depth_zbuffer': 0.6442}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 31\n",
      "Train Loss: {'segment_semantic': 0.8523, 'normal': 0.0537, 'depth_zbuffer': 0.4898}\n",
      "Val Loss: {'segment_semantic': 1.5833, 'normal': 0.0665, 'depth_zbuffer': 0.6289}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 49\n",
      "Train Loss: {'segment_semantic': 0.8597, 'normal': 0.0567, 'depth_zbuffer': 0.4676}\n",
      "Val Loss: {'segment_semantic': 1.5867, 'normal': 0.0629, 'depth_zbuffer': 0.5788}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 38\n",
      "Train Loss: {'segment_semantic': 0.8384, 'normal': 0.0558, 'depth_zbuffer': 0.4939}\n",
      "Val Loss: {'segment_semantic': 1.5611, 'normal': 0.0638, 'depth_zbuffer': 0.655}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 48\n",
      "Train Loss: {'segment_semantic': 0.8714, 'normal': 0.0559, 'depth_zbuffer': 0.4756}\n",
      "Val Loss: {'segment_semantic': 1.583, 'normal': 0.0628, 'depth_zbuffer': 0.5873}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 40\n",
      "Train Loss: {'segment_semantic': 0.8772, 'normal': 0.0599, 'depth_zbuffer': 0.4734}\n",
      "Val Loss: {'segment_semantic': 1.5818, 'normal': 0.0622, 'depth_zbuffer': 0.5777}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 17\n",
      "Train Loss: {'segment_semantic': 0.8798, 'normal': 0.0625, 'depth_zbuffer': 0.5731}\n",
      "Val Loss: {'segment_semantic': 1.5821, 'normal': 0.0638, 'depth_zbuffer': 0.688}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 4\n",
      "Train Loss: {'segment_semantic': 0.8566, 'normal': 0.0617, 'depth_zbuffer': 0.6798}\n",
      "Val Loss: {'segment_semantic': 1.5521, 'normal': 0.0635, 'depth_zbuffer': 0.6972}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 1\n",
      "Train Loss: {'segment_semantic': 0.8977, 'normal': 0.0631, 'depth_zbuffer': 0.6109}\n",
      "Val Loss: {'segment_semantic': 1.5584, 'normal': 0.0638, 'depth_zbuffer': 0.6795}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 27\n",
      "Train Loss: {'segment_semantic': 0.858, 'normal': 0.0546, 'depth_zbuffer': 0.5927}\n",
      "Val Loss: {'segment_semantic': 1.5719, 'normal': 0.0646, 'depth_zbuffer': 0.6813}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 6\n",
      "Train Loss: {'segment_semantic': 0.8656, 'normal': 0.0631, 'depth_zbuffer': 0.6434}\n",
      "Val Loss: {'segment_semantic': 1.573, 'normal': 0.0642, 'depth_zbuffer': 0.7092}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 23\n",
      "Train Loss: {'segment_semantic': 0.8608, 'normal': 0.0546, 'depth_zbuffer': 0.5098}\n",
      "Val Loss: {'segment_semantic': 1.5729, 'normal': 0.062, 'depth_zbuffer': 0.6645}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# For each layout\n",
    "for idx in layout_idx:\n",
    "    log = 'layout_' + str(idx) + '.stdout'\n",
    "    with open('./log/layout_'+data+'_'+model+'/'+log) as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "        if not confirm_complete(lines,iters):\n",
    "                print(str(idx) + ' not complete')\n",
    "                continue\n",
    "        train_loss = extract_loss_results(lines, tasks, reduce_var_length)\n",
    "        val_loss = extract_loss_results(lines, tasks, reduce_var_length, False)\n",
    "        \n",
    "        for task in tasks:\n",
    "            real_results['train_loss'][task].append(train_loss[task])\n",
    "            real_results['val_loss'][task].append(val_loss[task])\n",
    "            \n",
    "        print('Layout Idx: {}'.format(idx), flush=True)\n",
    "        print('Train Loss: {}\\nVal Loss: {}'.format(train_loss, val_loss), flush=True)\n",
    "        print('-'*80)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1bf73b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout Idx: 0\n",
      "Task Rel Perf: {'segment_semantic': -1.1310767034797578, 'normal': 1.4515324945649222, 'depth_zbuffer': 17.206554719771017}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 7\n",
      "Task Rel Perf: {'segment_semantic': -2.000797934906316, 'normal': -1.4825044535798682, 'depth_zbuffer': 16.487610120740122}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 11\n",
      "Task Rel Perf: {'segment_semantic': -1.726348859684259, 'normal': 1.254881236663984, 'depth_zbuffer': 15.993379030297154}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 10\n",
      "Task Rel Perf: {'segment_semantic': -0.6905037798589786, 'normal': 0.9432141393187079, 'depth_zbuffer': 13.339899534132709}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 9\n",
      "Task Rel Perf: {'segment_semantic': -2.3099381044118505, 'normal': 0.8691874595392981, 'depth_zbuffer': 10.766214936102065}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 8\n",
      "Task Rel Perf: {'segment_semantic': -2.5382118628442134, 'normal': -0.08577222141302324, 'depth_zbuffer': 9.4568818012722}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 16\n",
      "Task Rel Perf: {'segment_semantic': 3.1203904158798577, 'normal': 0.957563451975173, 'depth_zbuffer': 5.78847668653478}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 15\n",
      "Task Rel Perf: {'segment_semantic': 0.28166148485830755, 'normal': 0.5955193700003092, 'depth_zbuffer': 4.321265570876059}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 39\n",
      "Task Rel Perf: {'segment_semantic': 0.044744756200687685, 'normal': 0.8186339454106484, 'depth_zbuffer': 12.92699728173703}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 31\n",
      "Task Rel Perf: {'segment_semantic': -0.9534686325748207, 'normal': 1.2314871057349512, 'depth_zbuffer': 13.035300657296242}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 49\n",
      "Task Rel Perf: {'segment_semantic': -0.6688665509502134, 'normal': 0.044800548621183156, 'depth_zbuffer': 16.172247810300316}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 38\n",
      "Task Rel Perf: {'segment_semantic': -1.883790000063587, 'normal': 0.7956482938195879, 'depth_zbuffer': 11.72608444606107}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 48\n",
      "Task Rel Perf: {'segment_semantic': -3.91202688182298, 'normal': 0.6372298234629155, 'depth_zbuffer': 15.875109407452712}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 40\n",
      "Task Rel Perf: {'segment_semantic': -1.0141681131223768, 'normal': 0.150859644673612, 'depth_zbuffer': 16.66899974783218}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 17\n",
      "Task Rel Perf: {'segment_semantic': 0.3365791163586187, 'normal': -0.37207128269081013, 'depth_zbuffer': 9.248905938016271}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 4\n",
      "Task Rel Perf: {'segment_semantic': 0.6139687883469683, 'normal': -0.4456671479633121, 'depth_zbuffer': 4.892517008656606}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 1\n",
      "Task Rel Perf: {'segment_semantic': -1.3651521798564379, 'normal': -0.8374599201914144, 'depth_zbuffer': 7.286313857959795}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 27\n",
      "Task Rel Perf: {'segment_semantic': 0.10401367615922628, 'normal': 0.8925333474487477, 'depth_zbuffer': 9.611517057767395}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 6\n",
      "Task Rel Perf: {'segment_semantic': -1.578981250119214, 'normal': -0.760167882417807, 'depth_zbuffer': 5.807249490220665}\n",
      "--------------------------------------------------------------------------------\n",
      "Layout Idx: 23\n",
      "Task Rel Perf: {'segment_semantic': -1.4489790565929757, 'normal': 2.620013451331919, 'depth_zbuffer': 10.107121945582197}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# For each layout\n",
    "for idx in layout_idx:\n",
    "    log = 'layout_' + str(idx) + '.stdout'\n",
    "    with open('./log/layout_'+data+'_'+model+'/'+log) as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "        if not confirm_complete(lines,iters):\n",
    "                print(str(idx) + ' not complete')\n",
    "                continue\n",
    "        task_rel_perf = extract_metric_results(lines, tasks, metrics, metrics_prop, metrics_refer, reduce_var_length)\n",
    "        \n",
    "        for task in tasks:\n",
    "            real_results['rel_perf'][task].append(task_rel_perf[task])\n",
    "        \n",
    "        print('Layout Idx: {}'.format(idx), flush=True)\n",
    "        print('Task Rel Perf: {}'.format(task_rel_perf), flush=True)\n",
    "        print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac8c7cb",
   "metadata": {},
   "source": [
    "## SROCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "22e1902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss vs val loss\n",
      "Task segm:\t SpearmanrResult(correlation=0.13834586466165413, pvalue=0.5607873732874131)\n",
      "Task norm:\t SpearmanrResult(correlation=-0.17233638858423728, pvalue=0.46750191037322486)\n",
      "Task dept:\t SpearmanrResult(correlation=0.918796992481203, pvalue=1.0827727759514947e-08)\n",
      "Overall:\t SpearmanrResult(correlation=0.7115457441893588, pvalue=0.00043453614698927293)\n"
     ]
    }
   ],
   "source": [
    "print('train loss vs val loss')\n",
    "for task in tasks:\n",
    "    corr = stats.spearmanr(real_results['train_loss'][task],real_results['val_loss'][task])\n",
    "    print('Task {}:\\t {}'.format(task[:4], corr))\n",
    "corr = stats.spearmanr(np.sum([real_results['train_loss'][task] for task in tasks], axis=0),\n",
    "                       np.sum([real_results['val_loss'][task] for task in tasks], axis=0))\n",
    "print('Overall:\\t {}'.format(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6f33a06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss vs rel perf\n",
      "Task segm:\t SpearmanrResult(correlation=-0.47067669172932325, pvalue=0.03621455166600094)\n",
      "Task norm:\t SpearmanrResult(correlation=-0.6601434392342201, pvalue=0.0015372864271503688)\n",
      "Task dept:\t SpearmanrResult(correlation=-0.9383458646616539, pvalue=9.762241109318019e-10)\n",
      "Overall:\t SpearmanrResult(correlation=-0.793984962406015, pvalue=2.923733879684014e-05)\n"
     ]
    }
   ],
   "source": [
    "print('train loss vs rel perf')\n",
    "for task in tasks:\n",
    "    corr = stats.spearmanr(real_results['train_loss'][task],real_results['rel_perf'][task])\n",
    "    print('Task {}:\\t {}'.format(task[:4], corr))\n",
    "corr = stats.spearmanr(np.sum([real_results['train_loss'][task] for task in tasks], axis=0),\n",
    "                       np.mean([real_results['rel_perf'][task] for task in tasks], axis=0))\n",
    "print('Overall:\\t {}'.format(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "803bb9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss vs rel perf\n",
      "Task segm:\t SpearmanrResult(correlation=-0.4616541353383458, pvalue=0.040457634341480954)\n",
      "Task norm:\t SpearmanrResult(correlation=-0.353343929780536, pvalue=0.1264520510817935)\n",
      "Task dept:\t SpearmanrResult(correlation=-0.9774436090225563, pvalue=1.322934226421056e-13)\n",
      "Overall:\t SpearmanrResult(correlation=-0.8852952863751326, pvalue=2.1380395587912932e-07)\n"
     ]
    }
   ],
   "source": [
    "print('val loss vs rel perf')\n",
    "for task in tasks:\n",
    "    corr = stats.spearmanr(real_results['val_loss'][task],real_results['rel_perf'][task])\n",
    "    print('Task {}:\\t {}'.format(task[:4], corr))\n",
    "corr = stats.spearmanr(np.sum([real_results['val_loss'][task] for task in tasks], axis=0),\n",
    "                       np.mean([real_results['rel_perf'][task] for task in tasks], axis=0))\n",
    "print('Overall:\\t {}'.format(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e2d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
